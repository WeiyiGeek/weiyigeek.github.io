{"title":"Alibaba开源数据同步工具DataX技术快速入门实践","slug":"数据存储/Database-运维/Datax/Alibaba开源数据同步工具DataX技术快速入门实践","date":"2021-11-20T03:16:58.000Z","updated":"2022-06-15T02:46:32.063Z","url":"2021/11-20-601.html","path":"api/articles/2021/11-20-601.html.json","covers":["https://github.com/alibaba/DataX/blob/master/images/DataX-logo.jpg","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014223117.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211028105401.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014224117.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014225201.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014233439.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211026174237.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211027191426.png"],"content":"<p>[TOC]</p>\n<a id=\"more\"></a>\n<h2 id=\"0x00-基础概述\"><a href=\"#0x00-基础概述\" class=\"headerlink\" title=\"0x00 基础概述\"></a>0x00 基础概述</h2><h3 id=\"1-什么是DataX\"><a href=\"#1-什么是DataX\" class=\"headerlink\" title=\"1.什么是DataX?\"></a>1.什么是DataX?</h3><p>DataX 是阿里云商用产品 DataWorks 数据集成的开源版本，它是一个<code>异构</code>数据源的<code>离线数据同步</code>工具/平台（ETL工具）。DataX 实现了包括 MySQL、Oracle、OceanBase、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、Hologres、DRDS 等各种<code>异构</code>数据源之间高效的数据同步功能。</p>\n<figure class=\"image-box\">\n                <img src=\"https://github.com/alibaba/DataX/blob/master/images/DataX-logo.jpg\" alt=\"DataX.Logo\" title=\"\" class=\"\">\n                <p>DataX.Logo</p>\n            </figure>\n<p>Tips : 异构即不同类型的应用或者数据源，例如<code>MySQL/Oracle/DB2/MongDB</code>等不同类型的数据库源<br>Tips : 离线数据同步以及CDC实时数据复制，前者常用Sqoop以及DataX工具。<br>Tips : ETL(<code>Extract-Transform-Load</code>)工具描述将数据从来源端经过<code>抽取（extract）、转换（transform）、加载（load）</code>至目的端的过程,<code>目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据</code>，其常用在数据仓库，但其对象并不限于数据仓库(DW)。</p>\n<p><br></p>\n<p>前面我们说到 DataX 的前身是阿里云商业化产品 DataWorks, 其稳定、高效、支持多样化等优点就不言而喻， DataWorks 致力于提供复杂网络环境下、丰富的异构数据源之间高速稳定的数据移动能力，以及繁杂业务背景下的数据同步解决方案。目前已经支持云上近3000家客户，单日同步数据超过3万亿条。DataWorks 数据集成目前支持离线50+种数据源，可以进行整库迁移、批量上云、增量同步、分库分表等各类同步解决方案。商业版本参见(<a href=\"https://www.aliyun.com/product/bigdata/ide\" target=\"_blank\" rel=\"noopener\">https://www.aliyun.com/product/bigdata/ide</a>)</p>\n<p><br></p>\n<p><strong>DataX它有何特点?</strong></p>\n<blockquote>\n<p>答: DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。</p>\n</blockquote>\n<p>Github 仓库: <a href=\"https://github.com/alibaba/DataX\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/DataX</a><br>Gitee 国内仓库: <a href=\"https://gitee.com/mirrors/DataX\" target=\"_blank\" rel=\"noopener\">https://gitee.com/mirrors/DataX</a></p>\n<p><br></p>\n<h3 id=\"2-DataX的设计思想\"><a href=\"#2-DataX的设计思想\" class=\"headerlink\" title=\"2.DataX的设计思想\"></a>2.DataX的设计思想</h3><p>描述：为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。</p>\n<p>简单得说,DataX就像中间商一样为每一个服务对象进行需求供应。</p>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014223117.png\" alt=\"WeiyiGeek.DataX设计思想\" title=\"\" class=\"\">\n                <p>WeiyiGeek.DataX设计思想</p>\n            </figure>\n<p><br></p>\n<h3 id=\"3-DataX的框架设计\"><a href=\"#3-DataX的框架设计\" class=\"headerlink\" title=\"3.DataX的框架设计\"></a>3.DataX的框架设计</h3><p>描述: DataX本身作为离线数据同步框架，离线（批量）的数据通道通过定义数据来源和去向的数据源和数据集，提供一套抽象化的数据抽取插件（Reader）、数据写入插件（Writer），并基于此框架设计一套简化版的中间数据传输格式，从而实现任意结构化、半结构化数据源之间数据传输。</p>\n<ul>\n<li><p>Reader：数据采集模块，负责采集数据源的数据，将数据发送给Framework。</p>\n</li>\n<li><p>Writer：数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。</p>\n</li>\n<li><p>Framework：用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。</p>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211028105401.png\" alt=\"WeiyiGeek.离线（批量）同步简介\"></p>\n<p>例如，将MySQL中的数据离线同步到HDFS之中来展示DataX的框架设计结构。</p>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014224117.png\" alt=\"WeiyiGeek.DataX框架设计\" title=\"\" class=\"\">\n                <p>WeiyiGeek.DataX框架设计</p>\n            </figure>\n<p>Tips : DataX架构设计流程类似<code>source（数据来源）-&gt; channel(数据存储池中转通道) -&gt; sink (目的地)</code>流程，</p>\n<p><br></p>\n<h3 id=\"4-DataX的运行原理\"><a href=\"#4-DataX的运行原理\" class=\"headerlink\" title=\"4.DataX的运行原理\"></a>4.DataX的运行原理</h3><p>描述: DataX 3.0 开源版本支持单机多线程模式完成同步作业运行，本小节按一个DataX作业生命周期的时序图，从整体架构设计非常简要说明DataX各个模块相互关系。</p>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014225201.png\" alt=\"WeiyiGeek.DataX运行原理\" title=\"\" class=\"\">\n                <p>WeiyiGeek.DataX运行原理</p>\n            </figure>\n<p><br></p>\n<p><strong>DataX 调度流程:</strong><br>描述: DataX完成单个数据同步的作业(Job)，当DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。在Job启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—&gt;Channel—&gt;Writer的线程来完成任务同步工作。DataX作业运行起来之后，Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出，<code>否则异常退出，并且进程退出值非0</code>。</p>\n<p><br></p>\n<p><strong>核心模块解析:</strong></p>\n<ul>\n<li>DataX Job 模块 : 是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。</li>\n<li>DataX Task : 由Job切分而来, 是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作（包含<code>Reader—&gt;Channel—&gt;Writer</code>流程）。</li>\n<li>DataX Schedule 模块 : 将Task组成TaskGroup ，注意单个组的默认并发数量为5(<code>动态概念即同时有5个在运行</code>)。</li>\n<li>DataX TaskGroup : 负责启动以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。</li>\n</ul>\n<p><br></p>\n<p><strong>举例说明,当用户提交一个Datax Job 并且配置了20并非数，目的是将一个100张分别的MySQL数据同步到odps中。</strong></p>\n<ul>\n<li>(1) 首先根据分库分表切分成为100个Task。</li>\n<li>(2) 根据要达到20个并发，此时我们需要分配4个TaskGroup，简单的说20并发除以每个TaskGroup的默认并发5得到4。</li>\n<li>(3) 此时每一个TaskGroup负责以5并发数，共计运行25个Task，简单的说100Task除以4个TaskGroup就得到每个组需要执行的Task数。</li>\n</ul>\n<p><br></p>\n<h3 id=\"5-DataX支持的数据源\"><a href=\"#5-DataX支持的数据源\" class=\"headerlink\" title=\"5.DataX支持的数据源\"></a>5.DataX支持的数据源</h3><p>DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入，目前支持数据源如下表 (<a href=\"https://github.com/alibaba/DataX#support-data-channels\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/DataX#support-data-channels</a>)</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>数据源</th>\n<th>Reader(读)</th>\n<th>Writer(写)</th>\n<th>文档</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>RDBMS 关系型数据库</td>\n<td>MySQL</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Oracle</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>OceanBase</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>SQLServer</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>PostgreSQL</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>DRDS</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>通用RDBMS(支持所有关系型数据库)</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/rdbmsreader/doc/rdbmsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/rdbmswriter/doc/rdbmswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td>阿里云数仓数据存储</td>\n<td>ODPS</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/odpswriter/doc/odpswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>ADS</td>\n<td></td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>OSS</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>OCS</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/ocsreader/doc/ocsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td>NoSQL数据存储</td>\n<td>OTS</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Hbase0.94</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Hbase1.1</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/hbase11xreader/doc/hbase11xreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Phoenix4.x</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/hbase11xsqlreader/doc/hbase11xsqlreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/hbase11xsqlwriter/doc/hbase11xsqlwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Phoenix5.x</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/hbase20xsqlreader/doc/hbase20xsqlreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/hbase20xsqlwriter/doc/hbase20xsqlwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>MongoDB</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/mongodbreader/doc/mongodbreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Hive</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Cassandra</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/cassandrareader/doc/cassandrareader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/cassandrawriter/doc/cassandrawriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td>无结构化数据存储</td>\n<td>TxtFile</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>FTP</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>HDFS</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td></td>\n<td>Elasticsearch</td>\n<td></td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n<tr>\n<td>时间序列数据库</td>\n<td>OpenTSDB</td>\n<td>√</td>\n<td></td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/opentsdbreader/doc/opentsdbreader.md\" target=\"_blank\" rel=\"noopener\">读</a></td>\n</tr>\n<tr>\n<td></td>\n<td>TSDB</td>\n<td>√</td>\n<td>√</td>\n<td><a href=\"https://github.com/alibaba/DataX/blob/master/tsdbreader/doc/tsdbreader.md\" target=\"_blank\" rel=\"noopener\">读</a> 、<a href=\"https://github.com/alibaba/DataX/blob/master/tsdbwriter/doc/tsdbhttpwriter.md\" target=\"_blank\" rel=\"noopener\">写</a></td>\n</tr>\n</tbody>\n</table>\n<p>Tips : DataX Framework提供了简单的接口与插件交互，提供简单的插件接入机制，只需要任意加上一种插件，就能无缝对接其他数据源。</p>\n<p><br></p>\n<h3 id=\"6-为何选择DataX\"><a href=\"#6-为何选择DataX\" class=\"headerlink\" title=\"6.为何选择DataX?\"></a>6.为何选择DataX?</h3><p>描述: 我们可以从DataX 3.0六大核心优势入手了解我们为何选择它。</p>\n<p>(1) 可靠的数据质量监控</p>\n<ul>\n<li>完美解决数据传输个别类型失真问题</li>\n<li>提供作业全链路的流量、数据量运行时监控</li>\n<li>提供脏数据探测</li>\n</ul>\n<p>(2) 丰富的数据转换功能 : DataX作为一个服务于大数据的ETL工具，除了提供数据快照搬迁功能之外，还提供了丰富数据转换的功能，让数据在传输过程中可以轻松完成数据脱敏，补全，过滤等数据转换功能，另外还提供了自动groovy函数，让用户自定义转换函数。</p>\n<p>(3) 精准的速度控制 : 新版本DataX3.0提供了包括通道(并发)、记录流、字节流三种流控模式，可以随意控制你的作业速度，让你的作业在库可以承受的范围内达到最佳的同步速度。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"speed\"</span>: &#123;</span><br><span class=\"line\">   <span class=\"string\">\"channel\"</span>: 5,</span><br><span class=\"line\">   <span class=\"string\">\"byte\"</span>: 1048576,</span><br><span class=\"line\">   <span class=\"string\">\"record\"</span>: 10000</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>(4) 强劲的同步性能 : DataX3.0每一种读插件都有一种或多种切分策略，都能将作业合理切分成多个Task并行执行，单机多线程执行模型可以让DataX速度随并发成线性增长</p>\n<p>(5) 健壮的容错机制</p>\n<ul>\n<li>线程内部重试</li>\n<li>线程级别重试</li>\n</ul>\n<p>(6) 极简的使用体验</p>\n<ul>\n<li>易用: 开箱即用支持linux和windows，只需要短短几步骤就可以完成数据的传输</li>\n<li>详细: 在运行日志中打印了大量信息，其中包括传输速度，Reader、Writer性能，进程CPU，JVM和GC情况</li>\n</ul>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211014233439.png\" alt=\"WeiyiGeek.详细日志输出\" title=\"\" class=\"\">\n                <p>WeiyiGeek.详细日志输出</p>\n            </figure>\n<p><br></p>\n<p><strong>DataX 与 Sqoop 间的对比(VS)</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Function</th>\n<th>DataX</th>\n<th>Sqoop</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"> 运行模式</td>\n<td>单进程多线程 (可以独立启动多个进程)</td>\n<td>MR模型</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 文件格式</td>\n<td>ORC 支持</td>\n<td>orc 不支持</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 分布式</td>\n<td>不支持（但可以通过调度系统扩充）</td>\n<td>支持</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 流量控制</td>\n<td>支持</td>\n<td>需要定制</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 统计信息</td>\n<td>基本详细的统计信息</td>\n<td>没有(分布式的数据采集不方便)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 数据校验</td>\n<td>在core部分有校验功能</td>\n<td>没有 </td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 数据监控</td>\n<td>需要定制</td>\n<td>需要定制</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> 社区支持</td>\n<td>开源时间短社区活跃一般</td>\n<td>开源时间长社区活跃，核心部分变动少</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> MySQL读写</td>\n<td>单机压力大、读写粒度容易控制</td>\n<td>MR 模式错误处理麻烦</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"> Hive 读写</td>\n<td>单机压力大</td>\n<td>均衡写入很好</td>\n</tr>\n</tbody>\n</table>\n<p><br></p>\n<p><strong>DataX 应用场景与适用人群。</strong></p>\n<ul>\n<li>应用于企业应用中数据迁移备份，以及供不同接入的应用数据库的应用进行数据的访问。</li>\n<li>适用于从事数据采集工作人员，以及企业中从0到1建设阶段IT运维、以及DBA运维管理人员。</li>\n</ul>\n<p><br/></p>\n<h2 id=\"0x01-Datax-安装使用\"><a href=\"#0x01-Datax-安装使用\" class=\"headerlink\" title=\"0x01 Datax 安装使用\"></a>0x01 Datax 安装使用</h2><h3 id=\"1-快速开始\"><a href=\"#1-快速开始\" class=\"headerlink\" title=\"1.快速开始\"></a>1.快速开始</h3><p>描述: DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 <code>MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS</code> 等各种异构数据源之间高效的数据同步功能。</p>\n<p><strong>系统环境依赖-System Requirements</strong></p>\n<ul>\n<li>Linux</li>\n<li>JDK ( 1.8以上，推荐1.8 )</li>\n<li>Python ( 推荐 Python2.6.X )<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 国内镜像下载: https://npmmirror.com/mirrors/python/2.6.9/Python-2.6.9.tgz</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHON_HOME=<span class=\"string\">\"/usr/local/python27\"</span></span><br><span class=\"line\">wget https://www.python.org/ftp/python/2.7.18/Python-2.7.18.tgz</span><br><span class=\"line\">tar -zxf Python-2.7.18.tgz -C /usr/<span class=\"built_in\">local</span>/</span><br><span class=\"line\">apt install gcc g++ make </span><br><span class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/Python-2.7.18</span><br><span class=\"line\">./configure --prefix=/usr/<span class=\"built_in\">local</span>/python27</span><br><span class=\"line\">make &amp;&amp; make install</span><br><span class=\"line\">ln -s /usr/<span class=\"built_in\">local</span>/python27/bin/python2.7 /usr/bin/python</span><br><span class=\"line\">ln -s /usr/<span class=\"built_in\">local</span>/python27/bin/python2.7 /usr/bin/python2</span><br><span class=\"line\">python --version &amp;&amp; python2 --version</span><br><span class=\"line\">Python 2.7.18</span><br></pre></td></tr></table></figure></li>\n<li>Apache Maven 3.x (Compile DataX)</li>\n</ul>\n<p><br/></p>\n<p><strong>安装部署方式</strong></p>\n<ul>\n<li><p>方法一、直接下载 DataX工具包：<a href=\"http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz\" target=\"_blank\" rel=\"noopener\">DataX下载地址</a></p>\n<p>下载后解压至本地某个目录，进入bin目录，即可运行同步作业：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">export</span> DATAX_HOME=<span class=\"string\">\"/usr/local/datax\"</span></span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> wget http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> tar -zxf datax.tar.gz -C /usr/<span class=\"built_in\">local</span>/</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> <span class=\"variable\">$&#123;DATAX_HOME&#125;</span>/bin</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> python <span class=\"variable\">$&#123;DATAX_HOME&#125;</span>/bin/datax.py <span class=\"variable\">$&#123;DATAX_HOME&#125;</span>/job/job.json</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ln -s <span class=\"variable\">$&#123;DATAX_HOME&#125;</span>/bin/datax.py /usr/<span class=\"built_in\">local</span>/datax.py</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><br/></p>\n<ul>\n<li><p>方法二、下载DataX源码，自己编译：<a href=\"https://github.com/alibaba/DataX\" target=\"_blank\" rel=\"noopener\">DataX源码</a></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> (1)、下载DataX源码：</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> git <span class=\"built_in\">clone</span> git@github.com:alibaba/DataX.git</span></span><br><span class=\"line\"> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> (2)、通过maven打包：</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> <span class=\"built_in\">cd</span>  &#123;DataX_source_code_home&#125;</span></span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> mvn -U clean package assembly:assembly -Dmaven.test.skip=<span class=\"literal\">true</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> (3) 打包成功，日志显示如下：</span></span><br><span class=\"line\">[INFO] BUILD SUCCESS</span><br><span class=\"line\">[INFO] -----------------------------------------------------------------</span><br><span class=\"line\">[INFO] Total time: 08:12 min</span><br><span class=\"line\">[INFO] Finished at: 2015-12-13T16:26:48+08:00</span><br><span class=\"line\">[INFO] Final Memory: 133M/960M</span><br><span class=\"line\">[INFO] -----------------------------------------------------------------</span><br><span class=\"line\"></span><br><span class=\"line\">Tips : 打包成功后的DataX包位于 `&#123;DataX_source_code_home&#125;/target/datax/datax/ `</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>Datax 解压后其结构如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd &#x2F;usr&#x2F;local&#x2F;datax</span><br><span class=\"line\">$ &#x2F;usr&#x2F;local&#x2F;datax# tree -d -L 2</span><br><span class=\"line\">├── bin   # 可执行的Python脚本</span><br><span class=\"line\">├── conf  # Datax 配置文件</span><br><span class=\"line\">├── job   # 离线同步任务</span><br><span class=\"line\">├── lib   # 依赖库</span><br><span class=\"line\">├── log   # 任务执行过程日志</span><br><span class=\"line\">├── log_perf</span><br><span class=\"line\">├── plugin # 各类数据库读写插件</span><br><span class=\"line\">│   ├── reader</span><br><span class=\"line\">│   └── writer</span><br><span class=\"line\">├── script # 脚本存放</span><br><span class=\"line\">└── tmp    # 临时目录</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p><strong>运行测试</strong><br>描述: 采用 Datax 自带的 job/job.json 进行运行测试验证安装环境。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/<span class=\"built_in\">local</span>/datax<span class=\"comment\"># ./bin/datax.py job/job.json</span></span><br><span class=\"line\"><span class=\"comment\"># (1) 显示机器相关信息(CPU/内存、以及JVM相关信息)</span></span><br><span class=\"line\">2021-10-26 11:20:54.301 [main] INFO  Engine - the machine info  =&gt;</span><br><span class=\"line\">    osInfo: Eclipse Foundation 16 16.0.2+7</span><br><span class=\"line\">    jvmInfo:        Linux amd64 5.4.0-88-generic</span><br><span class=\"line\">    cpu num:        4</span><br><span class=\"line\">    totalPhysicalMemory:    -0.00G</span><br><span class=\"line\">    freePhysicalMemory:     -0.00G</span><br><span class=\"line\">    maxFileDescriptorCount: -1</span><br><span class=\"line\">    currentOpenFileDescriptorCount: -1</span><br><span class=\"line\"></span><br><span class=\"line\">    GC Names        [G1 Young Generation, G1 Old Generation]</span><br><span class=\"line\">    MEMORY_NAME                    | allocation_size                | init_size</span><br><span class=\"line\">    CodeHeap <span class=\"string\">'profiled nmethods'</span>   | 117.21MB                       | 2.44MB</span><br><span class=\"line\">    G1 Old Gen                     | 1,024.00MB                     | 970.00MB</span><br><span class=\"line\">    G1 Survivor Space              | -0.00MB                        | 0.00MB</span><br><span class=\"line\">    CodeHeap <span class=\"string\">'non-profiled nmethods'</span> | 117.22MB                       | 2.44MB</span><br><span class=\"line\">    Compressed Class Space         | 1,024.00MB                     | 0.00MB</span><br><span class=\"line\">    Metaspace                      | -0.00MB                        | 0.00MB</span><br><span class=\"line\">    G1 Eden Space                  | -0.00MB                        | 54.00MB</span><br><span class=\"line\">    CodeHeap <span class=\"string\">'non-nmethods'</span>        | 5.57MB                         | 2.44MB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) Job 任务执行情况</span></span><br><span class=\"line\">2021-10-26 11:21:04.364 [job-0] INFO  StandAloneJobContainerCommunicator - Total 100000 records, 2600000 bytes | Speed 253.91KB/s, 10000 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.021s |  All Task WaitReaderTim</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) job 任务执行CPU与GC占比信息</span></span><br><span class=\"line\">2021-10-26 11:21:04.367 [job-0] INFO  JobContainer -</span><br><span class=\"line\">[total cpu info] =&gt;</span><br><span class=\"line\">averageCpu                     | maxDeltaCpu                    | minDeltaCpu</span><br><span class=\"line\">-1.00%                         | -1.00%                         | -1.00%</span><br><span class=\"line\">[total gc info] =&gt;</span><br><span class=\"line\">NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime</span><br><span class=\"line\">G1 Young Generation  | 0                  | 0                  | 0                  | 0.000s             | 0.000s             | 0.000s</span><br><span class=\"line\">G1 Old Generation    | 0                  | 0                  | 0                  | 0.000s             | 0.000s             | 0.000s</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (4) Job 任务执行完毕总计数据(非常重要) 、可以验证同步的数据是否全部同步成功。</span></span><br><span class=\"line\">2021-10-26 11:21:04.367 [job-0] INFO  StandAloneJobContainerCommunicator - Total 100000 records, 2600000 bytes | Speed 253.91KB/s, 10000 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.021s |  All Task WaitReaderTime 0.041s | Percentage 100.00%</span><br><span class=\"line\">2021-10-26 11:21:04.368 [job-0] INFO  JobContainer -</span><br><span class=\"line\">任务启动时刻                    : 2021-10-26 11:20:54</span><br><span class=\"line\">任务结束时刻                    : 2021-10-26 11:21:04</span><br><span class=\"line\">任务总计耗时                    :                 10s</span><br><span class=\"line\">任务平均流量                    :          253.91KB/s</span><br><span class=\"line\">记录写入速度                    :          10000rec/s</span><br><span class=\"line\">读出记录总数                    :              100000</span><br><span class=\"line\">读写失败总数                    :                   0</span><br></pre></td></tr></table></figure></p>\n<p>Tips : 上面 Job 读写输出数据为<code>DataX   19890604        1989-06-03 23:00:00     true    test</code></p>\n<p><br></p>\n<h3 id=\"2-基础使用\"><a href=\"#2-基础使用\" class=\"headerlink\" title=\"2.基础使用\"></a>2.基础使用</h3><p>描述: 我们可以通过DataX数据源参考指南(<a href=\"https://github.com/alibaba/DataX/wiki/DataX-all-data-channels)来查看具体每个插件需要或者可选的插件。\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/DataX/wiki/DataX-all-data-channels)来查看具体每个插件需要或者可选的插件。</a></p>\n<p><strong>插件示例获取:</strong><br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./bin/datax.py -r streamreader -w streamwriter</span><br><span class=\"line\"># (1) 此处将会显示 读写 插件的使用文档说明</span><br><span class=\"line\">Please refer to the streamreader document: https://github.com/alibaba/DataX/blob/master/streamreader/doc/streamreader.md</span><br><span class=\"line\">Please refer to the streamwriter document:https://github.com/alibaba/DataX/blob/master/streamwriter/doc/streamwriter.md</span><br><span class=\"line\"></span><br><span class=\"line\"># (2) 命令执行示例</span><br><span class=\"line\">python &#123;DATAX_HOME&#125;/bin/datax.py &#123;JSON_FILE_NAME&#125;.json</span><br><span class=\"line\"></span><br><span class=\"line\"># (3) Job 任务配置示例 Json 格式 (以下参数我简单描述)</span><br><span class=\"line\">tee job/stream2stream.json &lt;&lt;'EOF'</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"job\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"content\"</span>: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            // 读插件</span><br><span class=\"line\">            \"reader\": &#123;</span><br><span class=\"line\">                \"name\": \"streamreader\", // 指定插件名称</span><br><span class=\"line\">                \"parameter\": &#123;</span><br><span class=\"line\">                    \"column\": [  // 字段类与值 (必须进行指定)</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"value\"</span>: <span class=\"string\">\"WeiyiGeek\"</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"string\"</span></span><br><span class=\"line\">                      &#125;,</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"value\"</span>: <span class=\"number\">2021</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"long\"</span></span><br><span class=\"line\">                      &#125;,</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"value\"</span>: <span class=\"string\">\"2021-01-01 00:00:00\"</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"date\"</span></span><br><span class=\"line\">                      &#125;,</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"value\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"bool\"</span></span><br><span class=\"line\">                      &#125;,</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"attr\">\"value\"</span>: <span class=\"string\">\"test\"</span>,</span><br><span class=\"line\">                        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"bytes\"</span></span><br><span class=\"line\">                      &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    \"sliceRecordCount\": \"10\" // 切片记录计数</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            // 写插件</span><br><span class=\"line\">            \"writer\": &#123;</span><br><span class=\"line\">                \"name\": \"streamwriter\",  // 指定使用的插件名称</span><br><span class=\"line\">                \"parameter\": &#123;</span><br><span class=\"line\">                    \"encoding\": \"UTF-8\",  // 编码格式</span><br><span class=\"line\">                    \"print\": true         // 是否终端打印</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      \"setting\": &#123;</span><br><span class=\"line\">          \"speed\": &#123;             // 同步速度采用的类型</span><br><span class=\"line\">              \"channel\": \"2\"     // 并发数</span><br><span class=\"line\">              //\"byte\": 10485760 // 字节数</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure></p>\n<p>执行结果: (执行时请删除上述备注)<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python bin/datax.py job/stream2stream.json</span><br><span class=\"line\"><span class=\"comment\"># (1) 两个任务进程</span></span><br><span class=\"line\">2021-10-26 16:28:33.568 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [2] channels <span class=\"keyword\">for</span> [2] tasks.</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) 每个任务进程执行10条 (即总数20条)</span></span><br><span class=\"line\">2021-10-26 16:28:33.579 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started</span><br><span class=\"line\">2021-10-26 16:28:33.595 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[1] attemptCount[1] is started</span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\">WeiyiGeek       2021    2021-01-01 00:00:00     <span class=\"literal\">true</span>    <span class=\"built_in\">test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) 执行结果信息</span></span><br><span class=\"line\">2021-10-26 16:28:43.576 [job-0] INFO  StandAloneJobContainerCommunicator - Total 20 records, 520 bytes | Speed 52B/s, 2 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReade        rTime 0.002s | Percentage 100.00%</span><br><span class=\"line\">2021-10-26 16:28:43.576 [job-0] INFO  JobContainer -</span><br><span class=\"line\">任务启动时刻                    : 2021-10-26 16:28:33</span><br><span class=\"line\">任务结束时刻                    : 2021-10-26 16:28:43</span><br><span class=\"line\">任务总计耗时                    :                 10s</span><br><span class=\"line\">任务平均流量                    :               52B/s</span><br><span class=\"line\">记录写入速度                    :              2rec/s</span><br><span class=\"line\">读出记录总数                    :                  20</span><br><span class=\"line\">读写失败总数                    :                   0</span><br></pre></td></tr></table></figure></p>\n<p>Tips : 执行后的日志除了终端打印还会在本地日志目录中存放(<code>/usr/local/datax/log/2021-10-26/b_stream2stream_json-16_28_33.312.log</code>)文件。</p>\n<p>Tips : 非常执行同步写入的总次数为<code>setting.speed.channel * sliceRecordCount</code>。</p>\n<hr>\n<h2 id=\"0x02-Datax-实战使用\"><a href=\"#0x02-Datax-实战使用\" class=\"headerlink\" title=\"0x02 Datax 实战使用\"></a>0x02 Datax 实战使用</h2><h3 id=\"1-MySQL-To-HDFS\"><a href=\"#1-MySQL-To-HDFS\" class=\"headerlink\" title=\"1.MySQL-To-HDFS\"></a>1.MySQL-To-HDFS</h3><p><strong>环境&amp;准备说明:</strong><br>描述: 为了快速搭建测试的数据库环境,本系列将采用<code>docker容器</code>进行搭建部署,如没有安装<code>docker 和 docker-compose</code>请参照本博客中的Docker系列课程。</p>\n<p><strong>(1) MySQL</strong><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># docker-compose.yml</span></span><br><span class=\"line\">version: <span class=\"string\">'3.1'</span></span><br><span class=\"line\">services:</span><br><span class=\"line\">  db8:</span><br><span class=\"line\">    image: mysql</span><br><span class=\"line\">    container_name: mysql8.x</span><br><span class=\"line\">    <span class=\"built_in\">command</span>: --default-authentication-plugin=mysql_native_password</span><br><span class=\"line\">    restart: always</span><br><span class=\"line\">    environment:</span><br><span class=\"line\">      MYSQL_ROOT_PASSWORD: www.weiyigeek.top</span><br><span class=\"line\">      MYSQL_DATABASE: <span class=\"built_in\">test</span></span><br><span class=\"line\">      MYSQL_USER: <span class=\"built_in\">test</span></span><br><span class=\"line\">      MYSQL_PASSWORD: www.weiyigeek.top</span><br><span class=\"line\">    volumes:</span><br><span class=\"line\">      - <span class=\"string\">\"/app/mysql8:/var/lib/mysql\"</span></span><br><span class=\"line\">    ports:</span><br><span class=\"line\">      - 3306:3306</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 部署流程 #</span></span><br><span class=\"line\">docker pull singularities/hadoop</span><br><span class=\"line\">docker-compose up -d</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建测试表</span></span><br><span class=\"line\">DROP TABLE IF EXISTS `user`;</span><br><span class=\"line\">CREATE TABLE `user`  (</span><br><span class=\"line\">  `uid` int(0) NOT NULL AUTO_INCREMENT COMMENT <span class=\"string\">'用户id'</span>,</span><br><span class=\"line\">  `name` varchar(32) CHARACTER SET utf8mb4  NOT NULL COMMENT <span class=\"string\">'用户名称'</span>,</span><br><span class=\"line\">  `age` int(0) NOT NULL COMMENT <span class=\"string\">'用户年龄'</span>,</span><br><span class=\"line\">  `hobby` varchar(255) CHARACTER SET utf8mb4  NOT NULL COMMENT <span class=\"string\">'用户爱好'</span>,</span><br><span class=\"line\">  `operation_time` datetime(0) NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP(0) COMMENT <span class=\"string\">'插入时间'</span>,</span><br><span class=\"line\">  PRIMARY KEY (`uid`) USING BTREE</span><br><span class=\"line\">) ENGINE = InnoDB AUTO_INCREMENT = 9 CHARACTER SET = utf8mb4 ROW_FORMAT = Dynamic;</span><br><span class=\"line\"></span><br><span class=\"line\">SET FOREIGN_KEY_CHECKS = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (1, <span class=\"string\">'WeiyiGeek'</span>, 20, <span class=\"string\">'Network,Computer'</span>, <span class=\"string\">'2021-10-12 14:34:03'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (2, <span class=\"string\">'Elastic'</span>, 18, <span class=\"string\">'数据分析,数据采集,数据处理'</span>, <span class=\"string\">'2021-10-12 17:16:34'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (3, <span class=\"string\">'Logstash'</span>, 20, <span class=\"string\">'日志采集,日志过滤'</span>, <span class=\"string\">'2021-10-12 17:16:59'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (4, <span class=\"string\">'Beats'</span>, 10, <span class=\"string\">'通用日志采集'</span>, <span class=\"string\">'2021-10-12 17:17:06'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (5, <span class=\"string\">'Kibana'</span>, 19, <span class=\"string\">'数据分析,日志搜寻,日志数据展示,可视化'</span>, <span class=\"string\">'2021-10-12 17:27:38'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (6, <span class=\"string\">'C'</span>, 25, <span class=\"string\">'面向过程编程语言'</span>, <span class=\"string\">'2021-10-13 02:43:30'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (7, <span class=\"string\">'C++'</span>, 25, <span class=\"string\">'面向对象'</span>, <span class=\"string\">'2021-10-13 10:44:59'</span>);</span><br><span class=\"line\">INSERT INTO `<span class=\"built_in\">test</span>`.`user`(`uid`, `name`, `age`, `hobby`, `operation_time`) VALUES (8, <span class=\"string\">'Python'</span>, 26, <span class=\"string\">'编程语言'</span>, <span class=\"string\">'2021-10-13 10:48:45'</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 此时test表中有如下数据。</span></span><br><span class=\"line\">mysql&gt; select * from test.user;</span><br><span class=\"line\">+-----+-----------+-----+---------------------------------------+---------------------+</span><br><span class=\"line\">| uid | name      | age | hobby                                 | operation_time      |</span><br><span class=\"line\">+-----+-----------+-----+---------------------------------------+---------------------+</span><br><span class=\"line\">|   1 | WeiyiGeek |  20 | Network,Computer                      | 2021-10-12 14:34:03 |</span><br><span class=\"line\">|   2 | Elastic   |  18 | 数据分析,数据采集,数据处理            | 2021-10-12 17:16:34 |</span><br><span class=\"line\">|   3 | Logstash  |  20 | 日志采集,日志过滤                     | 2021-10-12 17:16:59 |</span><br><span class=\"line\">|   4 | Beats     |  10 | 通用日志采集                          | 2021-10-12 17:17:06 |</span><br><span class=\"line\">|   5 | Kibana    |  19 | 数据分析,日志搜寻,日志数据展示,可视化 | 2021-10-12 17:27:38 |</span><br><span class=\"line\">|   6 | C         |  25 | 面向过程编程语言                      | 2021-10-13 02:43:30 |</span><br><span class=\"line\">|   7 | C++       |  25 | 面向对象                              | 2021-10-13 10:44:59 |</span><br><span class=\"line\">|   8 | Python    |  26 | 编程语言                              | 2021-10-13 10:48:45 |</span><br><span class=\"line\">+-----+-----------+-----+---------------------------------------+---------------------+</span><br><span class=\"line\">8 rows <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.04 sec)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表中字段类型</span></span><br><span class=\"line\">mysql&gt; desc test.user;</span><br><span class=\"line\">+----------------+--------------+------+-----+---------+-----------------------------+</span><br><span class=\"line\">| Field          | Type         | Null | Key | Default | Extra                       |</span><br><span class=\"line\">+----------------+--------------+------+-----+---------+-----------------------------+</span><br><span class=\"line\">| uid            | int          | NO   | PRI | NULL    | auto_increment              |</span><br><span class=\"line\">| name           | varchar(32)  | NO   |     | NULL    |                             |</span><br><span class=\"line\">| age            | int          | NO   |     | NULL    |                             |</span><br><span class=\"line\">| hobby          | varchar(255) | NO   |     | NULL    |                             |</span><br><span class=\"line\">| operation_time | datetime     | YES  |     | NULL    | on update CURRENT_TIMESTAMP |</span><br><span class=\"line\">+----------------+--------------+------+-----+---------+-----------------------------+</span><br><span class=\"line\">5 rows <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.04 sec)</span><br></pre></td></tr></table></figure></p>\n<p><br></p>\n<p><strong>(2) HDFS</strong><br>Docker HDFS镜像参考地址: <a href=\"https://registry.hub.docker.com/r/gradiant/hdfs\" target=\"_blank\" rel=\"noopener\">https://registry.hub.docker.com/r/gradiant/hdfs</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># hdfs-site 配置文件</span></span><br><span class=\"line\">tee /tmp/hdfs-site.xml &lt;&lt;<span class=\"string\">'EOF'</span></span><br><span class=\"line\">&lt;?xml version=<span class=\"string\">\"1.0\"</span> encoding=<span class=\"string\">\"UTF-8\"</span>?&gt;</span><br><span class=\"line\">&lt;?xml-stylesheet <span class=\"built_in\">type</span>=<span class=\"string\">\"text/xsl\"</span> href=<span class=\"string\">\"configuration.xsl\"</span>?&gt;</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;&lt;value&gt;file:///hadoop/dfs/name&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-bind-host&lt;/name&gt;&lt;value&gt;0.0.0.0&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.namenode.servicerpc-bind-host&lt;/name&gt;&lt;value&gt;0.0.0.0&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.namenode.http-bind-host&lt;/name&gt;&lt;value&gt;0.0.0.0&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.namenode.https-bind-host&lt;/name&gt;&lt;value&gt;0.0.0.0&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.client.use.datanode.hostname&lt;/name&gt;&lt;value&gt;<span class=\"literal\">true</span>&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.datanode.use.datanode.hostname&lt;/name&gt;&lt;value&gt;<span class=\"literal\">true</span>&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt;&lt;value&gt;<span class=\"literal\">false</span>&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;&lt;name&gt;dfs.permissions.enabled&lt;/name&gt;&lt;value&gt;<span class=\"literal\">false</span>&lt;/value&gt;&lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 部署流程 #</span></span><br><span class=\"line\">docker pull gradiant/hdfs-namenode</span><br><span class=\"line\">docker pull gradiant/hdfs-datanode</span><br><span class=\"line\">docker run -d --name hdfs-namenode -v /tmp/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml \\</span><br><span class=\"line\">      -p <span class=\"string\">\"8020:8020\"</span> \\</span><br><span class=\"line\">      -p <span class=\"string\">\"14000:14000\"</span> \\</span><br><span class=\"line\">      -p <span class=\"string\">\"50070:50070\"</span> \\</span><br><span class=\"line\">      -p <span class=\"string\">\"50075:50075\"</span> \\</span><br><span class=\"line\">      -p <span class=\"string\">\"10020:10020\"</span> \\</span><br><span class=\"line\">      -p <span class=\"string\">\"13562:13562\"</span> \\</span><br><span class=\"line\">      -p <span class=\"string\">\"19888:19888\"</span> gradiant/hdfs-namenode</span><br><span class=\"line\"><span class=\"comment\"># 此处需要等待 hdfs-namenode 启动完毕后才执行如下命令</span></span><br><span class=\"line\">docker run -d --link hdfs-namenode --name hdfs-datanode1 -e CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:8020 gradiant/hdfs-datanode</span><br><span class=\"line\">docker run -d --link hdfs-namenode --name hdfs-datanode2 -e CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:8020 gradiant/hdfs-datanode</span><br><span class=\"line\">docker run -d --link hdfs-namenode --name hdfs-datanode3 -e CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:8020 gradiant/hdfs-datanode</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试：在 hdfs 中创建和列出示例文件夹</span></span><br><span class=\"line\">docker <span class=\"built_in\">exec</span> -ti hdfs-namenode hadoop fs -mkdir /hdfs <span class=\"comment\"># 在根目录下创建hdfs文件夹</span></span><br><span class=\"line\">docker <span class=\"built_in\">exec</span> -ti hdfs-namenode hadoop fs -mkdir -p /hdfs/d1/d2        <span class=\"comment\"># 创建多级目录</span></span><br><span class=\"line\">docker <span class=\"built_in\">exec</span> -ti hdfs-namenode hadoop fs -ls /        <span class=\"comment\"># 列出根目录下的文件列表</span></span><br><span class=\"line\">  <span class=\"comment\"># Found 1 items</span></span><br><span class=\"line\">  <span class=\"comment\"># drwxr-xr-x   - hdfs supergroup          0 2021-10-27 08:42 /hdfs</span></span><br><span class=\"line\"><span class=\"comment\"># HDFS 常规命令帮助</span></span><br><span class=\"line\">hadoop fs </span><br><span class=\"line\"><span class=\"comment\"># 创建单级、多级目录</span></span><br><span class=\"line\">hadoop fs -mkdir /hdfs</span><br><span class=\"line\">hadoop fs -mkdir -p /hdfs/d1/d2</span><br><span class=\"line\"><span class=\"comment\"># 上传文件到HDFS</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"hello world\"</span> &gt;&gt; local.txt   <span class=\"comment\">#创建文件</span></span><br><span class=\"line\">hadoop fs -put local.txt /hdfs/   <span class=\"comment\">#上传文件到hdfs</span></span><br><span class=\"line\"><span class=\"comment\"># 下载hdfs文件</span></span><br><span class=\"line\">hadoop fs -get /hdfs/local.txt</span><br><span class=\"line\"><span class=\"comment\"># 删除hdfs中的文件</span></span><br><span class=\"line\">hadoop fs -rm /hdfs/local.txt</span><br><span class=\"line\"><span class=\"comment\"># 删除hdfs中的目录</span></span><br><span class=\"line\">hadoop fs -rmdir /hdfs/d1/d2</span><br></pre></td></tr></table></figure></p>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211026174237.png\" alt=\"WeiyiGeek.docker-hdfsTest\" title=\"\" class=\"\">\n                <p>WeiyiGeek.docker-hdfsTest</p>\n            </figure>\n<hr>\n<p><strong>mysqlreader 快速使用说明与配置样例</strong></p>\n<ul>\n<li>(1) 关键参数&amp;类型转换:<blockquote>\n<p>jdbcUrl: 描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述，并支持一个库填写多个连接地址。<br>username: 数据源的用户名<br>password: 数据源指定用户名的密码<br>table: 所选取的需要同步的表,支持多张表同时抽取,用户自己需保证多张表是同一schema结构.<br>column: 所配置的表中需要同步的列名集合，用户使用*代表默认使用所有列配置，例如<code>[&#39;*&#39;]</code>一般不会采用此种方式。<br>where: 筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取,注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。<br>splitPk: 表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，使得提高数据同步的效能,<code>目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型</code><br>querySql: 用户可自定义定义筛选SQL, 此参数会忽略 table、column 、where 选项，其优先级最高</p>\n</blockquote>\n</li>\n</ul>\n<p>MysqlReader针对Mysql类型转换列表: (注意除下述罗列字段类型外，其他类型均不支持。)</p>\n<table>\n<thead>\n<tr>\n<th>DataX 内部类型</th>\n<th>Mysql 数据类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Long</td>\n<td>int, tinyint, smallint, mediumint, int, bigint</td>\n</tr>\n<tr>\n<td>Double</td>\n<td>float, double, decimal</td>\n</tr>\n<tr>\n<td>String</td>\n<td>varchar, char, tinytext, text, mediumtext, longtext, year</td>\n</tr>\n<tr>\n<td>Date</td>\n<td>date, datetime, timestamp, time</td>\n</tr>\n<tr>\n<td>Boolean</td>\n<td>bit, bool</td>\n</tr>\n<tr>\n<td>Bytes</td>\n<td>tinyblob, mediumblob, blob, longblob, varbinary</td>\n</tr>\n</tbody>\n</table>\n<p>重点注意:</p>\n<ul>\n<li><code>除上述罗列字段类型外，其他类型均不支持</code>。</li>\n<li><code>tinyint(1) DataX视作为整形</code>。</li>\n<li><code>year DataX视作为字符串类型</code></li>\n<li><code>bit DataX属于未定义行为</code>。</li>\n</ul>\n<p>Tips : mysqlreader 插件默认不支持MySQL8.X由于其 jdbc_driver_class驱动名称<code>&quot;com.mysql.cj.jdbc.Driver&quot;</code></p>\n<p><br/></p>\n<ul>\n<li>(2) 配置样例<br>(2.1) 配置一个从Mysql数据库同步抽取数据到本地的作业:<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tee job/mysql2stream.json &lt;&lt;<span class=\"string\">'EOF'</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"job\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"string\">\"content\"</span>: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">              <span class=\"string\">\"reader\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"mysqlreader\"</span>,</span><br><span class=\"line\">                  <span class=\"string\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                      <span class=\"string\">\"column\"</span>: [</span><br><span class=\"line\">                        <span class=\"string\">\"uid\"</span>,</span><br><span class=\"line\">                        <span class=\"string\">\"name\"</span>,</span><br><span class=\"line\">                        <span class=\"string\">\"operation_time\"</span></span><br><span class=\"line\">                      ],</span><br><span class=\"line\">                      <span class=\"string\">\"connection\"</span>: [</span><br><span class=\"line\">                          &#123;</span><br><span class=\"line\">                            <span class=\"string\">\"jdbcUrl\"</span>: [<span class=\"string\">\"jdbc:mysql://10.20.172.248:3305/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai\"</span>],</span><br><span class=\"line\">                            <span class=\"string\">\"table\"</span>: [<span class=\"string\">\"user\"</span>]</span><br><span class=\"line\">                          &#125;</span><br><span class=\"line\">                      ],</span><br><span class=\"line\">                      <span class=\"string\">\"username\"</span>: <span class=\"string\">\"test5\"</span>,</span><br><span class=\"line\">                      <span class=\"string\">\"password\"</span>: <span class=\"string\">\"weiyigeek.top\"</span>,</span><br><span class=\"line\">                      <span class=\"string\">\"where\"</span>: <span class=\"string\">\"uid &gt; 0\"</span></span><br><span class=\"line\">                  &#125;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              <span class=\"string\">\"writer\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">\"name\"</span>: <span class=\"string\">\"streamwriter\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"string\">\"print\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">                  <span class=\"string\">\"encoding\"</span>: <span class=\"string\">\"UTF-8\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"string\">\"setting\"</span>: &#123;</span><br><span class=\"line\">          <span class=\"string\">\"speed\"</span>: &#123;</span><br><span class=\"line\">              <span class=\"string\">\"channel\"</span>: <span class=\"string\">\"2\"</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n执行结果:<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2021-10-26 21:43:04.419 [0-0-0-reader] INFO  CommonRdbmsReader<span class=\"variable\">$Task</span> - Finished <span class=\"built_in\">read</span> record by Sql: [select uid,name,operation_time from user <span class=\"built_in\">where</span> (uid &gt; 0)] </span><br><span class=\"line\">jdbcUrl:[jdbc:mysql://********&amp;yearIsDateType=<span class=\"literal\">false</span>&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=<span class=\"literal\">false</span>&amp;rewriteBatchedStatements=<span class=\"literal\">true</span>].</span><br><span class=\"line\">1       WeiyiGeek       2021-10-12 14:34:03</span><br><span class=\"line\">2       Elastic 2021-10-12 17:16:34</span><br><span class=\"line\">3       Logstash        2021-10-12 17:16:59</span><br><span class=\"line\">4       Beats   2021-10-12 17:17:06</span><br><span class=\"line\">5       Kibana  2021-10-12 17:27:38</span><br><span class=\"line\">6       C       2021-10-13 02:43:30</span><br><span class=\"line\">7       C++     2021-10-13 10:44:59</span><br><span class=\"line\">8       Python  2021-10-13 10:48:45</span><br><span class=\"line\">.....</span><br><span class=\"line\">2021-10-26 21:43:04.497 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[103]ms</span><br><span class=\"line\">2021-10-26 21:43:14.393 [job-0] INFO  StandAloneJobContainerCommunicator - Total 8 records, 117 bytes | Speed 11B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%</span><br><span class=\"line\">2021-10-26 21:43:14.394 [job-0] INFO  JobContainer -</span><br><span class=\"line\">任务启动时刻                    : 2021-10-26 21:43:04</span><br><span class=\"line\">任务结束时刻                    : 2021-10-26 21:43:14</span><br><span class=\"line\">任务总计耗时                    :                 10s</span><br><span class=\"line\">任务平均流量                    :               11B/s</span><br><span class=\"line\">记录写入速度                    :              0rec/s</span><br><span class=\"line\">读出记录总数                    :                   8</span><br><span class=\"line\">读写失败总数                    :                   0</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><br/></p>\n<p>(2.2) 配置一个自定义SQL的数据库同步任务到本地内容的作业：<br><figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat job/mysql2stream1.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"job\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"content\"</span>: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">              <span class=\"attr\">\"reader\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"mysqlreader\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                      <span class=\"attr\">\"connection\"</span>: [</span><br><span class=\"line\">                          &#123;</span><br><span class=\"line\">                            <span class=\"attr\">\"jdbcUrl\"</span>: [<span class=\"string\">\"jdbc:mysql://10.20.172.248:3305/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai\"</span>],</span><br><span class=\"line\">                            <span class=\"attr\">\"querySql\"</span>: [<span class=\"string\">\"select uid,name,hobby,operation_time from user where (uid &gt; 3);\"</span>],</span><br><span class=\"line\">                          &#125;</span><br><span class=\"line\">                      ],</span><br><span class=\"line\">                      <span class=\"attr\">\"username\"</span>: <span class=\"string\">\"test5\"</span>,</span><br><span class=\"line\">                      <span class=\"attr\">\"password\"</span>: <span class=\"string\">\"weiyigeek.top\"</span>,</span><br><span class=\"line\">                  &#125;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              <span class=\"attr\">\"writer\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"streamwriter\"</span>,</span><br><span class=\"line\">                <span class=\"attr\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"attr\">\"print\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"encoding\"</span>: <span class=\"string\">\"UTF-8\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"setting\"</span>: &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"speed\"</span>: &#123;</span><br><span class=\"line\">              <span class=\"attr\">\"channel\"</span>: <span class=\"string\">\"1\"</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>执行结果:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 执行SQL与Jdbc URL</span></span><br><span class=\"line\">2021-10-26 21:50:58.904 [0-0-0-reader] INFO  CommonRdbmsReader<span class=\"variable\">$Task</span> - Finished <span class=\"built_in\">read</span> record by Sql: [select uid,name,hobby,operation_time from user <span class=\"built_in\">where</span> (uid &gt; 3);] </span><br><span class=\"line\">jdbcUrl:[jdbc:mysql://*******&amp;rewriteBatchedStatements=<span class=\"literal\">true</span>].</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印查询到的数据到终端中 </span></span><br><span class=\"line\">4       Beats   通用日志采集    2021-10-12 17:17:06</span><br><span class=\"line\">5       Kibana  数据分析,日志搜寻,日志数据展示,可视化   2021-10-12 17:27:38</span><br><span class=\"line\">6       C       面向过程编程语言        2021-10-13 02:43:30</span><br><span class=\"line\">7       C++     面向对象        2021-10-13 10:44:59</span><br><span class=\"line\">8       Python  编程语言        2021-10-13 10:48:45</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 任务执行结果统计</span></span><br><span class=\"line\">2021-10-26 21:51:08.877 [job-0] INFO  JobContainer -</span><br><span class=\"line\">任务启动时刻                    : 2021-10-26 21:50:58</span><br><span class=\"line\">任务结束时刻                    : 2021-10-26 21:51:08</span><br><span class=\"line\">任务总计耗时                    :                 10s</span><br><span class=\"line\">任务平均流量                    :               10B/s</span><br><span class=\"line\">记录写入速度                    :              0rec/s</span><br><span class=\"line\">读出记录总数                    :                   5</span><br><span class=\"line\">读写失败总数                    :                   0</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p><strong>hdfswriter 快速使用说明与配置样例</strong></p>\n<ul>\n<li>(1) 关键参数&amp;类型转换: HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。<blockquote>\n<p>defaultFS：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口<br>fileType: 文件的类型，目前只支持用户配置为”text”(textfile文件格式)或”orc”(orc表示orcfile文件格式)。<br>path: 存储到Hadoop hdfs文件系统的路径信息，HdfsWriter会根据并发配置在Path目录下写入多个文件<br>fileName: HdfsWriter写入时的文件名，实际执行时会在该文件名后添加随机的后缀作为每个线程写入实际文件名。<br>column: 写入数据的字段，不支持对部分列写入。为与hive中表关联，需要指定表中所有字段名和字段类型。<br>writeMode: 写入前数据清理处理模式,append 写入前不做任何处理, onConflict，如果目录下有fileName前缀的文件，直接报错。<br>fieldDelimiter: 写入时的字段分隔符,需要用户保证与创建的Hive表的字段分隔符一致，否则无法在Hive表中查到数据<br>compress: 写入文件压缩类型，默认没有压缩。其中：text类型文件支持压缩类型有gzip、bzip2;orc类型文件支持的压缩类型有NONE、SNAPPY（需要用户安装SnappyCodec）。<br>encoding: 写文件的编码配置, 默认值 utf-8 慎重修改。<br>haveKerberos : 是否有Kerberos认证默认false,如果为True则配置项<code>kerberosKeytabFilePath，kerberosPrincipal</code>为必填。<br>kerberosKeytabFilePath: Kerberos认证 keytab文件路径，绝对路径<br>kerberosPrincipal: Kerberos认证Principal名，如<a href=\"mailto:xxxx/hadoopclient@xxx.xxx\">xxxx/hadoopclient@xxx.xxx</a><br>hadoopConfig: HadoopConfig 高级HA配置:</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 名称空间: testDfs</span><br><span class=\"line\">\"hadoopConfig\":&#123;</span><br><span class=\"line\">  \"dfs.nameservices\": \"testDfs\",</span><br><span class=\"line\">  \"dfs.ha.namenodes.testDfs\": \"namenode1,namenode2\",</span><br><span class=\"line\">  \"dfs.namenode.rpc-address.aliDfs.namenode1\": \"主机名:端口\",</span><br><span class=\"line\">  \"dfs.namenode.rpc-address.aliDfs.namenode2\": \"主机名:端口\",</span><br><span class=\"line\">  \"dfs.client.failover.proxy.provider.testDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\"</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</blockquote>\n</li>\n</ul>\n<p>HdfsWriter 针对 Hive 数据类型转换列表:<br>| DataX 内部类型| HIVE 数据类型    |<br>| ——– | —–  |<br>| Long     |TINYINT,SMALLINT,INT,BIGINT |<br>| Double   |FLOAT,DOUBLE |<br>| String   |STRING,VARCHAR,CHAR |<br>| Boolean  |BOOLEAN |<br>| Date     |DATE,TIMESTAMP |</p>\n<p><br/></p>\n<ul>\n<li>(2) 配置样例<br>(2.1) 从MySQL同步数据HDFS中实例演示:<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 示例生成</span><br><span class=\"line\">bin/datax.py -r mysqlreader -w hdfswriter &gt; mysql2hdfs.json</span><br><span class=\"line\"></span><br><span class=\"line\">// 最终示例</span><br><span class=\"line\">tee job/mysql2hdfs3.json &lt;&lt;'EOF'</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"job\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"content\"</span>: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">              <span class=\"attr\">\"reader\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"mysqlreader\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                      <span class=\"attr\">\"connection\"</span>: [</span><br><span class=\"line\">                          &#123;</span><br><span class=\"line\">                            <span class=\"attr\">\"jdbcUrl\"</span>: [<span class=\"string\">\"jdbc:mysql://10.20.172.248:3305/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai\"</span>],</span><br><span class=\"line\">                            <span class=\"attr\">\"querySql\"</span>: [<span class=\"string\">\"select uid,name,hobby,operation_time from user where (uid &gt; 3);\"</span>],</span><br><span class=\"line\">                          &#125;</span><br><span class=\"line\">                      ],</span><br><span class=\"line\">                      <span class=\"attr\">\"username\"</span>: <span class=\"string\">\"test5\"</span>,</span><br><span class=\"line\">                      <span class=\"attr\">\"password\"</span>: <span class=\"string\">\"weiyigeek.top\"</span>,</span><br><span class=\"line\">                  &#125;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              <span class=\"attr\">\"writer\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"hdfswriter\"</span>,</span><br><span class=\"line\">                <span class=\"attr\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"attr\">\"column\"</span>: [</span><br><span class=\"line\">                    &#123;<span class=\"attr\">\"name\"</span>:<span class=\"string\">\"uid\"</span>,<span class=\"attr\">\"type\"</span>:<span class=\"string\">\"Long\"</span>&#125;,</span><br><span class=\"line\">                    &#123;<span class=\"attr\">\"name\"</span>:<span class=\"string\">\"name\"</span>,<span class=\"attr\">\"type\"</span>:<span class=\"string\">\"string\"</span>&#125;,</span><br><span class=\"line\">                    &#123;<span class=\"attr\">\"name\"</span>:<span class=\"string\">\"hobby\"</span>,<span class=\"attr\">\"type\"</span>:<span class=\"string\">\"string\"</span>&#125;,</span><br><span class=\"line\">                    &#123;<span class=\"attr\">\"name\"</span>:<span class=\"string\">\"operation_time\"</span>,<span class=\"attr\">\"type\"</span>:<span class=\"string\">\"Date\"</span>&#125;,</span><br><span class=\"line\">                  ],</span><br><span class=\"line\">                  <span class=\"attr\">\"compress\"</span>: <span class=\"string\">\"gzip\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"defaultFS\"</span>: <span class=\"string\">\"hdfs://10.10.107.225:8020\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"fieldDelimiter\"</span>: <span class=\"string\">\"|\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"fileName\"</span>: <span class=\"string\">\"mysql-test-user\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"fileType\"</span>: <span class=\"string\">\"test\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"path\"</span>: <span class=\"string\">\"/hdfs\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"writeMode\"</span>: <span class=\"string\">\"append\"</span>,</span><br><span class=\"line\">                  <span class=\"attr\">\"encoding\"</span>: <span class=\"string\">\"UTF-8\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"setting\"</span>: &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"speed\"</span>: &#123;</span><br><span class=\"line\">              <span class=\"attr\">\"channel\"</span>: <span class=\"string\">\"1\"</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>执行结果:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/usr/<span class=\"built_in\">local</span>/datax<span class=\"comment\"># ./bin/datax.py job/mysql2hdfsjson</span></span><br><span class=\"line\"><span class=\"comment\"># 插件加载</span></span><br><span class=\"line\">2021-10-27 18:25:25.794 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] <span class=\"keyword\">do</span> prepare work .</span><br><span class=\"line\">2021-10-27 18:25:25.794 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] <span class=\"keyword\">do</span> prepare work .</span><br><span class=\"line\">2021-10-27 18:25:25.853 [job-0] INFO  HdfsWriter<span class=\"variable\">$Job</span> - 由于您配置了writeMode append, 写入前不做清理工作, [/] 目录下写入相应文件名前缀  [mysql-test-user] 的文件</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># mysqlreader 开始执行SQL读取数据</span></span><br><span class=\"line\">2021-10-27 18:25:25.895 [0-0-0-reader] INFO  CommonRdbmsReader<span class=\"variable\">$Task</span> - Begin to <span class=\"built_in\">read</span> record by Sql、</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hdfswriter 准备将数据写入到临时目录和文件中</span></span><br><span class=\"line\">2021-10-27 18:25:25.910 [0-0-0-writer] INFO  HdfsWriter<span class=\"variable\">$Task</span> - begin <span class=\"keyword\">do</span> write...</span><br><span class=\"line\">2021-10-27 18:25:25.911 [0-0-0-writer] INFO  HdfsWriter<span class=\"variable\">$Task</span> - write to file : [hdfs://10.10.107.225:8020/__5a361c9b_5a1b_413f_aec9_d074058f0c82/mysql-test-user__f9ea0b07_9023_46f5_9f3a_dd42244bfdd8]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># mysqlreader 读取完成</span></span><br><span class=\"line\">2021-10-27 18:25:25.923 [0-0-0-reader] INFO  CommonRdbmsReader<span class=\"variable\">$Task</span> - Finished <span class=\"built_in\">read</span> record by Sql</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hdfswriter 将写入的临时文件进行重命名`mysql-test-user__f9ea0b07_9023_46f5_9f3a_dd42244bfdd8.gz`并删除临时目录和文件</span></span><br><span class=\"line\">2021-10-27 18:25:35.885 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] <span class=\"keyword\">do</span> post work.</span><br><span class=\"line\">2021-10-27 18:25:35.885 [job-0] INFO  HdfsWriter<span class=\"variable\">$Job</span> - start rename file [hdfs://10.10.107.225:8020/__5a361c9b_5a1b_413f_aec9_d074058f0c82/mysql-test-user__f9ea0b07_9023_46f5_9f3a_dd42244bfdd8.gz] to file [hdfs://10.10.107.225:8020/mysql-test-user__f9ea0b07_9023_46f5_9f3a_dd42244bfdd8.gz].</span><br><span class=\"line\">2021-10-27 18:25:35.902 [job-0] INFO  HdfsWriter<span class=\"variable\">$Job</span> - finish rename file [hdfs://10.10.107.225:8020/__5a361c9b_5a1b_413f_aec9_d074058f0c82/mysql-test-user__f9ea0b07_9023_46f5_9f3a_dd42244bfdd8.gz] to file [hdfs://10.10.107.225:8020/mysql-test-user__f9ea0b07_9023_46f5_9f3a_dd42244bfdd8.gz].</span><br><span class=\"line\">2021-10-27 18:25:35.902 [job-0] INFO  HdfsWriter<span class=\"variable\">$Job</span> - start delete tmp dir [hdfs://10.10.107.225:8020/__5a361c9b_5a1b_413f_aec9_d074058f0c82] .</span><br><span class=\"line\">2021-10-27 18:25:35.911 [job-0] INFO  HdfsWriter<span class=\"variable\">$Job</span> - finish delete tmp dir [hdfs://10.10.107.225:8020/__5a361c9b_5a1b_413f_aec9_d074058f0c82] .</span><br><span class=\"line\">2021-10-27 18:25:35.912 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 结果统计</span></span><br><span class=\"line\">任务启动时刻                    : 2021-10-27 18:25:24</span><br><span class=\"line\">任务结束时刻                    : 2021-10-27 18:25:36</span><br><span class=\"line\">任务总计耗时                    :                 11s</span><br><span class=\"line\">任务平均流量                    :                6B/s</span><br><span class=\"line\">记录写入速度                    :              0rec/s</span><br><span class=\"line\">读出记录总数                    :                   5</span><br><span class=\"line\">读写失败总数                    :                   0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 从HDFS中读取插入的text数据</span></span><br><span class=\"line\">$ docker inspect hdfs-datanode1 | grep <span class=\"string\">'\"IPAddress\"'</span> | head -n 1</span><br><span class=\"line\"><span class=\"string\">\"IPAddress\"</span>: <span class=\"string\">\"172.17.0.3\"</span>,</span><br><span class=\"line\"></span><br><span class=\"line\">$ curl <span class=\"string\">\"http://172.17.0.3:50075/webhdfs/v1/mysql-test-user__7630c0e0_d169_43cf_a808_272ad7d907bc?op=OPEN&amp;namenoderpcaddress=0f3e052efe21:8020&amp;offset=0\"</span></span><br><span class=\"line\">4|Beats|通用日志采集</span><br><span class=\"line\">5|Kibana|数据分析,日志搜寻,日志数据展示,可视化</span><br><span class=\"line\">6|C|面向过程编程语言</span><br><span class=\"line\">7|C++|面向对象</span><br><span class=\"line\">8|Python|编程语言</span><br></pre></td></tr></table></figure></p>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/5/20211027191426.png\" alt=\"WeiyiGeek.WriteDataHDFSResult\" title=\"\" class=\"\">\n                <p>WeiyiGeek.WriteDataHDFSResult</p>\n            </figure>\n<p>Tips : 总结Datax针对HDFS的写入流程，首先将数据写入到一个临时文件，如果全部成功<code>则重命名(移动)</code>临时文件名、并删除临时目录。如果个别数据失败则Job任务失败，删除临时目录和临时文件。<br>Tips : 从上面结果可以看出HDFS实际执行时会在该文件名后添加随机的后缀作为每个线程的实际写入文件名。</p>\n<hr>\n<h3 id=\"2-HDFS-To-MySQL\"><a href=\"#2-HDFS-To-MySQL\" class=\"headerlink\" title=\"2.HDFS-To-MySQL\"></a>2.HDFS-To-MySQL</h3><p><strong>hdfsreader 快速使用说明与配置样例</strong></p>\n<ul>\n<li>(1) 快速介绍和参数说明<br>HdfsReader支持的文件格式有<code>textfile（text）、orcfile（orc）、rcfile（rc）、sequence file（seq）和普通逻辑二维表（csv）</code>类型格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表。</li>\n</ul>\n<p>参数说明:</p>\n<blockquote>\n<p>path: 要读取的文件路径，如果要读取多个文件，可以使用正则表达式”<em>“，注意这里可以支持填写多个路径,比如需要读取表名叫mytable01下分区day为20150820这一天的所有数据，则配置如下：`”path”: “/user/hive/warehouse/mytable01/20150820/</em>“<code>defaultFS: Hadoop hdfs文件系统namenode节点地址\nfileType: 文件的类型，目前只支持用户配置为</code>“text”、”orc”、”rc”、”seq”、”csv”<code>column: 读取字段列表，type指定源数据的类型，index指定当前列来自于文本第几列(以0开始)，value指定当前类型为常量，如</code>{ “type”: “long”, “index”: 0}, { “type”: “string”, “value”: “alibaba”}`<br>fieldDelimiter: 读取的字段分隔符<br>encoding: 读取文件的编码配置<br>nullFormat: 文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。<br>haveKerberos:是否有Kerberos认证，默认false,例如如果用户配置true，则配置项kerberosKeytabFilePath，kerberosPrincipal为必填。<br>kerberosKeytabFilePath: Kerberos认证 keytab文件路径，绝对路径<br>kerberosPrincipal: Kerberos认证Principal名，如<a href=\"mailto:xxxx/hadoopclient@xxx.xxx\">xxxx/hadoopclient@xxx.xxx</a><br>compress: 当fileType（文件类型）为csv下的文件压缩方式，目前仅支持 gzip、bz2、zip、lzo、lzo_deflate、hadoop-snappy、framing-snappy压缩；<br>csvReaderConfig: 取CSV类型文件参数配置，Map类型。读取CSV类型文件使用的CsvReader进行读取，会有很多配置，不配置则使用默认值。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"csvReaderConfig\"</span>:&#123;</span><br><span class=\"line\">  <span class=\"string\">\"safetySwitch\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">  <span class=\"string\">\"skipEmptyRecords\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">  <span class=\"string\">\"useTextQualifier\"</span>: <span class=\"literal\">false</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 所有配置项及默认值,配置时 csvReaderConfig 的map中请严格按照以下字段名字进行配置：</span></span><br><span class=\"line\">boolean caseSensitive = <span class=\"literal\">true</span>;</span><br><span class=\"line\">char textQualifier = 34;</span><br><span class=\"line\">boolean trimWhitespace = <span class=\"literal\">true</span>;</span><br><span class=\"line\">boolean useTextQualifier = <span class=\"literal\">true</span>;//是否使用csv转义字符</span><br><span class=\"line\">char delimiter = 44;//分隔符</span><br><span class=\"line\">char recordDelimiter = 0;</span><br><span class=\"line\">char comment = 35;</span><br><span class=\"line\">boolean useComments = <span class=\"literal\">false</span>;</span><br><span class=\"line\">int escapeMode = 1;</span><br><span class=\"line\">boolean safetySwitch = <span class=\"literal\">true</span>;//单列长度是否限制100000字符</span><br><span class=\"line\">boolean skipEmptyRecords = <span class=\"literal\">true</span>;//是否跳过空行</span><br><span class=\"line\">boolean captureRawRecord = <span class=\"literal\">true</span>;</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p><br/></p>\n<p>HdfsReader提供了类型转换的建议表如下：</p>\n<table>\n<thead>\n<tr>\n<th>DataX 内部类型</th>\n<th>Hive表 数据类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Long</td>\n<td>TINYINT,SMALLINT,INT,BIGINT</td>\n</tr>\n<tr>\n<td>Double</td>\n<td>FLOAT,DOUBLE</td>\n</tr>\n<tr>\n<td>String</td>\n<td>String,CHAR,VARCHAR,STRUCT,MAP,ARRAY,UNION,BINARY</td>\n</tr>\n<tr>\n<td>Boolean</td>\n<td>BOOLEAN</td>\n</tr>\n<tr>\n<td>Date</td>\n<td>Date,TIMESTAMP</td>\n</tr>\n</tbody>\n</table>\n<p>其中：</p>\n<ul>\n<li>Long是指Hdfs文件文本中使用整形的字符串表示形式，例如”123456789”。</li>\n<li>Double是指Hdfs文件文本中使用Double的字符串表示形式，例如”3.1415”。</li>\n<li>Boolean是指Hdfs文件文本中使用Boolean的字符串表示形式，例如”true”、”false”。不区分大小写。</li>\n<li>Date是指Hdfs文件文本中使用Date的字符串表示形式，例如”2014-12-31”。</li>\n</ul>\n<p>特别提醒：</p>\n<ul>\n<li>Hive支持的数据类型TIMESTAMP可以精确到纳秒级别，所以textfile、orcfile中TIMESTAMP存放的数据类似于”2015-08-21 22:40:47.397898389”，如果转换的类型配置为DataX的Date，转换之后会导致纳秒部分丢失，所以如果需要保留纳秒部分的数据，请配置转换类型为DataX的String类型。</li>\n</ul>\n<p>Tips: 目前HdfsReader不支持对Hive元数据数据库进行访问查询，因此用户在进行类型转换的时候，必须指定数据类型，<code>如果用户配置的column为&quot;*&quot;，则所有column默认转换为string类型</code>。</p>\n<p><br/></p>\n<p><strong>mysqlwriter 快速使用说明与配置样例</strong></p>\n<ul>\n<li>(1) 描述: 我们使用 MysqlWriter 从数仓导入数据到 Mysql，同时 MysqlWriter 亦可以作为数据迁移工具为DBA等用户提供服务。</li>\n</ul>\n<p>MysqlWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置的 writeMode 生成<code>insert into...(当主键/唯一性索引冲突时会写不进去冲突的行)</code>或者<code>replace into...(没有遇到主键/唯一性索引冲突时</code>，与 insert into 行为一致，冲突时会用新行替换原有行所有字段) 的语句写入数据到 Mysql。</p>\n<p>MysqlWriter 可用参数: </p>\n<blockquote>\n<p>jdbcUrl: 目的数据库的 JDBC 连接信息。<br>username: 目的数据库的用户名。<br>password: 目的数据库的密码。<br>table: 目的表的表名称。<code>注意：table 和 jdbcUrl 必须包含在 connection 配置单元中</code><br>column: 目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: “column”: [“id”,”name”,”age”]。如果要依次写入全部列，使用<em>表示, 例如: “column”: `[“</em>“]`。<br>session: DataX在获取Mysql连接时，执行session指定的SQL语句，修改当前connection session属性。<br>preSql: 写入数据到目的表前，会先执行这里的标准语句<br>postSql: 写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ）<br>writeMode: 控制写入数据到目标表采用 insert into 或者 replace into 或者 ON DUPLICATE KEY UPDATE 语句<br>batchSize: 一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。</p>\n</blockquote>\n<p>MysqlWriter 针对 Mysql 类型转换列表: <code>Long、Double、String、Date、Boolean、Bytes</code> 与Mysqlreader插件是一致的。</p>\n<p><br/></p>\n<p><strong>配置示例演示</strong></p>\n<ul>\n<li>(1) 从HDFS同步数据到MySQL中实例演示:<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 操作重命名hadoop中指定文件名称</span></span><br><span class=\"line\">/usr/<span class=\"built_in\">local</span>/datax<span class=\"comment\"># docker exec -it hdfs-namenode hadoop fs -mv /mysql-test-user__7630c0e0_d169_43cf_a808_272ad7d907bc /mysql-test-user.txt</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 数据库表窗口</span></span><br><span class=\"line\">mysql&gt; CREATE TABLE IF NOT EXISTS test.hdfsreader like test.user;</span><br><span class=\"line\">Query OK, 0 rows affected (0.48 sec)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 表结构</span></span><br><span class=\"line\">mysql&gt; DESC test.hdfsreader;</span><br><span class=\"line\">+----------------+--------------+------+-----+---------+-----------------------------+</span><br><span class=\"line\">| Field          | Type         | Null | Key | Default | Extra                       |</span><br><span class=\"line\">+----------------+--------------+------+-----+---------+-----------------------------+</span><br><span class=\"line\">| uid            | int(11)      | NO   | PRI | NULL    | auto_increment              |</span><br><span class=\"line\">| name           | varchar(32)  | NO   |     | NULL    |                             |</span><br><span class=\"line\">| hobby          | varchar(255) | NO   |     | NULL    |                             |</span><br><span class=\"line\">| operation_time | datetime     | YES  |     | NULL    | on update CURRENT_TIMESTAMP |</span><br><span class=\"line\">+----------------+--------------+------+-----+---------+-----------------------------+</span><br><span class=\"line\">4 rows <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.03 sec)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hdfsreader =&gt;&gt; mysqlwriter 示例文件生成</span></span><br><span class=\"line\">$ bin/datax.py -r hdfsreader -w mysqlwriter</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 最终的Job配置</span></span><br><span class=\"line\">tee job/hdfs2mysql.json &lt;&lt;<span class=\"string\">'EOF'</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"job\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"content\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"string\">\"reader\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">\"name\"</span>: <span class=\"string\">\"hdfsreader\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">\"column\"</span>: [</span><br><span class=\"line\">                       &#123;<span class=\"string\">\"index\"</span>:1,<span class=\"string\">\"type\"</span>:<span class=\"string\">\"string\"</span>&#125;,</span><br><span class=\"line\">                       &#123;<span class=\"string\">\"index\"</span>:2,<span class=\"string\">\"type\"</span>:<span class=\"string\">\"string\"</span>&#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"defaultFS\"</span>: <span class=\"string\">\"hdfs://10.10.107.225:8020\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"encoding\"</span>: <span class=\"string\">\"UTF-8\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"fieldDelimiter\"</span>: <span class=\"string\">\"|\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"fileType\"</span>: <span class=\"string\">\"text\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"path\"</span>: <span class=\"string\">\"/mysql-test-user.txt\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            <span class=\"string\">\"writer\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">\"name\"</span>: <span class=\"string\">\"mysqlwriter\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">\"column\"</span>: [</span><br><span class=\"line\">                      <span class=\"string\">\"name\"</span>,</span><br><span class=\"line\">                      <span class=\"string\">\"hobby\"</span></span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"connection\"</span>: [</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"string\">\"jdbcUrl\"</span>: <span class=\"string\">\"jdbc:mysql://10.20.172.248:3305/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai\"</span>,</span><br><span class=\"line\">                        <span class=\"string\">\"table\"</span>: [<span class=\"string\">\"hdfsreader\"</span>]</span><br><span class=\"line\">                      &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"username\"</span>: <span class=\"string\">\"test5\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"password\"</span>: <span class=\"string\">\"weiyigeek.top\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"writeMode\"</span>: <span class=\"string\">\"insert\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"setting\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"speed\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"string\">\"channel\"</span>: <span class=\"string\">\"1\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>执行结果:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/datax.py job/hdfs2mysql.json</span><br><span class=\"line\"><span class=\"comment\"># - 获取的列</span></span><br><span class=\"line\">2021-10-27 23:20:44.255 [job-0] INFO  OriginalConfPretreatmentUtil - table:[hdfsreader] all columns:[uid,name,hobby,operation_time].</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># - SQL语句生成</span></span><br><span class=\"line\">2021-10-27 23:20:44.277 [job-0] INFO  OriginalConfPretreatmentUtil - Write data [insert INTO %s (name,hobby) VALUES(?,?)], <span class=\"built_in\">which</span> jdbcUrl like:[jdbc:mysql://10.20.172.248:3305/<span class=\"built_in\">test</span>?useSSL=<span class=\"literal\">false</span>&amp;useUnicode=<span class=\"literal\">true</span>&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai&amp;yearIsDateType=<span class=\"literal\">false</span>&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=<span class=\"literal\">false</span>&amp;rewriteBatchedStatements=<span class=\"literal\">true</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># - 读取HDFS中指定的mysql-test-user.txt文件</span></span><br><span class=\"line\">2021-10-27 23:20:44.763 [job-0] INFO  HdfsReader<span class=\"variable\">$Job</span> - [hdfs://10.10.107.225:8020/mysql-test-user.txt]是[text]类型的文件, 将该文件加入<span class=\"built_in\">source</span> files列表</span><br><span class=\"line\">2021-10-27 23:20:44.764 [job-0] INFO  HdfsReader<span class=\"variable\">$Job</span> - 您即将读取的文件数为: [1], 列表为: [hdfs://10.10.107.225:8020/mysql-test-user.txt]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># - 读取开始</span></span><br><span class=\"line\">2021-10-27 23:20:44.818 [0-0-0-reader] INFO  Reader<span class=\"variable\">$Task</span> - <span class=\"built_in\">read</span> start</span><br><span class=\"line\">2021-10-27 23:20:44.818 [0-0-0-reader] INFO  Reader<span class=\"variable\">$Task</span> - reading file : [hdfs://10.10.107.225:8020/mysql-test-user.txt]</span><br><span class=\"line\">2021-10-27 23:20:44.833 [0-0-0-reader] INFO  UnstructuredStorageReaderUtil - CsvReader使用默认值[&#123;<span class=\"string\">\"captureRawRecord\"</span>:<span class=\"literal\">true</span>,<span class=\"string\">\"columnCount\"</span>:0,<span class=\"string\">\"comment\"</span>:<span class=\"string\">\"#\"</span>,<span class=\"string\">\"currentRecord\"</span>:-1,<span class=\"string\">\"delimiter\"</span>:<span class=\"string\">\"|\"</span>,<span class=\"string\">\"escapeMode\"</span>:1,<span class=\"string\">\"headerCount\"</span>:0,<span class=\"string\">\"rawRecord\"</span>:<span class=\"string\">\"\"</span>,<span class=\"string\">\"recordDelimiter\"</span>:<span class=\"string\">\"\\u0000\"</span>,<span class=\"string\">\"safetySwitch\"</span>:<span class=\"literal\">false</span>,<span class=\"string\">\"skipEmptyRecords\"</span>:<span class=\"literal\">true</span>,<span class=\"string\">\"textQualifier\"</span>:<span class=\"string\">\"\\\"\"</span>,<span class=\"string\">\"trimWhitespace\"</span>:<span class=\"literal\">true</span>,<span class=\"string\">\"useComments\"</span>:<span class=\"literal\">false</span>,<span class=\"string\">\"useTextQualifier\"</span>:<span class=\"literal\">true</span>,<span class=\"string\">\"values\"</span>:[]&#125;],csvReaderConfig值为[null]</span><br><span class=\"line\">2021-10-27 23:20:44.836 [0-0-0-reader] INFO  Reader<span class=\"variable\">$Task</span> - end <span class=\"built_in\">read</span> <span class=\"built_in\">source</span> files...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># - 执行结果</span></span><br><span class=\"line\">任务启动时刻                    : 2021-10-27 23:20:43</span><br><span class=\"line\">任务结束时刻                    : 2021-10-27 23:20:54</span><br><span class=\"line\">任务总计耗时                    :                 10s</span><br><span class=\"line\">任务平均流量                    :                6B/s</span><br><span class=\"line\">记录写入速度                    :              0rec/s</span><br><span class=\"line\">读出记录总数                    :                   5</span><br><span class=\"line\">读写失败总数                    :                   0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># - 查看写入表的数据。</span></span><br><span class=\"line\">mysql&gt; select * from test.hdfsreader;</span><br><span class=\"line\">+-----+--------+---------------------------------------+----------------+</span><br><span class=\"line\">| uid | name   | hobby                                 | operation_time |</span><br><span class=\"line\">+-----+--------+---------------------------------------+----------------+</span><br><span class=\"line\">|   1 | Beats  | 通用日志采集                          | NULL           |</span><br><span class=\"line\">|   2 | Kibana | 数据分析,日志搜寻,日志数据展示,可视化 | NULL           |</span><br><span class=\"line\">|   3 | C      | 面向过程编程语言                      | NULL           |</span><br><span class=\"line\">|   4 | C++    | 面向对象                              | NULL           |</span><br><span class=\"line\">|   5 | Python | 编程语言                              | NULL           |</span><br><span class=\"line\">+-----+--------+---------------------------------------+----------------+</span><br><span class=\"line\">5 rows <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.04 sec)</span><br></pre></td></tr></table></figure></p>\n<p><br> </p>\n<ul>\n<li>(2) 从MySQL中读取并写入到指定表之中。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 表示创建</span></span><br><span class=\"line\">create TABLE <span class=\"keyword\">if</span> not EXISTS mysqlwriter LIKE hdfsreader;</span><br><span class=\"line\"><span class=\"comment\"># 示例生成</span></span><br><span class=\"line\">bin/datax.py -r mysqlreader -w mysqlwriter</span><br><span class=\"line\"><span class=\"comment\"># job任务配置 </span></span><br><span class=\"line\">tee job/mysql2mysql.json &lt;&lt;<span class=\"string\">'EOF'</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"job\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"string\">\"content\"</span>: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">              <span class=\"string\">\"reader\"</span>: &#123;</span><br><span class=\"line\">                  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"mysqlreader\"</span>,</span><br><span class=\"line\">                  <span class=\"string\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                      <span class=\"string\">\"connection\"</span>: [</span><br><span class=\"line\">                          &#123;</span><br><span class=\"line\">                            <span class=\"string\">\"jdbcUrl\"</span>: [<span class=\"string\">\"jdbc:mysql://10.20.172.248:3305/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai\"</span>],</span><br><span class=\"line\">                            <span class=\"string\">\"querySql\"</span>: [<span class=\"string\">\"select name,hobby,operation_time from user where (uid &gt; 5);\"</span>],</span><br><span class=\"line\">                          &#125;</span><br><span class=\"line\">                      ],</span><br><span class=\"line\">                      <span class=\"string\">\"username\"</span>: <span class=\"string\">\"test5\"</span>,</span><br><span class=\"line\">                      <span class=\"string\">\"password\"</span>: <span class=\"string\">\"weiyigeek.top\"</span>,</span><br><span class=\"line\">                  &#125;</span><br><span class=\"line\">              &#125;,</span><br><span class=\"line\">              <span class=\"string\">\"writer\"</span>: &#123;</span><br><span class=\"line\">                <span class=\"string\">\"name\"</span>: <span class=\"string\">\"mysqlwriter\"</span>,</span><br><span class=\"line\">                <span class=\"string\">\"parameter\"</span>: &#123;</span><br><span class=\"line\">                    <span class=\"string\">\"column\"</span>: [</span><br><span class=\"line\">                      <span class=\"string\">\"name\"</span>,</span><br><span class=\"line\">                      <span class=\"string\">\"hobby\"</span>,</span><br><span class=\"line\">                      <span class=\"string\">\"operation_time\"</span></span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"connection\"</span>: [</span><br><span class=\"line\">                      &#123;</span><br><span class=\"line\">                        <span class=\"string\">\"jdbcUrl\"</span>: <span class=\"string\">\"jdbc:mysql://10.20.172.248:3305/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai\"</span>,</span><br><span class=\"line\">                        <span class=\"string\">\"table\"</span>: [<span class=\"string\">\"mysqlwriter\"</span>]</span><br><span class=\"line\">                      &#125;</span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"session\"</span>: [</span><br><span class=\"line\">                      <span class=\"string\">\"set session sql_mode='ANSI'\"</span></span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"preSql\"</span>: [</span><br><span class=\"line\">                        <span class=\"string\">\"delete from mysqlwriter\"</span></span><br><span class=\"line\">                    ],</span><br><span class=\"line\">                    <span class=\"string\">\"username\"</span>: <span class=\"string\">\"test5\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"password\"</span>: <span class=\"string\">\"weiyigeek.top\"</span>,</span><br><span class=\"line\">                    <span class=\"string\">\"writeMode\"</span>: <span class=\"string\">\"insert\"</span></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">              &#125;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"string\">\"setting\"</span>: &#123;</span><br><span class=\"line\">          <span class=\"string\">\"speed\"</span>: &#123;</span><br><span class=\"line\">              <span class=\"string\">\"channel\"</span>: <span class=\"string\">\"1\"</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n<p>执行结果:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -MysqlWriter 写入的字段以及SQL</span></span><br><span class=\"line\">2021-10-28 09:57:05.554 [job-0] INFO  OriginalConfPretreatmentUtil - table:[mysqlwriter] all columns:[uid,name,hobby,operation_time].</span><br><span class=\"line\">2021-10-28 09:57:05.582 [job-0] INFO  OriginalConfPretreatmentUtil - Write data [</span><br><span class=\"line\">insert INTO %s (name,hobby,operation_time) VALUES(?,?,?)</span><br><span class=\"line\">], <span class=\"built_in\">which</span> jdbcUrl like:[jdbc:mysql://10.20.172.248:3305/<span class=\"built_in\">test</span>?useSSL=<span class=\"literal\">false</span>&amp;useUnicode=<span class=\"literal\">true</span>&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai&amp;yearIsDateType=<span class=\"literal\">false</span>&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=<span class=\"literal\">false</span>&amp;rewriteBatchedStatements=<span class=\"literal\">true</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -写入前的SQL执行处理</span></span><br><span class=\"line\">2021-10-28 09:57:05.628 [job-0] INFO  CommonRdbmsWriter<span class=\"variable\">$Job</span> - Begin to execute preSqls:[delete from mysqlwriter]. context info:jdbc:mysql://10.20.172.248:3305/<span class=\"built_in\">test</span>?useSSL=<span class=\"literal\">false</span>&amp;useUnicode=<span class=\"literal\">true</span>&amp;characterEncoding=UTF8&amp;serverTimezone=Asia/Shanghai&amp;yearIsDateType=<span class=\"literal\">false</span>&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=<span class=\"literal\">false</span>&amp;rewriteBatchedStatements=<span class=\"literal\">true</span>.</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -执行统计</span></span><br><span class=\"line\">任务启动时刻                    : 2021-10-28 09:57:05</span><br><span class=\"line\">任务结束时刻                    : 2021-10-28 09:57:15</span><br><span class=\"line\">任务总计耗时                    :                 10s</span><br><span class=\"line\">任务平均流量                    :                5B/s</span><br><span class=\"line\">记录写入速度                    :              0rec/s</span><br><span class=\"line\">读出记录总数                    :                   3</span><br><span class=\"line\">读写失败总数                    :                   0</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -查询插入到数据库的中的表数据</span></span><br><span class=\"line\">SELECT * from test.mysqlwriter;</span><br><span class=\"line\">+-----+--------+------------------+---------------------+</span><br><span class=\"line\">| uid | name   | hobby            | operation_time      |</span><br><span class=\"line\">+-----+--------+------------------+---------------------+</span><br><span class=\"line\">|   1 | C      | 面向过程编程语言 | 2021-10-13 02:43:30 |</span><br><span class=\"line\">|   2 | C++    | 面向对象         | 2021-10-13 10:44:59 |</span><br><span class=\"line\">|   3 | Python | 编程语言         | 2021-10-13 10:48:45 |</span><br><span class=\"line\">+-----+--------+------------------+---------------------+</span><br><span class=\"line\">3 rows <span class=\"keyword\">in</span> <span class=\"built_in\">set</span> (0.03 sec)</span><br></pre></td></tr></table></figure></p>\n<p>Tips : 非常注意读取和写入的字段数需要一致。</p>\n<p>至此本章完毕，下节更精彩。</p>\n","comments":true,"excerpt":"[TOC]","categories":[{"name":"database","path":"api/categories/database.json"},{"name":"异构数据同步","path":"api/categories/异构数据同步.json"}],"tags":[{"name":"DataX","path":"api/tags/DataX.json"}]}