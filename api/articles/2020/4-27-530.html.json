{"title":"10-Kubernetes进阶之原理架构学习及操作配置","slug":"虚拟云容/云容器/Kubernetes/10-Kubernetes进阶之原理架构学习及操作配置","date":"2020-04-27T10:37:47.000Z","updated":"2022-03-29T05:39:03.676Z","url":"2020/4-27-530.html","path":"api/articles/2020/4-27-530.html.json","covers":["https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210227180146.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210227181312.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210227181426.png","https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210302201524.png"],"content":"<p>[TOC]</p>\n<a id=\"more\"></a>\n<h2 id=\"0x01-核心组件\"><a href=\"#0x01-核心组件\" class=\"headerlink\" title=\"0x01 核心组件\"></a>0x01 核心组件</h2><h3 id=\"基础架构\"><a href=\"#基础架构\" class=\"headerlink\" title=\"基础架构\"></a>基础架构</h3><p>描述: 说过<code>kubernetes</code>架构中介绍到 <code>k8s Master</code> 由三个组件组成, 分别是<code>API Server、Controller Manager 与 Scheduler</code></p>\n<p><strong>图示1.k8s架构图示</strong><br><figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210227180146.png\" alt=\"WeiyiGeek.k8s架构\" title=\"\" class=\"\">\n                <p>WeiyiGeek.k8s架构</p>\n            </figure></p>\n<hr>\n<h3 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h3><h4 id=\"1-节点状态\"><a href=\"#1-节点状态\" class=\"headerlink\" title=\"1.节点状态\"></a>1.节点状态</h4><p><em>Q:什么是节点?</em><br>答:Kubernetes中节点（node）指的是一个工作机器曾经叫做 minion , 但是需要注意不同的集群中，节点可能是虚拟机也可能是物理机。<br>每个节点都<code>由 master 组件</code>管理，并包含了运行 Pod（容器组）所需的服务包括：<code>容器引擎 / kubelet / kube-proxy</code></p>\n<p><em>节点的状态包含如下信息:</em></p>\n<ul>\n<li>Conditions:节点的状态正常的如下面的节点信息,实际在文件中是以JSON对象的形式存在;<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Ready \t            <span class=\"comment\">#如果节点是健康的且已经就绪可以接受新的 Pod。则节点Ready字段为 True。False表明了该节点不健康不能够接受新的 Pod。</span></span><br><span class=\"line\">OutOfDisk \t        <span class=\"comment\">#如果节点上的空白磁盘空间不够，不能够再添加新的节点时，该字段为 True 其他情况为 False</span></span><br><span class=\"line\">MemoryPressure \t    <span class=\"comment\">#如果节点内存紧张，则该字段为 True，否则为False</span></span><br><span class=\"line\">PIDPressure \t      <span class=\"comment\">#如果节点上进程过多，则该字段为 True，否则为 False</span></span><br><span class=\"line\">DiskPressure \t      <span class=\"comment\">#如果节点磁盘空间紧张，则该字段为 True，否则为 False</span></span><br><span class=\"line\">NetworkUnvailable \t<span class=\"comment\">#如果节点的网络配置有问题，则该字段为 True，否则为 False</span></span><br></pre></td></tr></table></figure></li>\n<li>Addresses<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#ExternalIP：通常是节点的外部IP（可以从集群外访问的内网IP地址此字段为空）</span></span><br><span class=\"line\"><span class=\"comment\">#InternalIP：通常是从节点内部可以访问的 IP 地址</span></span><br></pre></td></tr></table></figure></li>\n<li>Capacity and Allocatable : 描述了节点上的可用资源的情况即<code>CPU,内存,该节点可调度的最大 pod 数量</code><ul>\n<li>Capacity 中的字段表示节点上的资源总数</li>\n<li>Allocatable 中的字段表示该节点上可分配给普通 Pod 的资源总数。</li>\n</ul>\n</li>\n<li>Info : 描述了节点的基本信息该信息以信息由节点上的 kubelet 收集。<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">* Linux 内核版本</span><br><span class=\"line\">* Kubernetes 版本（kubelet 和 kube-proxy 的版本）</span><br><span class=\"line\">* Docker 版本</span><br><span class=\"line\">* 操作系统名称</span><br></pre></td></tr></table></figure>\n<br></li>\n</ul>\n<p><em>Q:如何查看节点状态?</em><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#查看所有节点的列表</span></span><br><span class=\"line\"><span class=\"variable\">$kubectl</span> get nodes -o wide</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#查看节点状态以及节点的其他详细信息</span></span><br><span class=\"line\">kubectl describe node &lt;your-node-name&gt;</span><br><span class=\"line\"><span class=\"variable\">$kubectl</span> describe node node-1</span><br><span class=\"line\">Name:               node-1 <span class=\"comment\">#节点名称</span></span><br><span class=\"line\">Roles:              &lt;none&gt;</span><br><span class=\"line\">Labels:             beta.kubernetes.io/arch=amd64</span><br><span class=\"line\">                    beta.kubernetes.io/os=linux</span><br><span class=\"line\">                    kubernetes.io/arch=amd64</span><br><span class=\"line\">                    kubernetes.io/hostname=node-1</span><br><span class=\"line\">                    kubernetes.io/os=linux</span><br><span class=\"line\">Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock</span><br><span class=\"line\">                    node.alpha.kubernetes.io/ttl: 0</span><br><span class=\"line\">                    projectcalico.org/IPv4Address: 10.20.172.82/24      <span class=\"comment\">#IPaddress</span></span><br><span class=\"line\">                    projectcalico.org/IPv4IPIPTunnelAddr: 10.100.84.128 <span class=\"comment\">#Tunnel IP</span></span><br><span class=\"line\">                    volumes.kubernetes.io/controller-managed-attach-detach: <span class=\"literal\">true</span></span><br><span class=\"line\">CreationTimestamp:  Tue, 16 Jun 2020 15:15:11 +0800                     <span class=\"comment\">#加入时间</span></span><br><span class=\"line\">Taints:             &lt;none&gt;</span><br><span class=\"line\">Unschedulable:      <span class=\"literal\">false</span></span><br><span class=\"line\">Lease:</span><br><span class=\"line\">  HolderIdentity:  node-1</span><br><span class=\"line\">  AcquireTime:     &lt;<span class=\"built_in\">unset</span>&gt;</span><br><span class=\"line\">  RenewTime:       Wed, 17 Jun 2020 00:01:37 +0800</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (1)  描述了节点的状态</span></span><br><span class=\"line\">Conditions:</span><br><span class=\"line\">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class=\"line\">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class=\"line\">  NetworkUnavailable   False   Tue, 16 Jun 2020 23:17:13 +0800   Tue, 16 Jun 2020 23:17:13 +0800   CalicoIsUp                   Calico is running on this node</span><br><span class=\"line\">  MemoryPressure       False   Tue, 16 Jun 2020 23:57:26 +0800   Tue, 16 Jun 2020 23:15:44 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class=\"line\">  DiskPressure         False   Tue, 16 Jun 2020 23:57:26 +0800   Tue, 16 Jun 2020 23:15:44 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class=\"line\">  PIDPressure          False   Tue, 16 Jun 2020 23:57:26 +0800   Tue, 16 Jun 2020 23:15:44 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class=\"line\">  Ready                True    Tue, 16 Jun 2020 23:57:26 +0800   Tue, 16 Jun 2020 23:16:35 +0800   KubeletReady                 kubelet is posting ready status</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) 依据你集群部署的方式（在哪个云供应商部署，或是在物理机上部署），Addesses 字段可能有所不同。</span></span><br><span class=\"line\">Addresses:</span><br><span class=\"line\">  <span class=\"comment\"># 内部IP</span></span><br><span class=\"line\">  InternalIP:  10.20.172.82</span><br><span class=\"line\">  <span class=\"comment\"># 节点主机名称,启动 kubelet 时可以通过参数 --hostname-override 覆盖</span></span><br><span class=\"line\">  Hostname:    node-1 </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) 容量描述了节点上的可用资源的情况</span></span><br><span class=\"line\"><span class=\"comment\"># Capacity 中的字段表示节点上的资源总数</span></span><br><span class=\"line\">Capacity:</span><br><span class=\"line\">  cpu:                2</span><br><span class=\"line\">  ephemeral-storage:  47285700Ki</span><br><span class=\"line\">  hugepages-1Gi:      0</span><br><span class=\"line\">  hugepages-2Mi:      0</span><br><span class=\"line\">  memory:             2037168Ki</span><br><span class=\"line\">  pods:               110</span><br><span class=\"line\"><span class=\"comment\"># Allocatable 中的字段表示该节点上可分配给普通 Pod 的资源总数。</span></span><br><span class=\"line\">Allocatable:</span><br><span class=\"line\">  cpu:                2</span><br><span class=\"line\">  ephemeral-storage:  43578501048</span><br><span class=\"line\">  hugepages-1Gi:      0</span><br><span class=\"line\">  hugepages-2Mi:      0</span><br><span class=\"line\">  memory:             1934768Ki</span><br><span class=\"line\">  pods:               110</span><br><span class=\"line\"><span class=\"comment\"># 节点系统信息</span></span><br><span class=\"line\">System Info:</span><br><span class=\"line\">  Machine ID:                 6e65e151c0ef4248b78d6be0fb63eb58</span><br><span class=\"line\">  System UUID:                564d504e-4027-b5c3-9c49-11f2de69bf26</span><br><span class=\"line\">  Boot ID:                    90c3795b-4823-41de-9893-ef6b89db9614</span><br><span class=\"line\">  Kernel Version:             5.7.0-1.el7.elrepo.x86_64</span><br><span class=\"line\">  OS Image:                   CentOS Linux 7 (Core)</span><br><span class=\"line\">  Operating System:           linux</span><br><span class=\"line\">  Architecture:               amd64</span><br><span class=\"line\">  Container Runtime Version:  docker://19.3.9 <span class=\"comment\">#容器版本</span></span><br><span class=\"line\">  Kubelet Version:            v1.18.3  <span class=\"comment\">#kubernetes 版本</span></span><br><span class=\"line\">  Kube-Proxy Version:         v1.18.3  </span><br><span class=\"line\">PodCIDR:                      10.100.1.0/24 <span class=\"comment\"># Pod子网</span></span><br><span class=\"line\">PodCIDRs:                     10.100.1.0/24</span><br><span class=\"line\">Non-terminated Pods:          (2 <span class=\"keyword\">in</span> total)</span><br><span class=\"line\">  Namespace                   Name                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE</span><br><span class=\"line\">  ---------                   ----                 ------------  ----------  ---------------  -------------  ---</span><br><span class=\"line\">  kube-system                 calico-node-jp55x    250m (12%)    0 (0%)      0 (0%)           0 (0%)         46m  <span class=\"comment\">#节点的Calicao网络</span></span><br><span class=\"line\">  kube-system                 kube-proxy-kglgh     0 (0%)        0 (0%)      0 (0%)           0 (0%)         46m  <span class=\"comment\">#节点的kube-proxy代理</span></span><br><span class=\"line\">Allocated resources:  <span class=\"comment\">#分配资源 配置资源情况</span></span><br><span class=\"line\">  (Total limits may be over 100 percent, i.e., overcommitted.)</span><br><span class=\"line\">  Resource           Requests    Limits</span><br><span class=\"line\">  --------           --------    ------</span><br><span class=\"line\">  cpu                250m (12%)  0 (0%)</span><br><span class=\"line\">  memory             0 (0%)      0 (0%)</span><br><span class=\"line\">  ephemeral-storage  0 (0%)      0 (0%)</span><br><span class=\"line\">  hugepages-1Gi      0 (0%)      0 (0%)</span><br><span class=\"line\">  hugepages-2Mi      0 (0%)      0 (0%)</span><br><span class=\"line\">Events: <span class=\"comment\">#事件信息</span></span><br><span class=\"line\">  Type    Reason                   Age                            From                Message</span><br><span class=\"line\">  ----    ------                   ----                           ----                -------</span><br><span class=\"line\">  Normal  Starting                 &lt;invalid&gt;                      kubelet, node-1     Starting kubelet.</span><br><span class=\"line\">  Normal  NodeHasSufficientMemory  &lt;invalid&gt; (x2 over &lt;invalid&gt;)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientMemory</span><br><span class=\"line\">  Normal  NodeHasNoDiskPressure    &lt;invalid&gt; (x2 over &lt;invalid&gt;)  kubelet, node-1     Node node-1 status is now: NodeHasNoDiskPressure</span><br><span class=\"line\">  Normal  NodeHasSufficientPID     &lt;invalid&gt; (x2 over &lt;invalid&gt;)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientPID</span><br><span class=\"line\">  Normal  NodeAllocatableEnforced  &lt;invalid&gt;                      kubelet, node-1     Updated Node Allocatable <span class=\"built_in\">limit</span> across pods</span><br><span class=\"line\">  Normal  Starting                 &lt;invalid&gt;                      kube-proxy, node-1  Starting kube-proxy.</span><br><span class=\"line\">  Normal  NodeReady                &lt;invalid&gt;                      kubelet, node-1     Node node-1 status is now: NodeReady</span><br></pre></td></tr></table></figure></p>\n<p><em>注意事项:</em></p>\n<ul>\n<li>1) 如果 Ready 类型Condition 的 status 持续为 <code>Unkown 或者 False</code>超过 pod-eviction-timeout（kube-controller-manager 的参数）所指定的时间(默认5分钟),节点控制器（node controller）将对该节点上的所有 Pod 执行删除的调度动作; 然而在某些特殊情况下（例如，节点网络故障）apiserver 不能够与节点上的 kubelet 通信<code>导致删除 Pod 的指令不能下达到该节点的 kubelet 上</code>，直到 apiserver 与节点的通信重新建立指令才下达到节点, 意味着虽然对Pod执行了删除的调用指令, 但是这些Pod仍然在失联的节点上运行。<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 不同版本的解决方式</span></span><br><span class=\"line\">&lt;  kubernetes v1.5 : 节点控制器将从 apiserver 强制删除这些失联节点上的 Pod</span><br><span class=\"line\">&gt;= kubernetes v1.5 : 节点控制器将不会强制删除这些 Pod，直到已经确认他们已经停止运行为止,此时发现失联节点上的Pod仍然是在运行的(在该节点上运行docker ps即可以看见容器的运行状态), 然而 apiserver 中他们的状态已经变为 Terminating 或者 Unknown;</span><br><span class=\"line\">== Kubernetes v1.12 : TaintNodesByCondition 特性利用node lifecycle controller 将自动创建该 Condition 对应的 污点。相应地调度器在选择合适的节点时，不再关注节点的 Condition而是检查节点的污点和 Pod 的容忍</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 手动解决方式: 如果 Kubernetes 不能通过 cloud-controller-manager 判断失联节点是否已经永久从集群中移除（例如，在虚拟机或物理机上自己部署 Kubernetes 的情况）</span></span><br><span class=\"line\">kubectl delete node your-node-name <span class=\"comment\">#删除 apiserver 中的节点对象, 此时Kubernetes 将删除该节点上的所有 Pod。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><br></p>\n<h4 id=\"2-节点管理\"><a href=\"#2-节点管理\" class=\"headerlink\" title=\"2.节点管理\"></a>2.节点管理</h4><p>描述:前面我们说过Node(节点)可以是一台物理主机或者虚拟机的资源池再或者云供应商创建的，在向 Kubernetes 中创建节点时，仅仅是创建了一个描述该节点的 API 对象。<br>当节点 API 对象创建成功后，Kubernetes将检查该节点是否有效。</p>\n<p><em>注意事项:</em></p>\n<ul>\n<li>Kubernetes 在 APIServer 上创建一个节点 API 对象（节点的描述），并且基于 metadata.name 字段对节点进行健康检查.<br>如果<code>节点有效（节点组件正在运行）</code>，则可以向该<code>节点调度 Pod</code>；否则该节点 API 对象将被忽略，直到节点变为有效状态。</li>\n<li>Kubernetes 将保留无效的节点 API 对象，并不断地检查该节点是否有效。除非您使用 <code>kubectl delete node my-first-k8s-node</code> 命令删除该节点。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#例如，假设您创建如下节点信息：</span></span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Node</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: <span class=\"string\">\"10.240.79.157\"</span></span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    name: <span class=\"string\">\"my-first-k8s-node\"</span></span><br></pre></td></tr></table></figure>\n<p><strong>节点控制器（Node Controller）</strong><br>描述:在节点的生命周期中，节点控制器起到了许多作用。节点控制器是一个<code>负责管理节点的 Kubernetes master 组件</code>;</p>\n<p>工作流程:</p>\n<ul>\n<li>1.首先节点控制器在注册节点时为节点分配 CIDR 地址块<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$kubectl</span> describe node node-1</span><br><span class=\"line\">Addresses:</span><br><span class=\"line\">  InternalIP:  10.20.172.82</span><br><span class=\"line\">projectcalico.org/IPv4Address: 10.20.172.82/24</span><br><span class=\"line\">projectcalico.org/IPv4IPIPTunnelAddr: 10.100.84.128</span><br><span class=\"line\">PodCIDR:                      10.100.1.0/24</span><br><span class=\"line\">PodCIDRs:                     10.100.1.0/24</span><br></pre></td></tr></table></figure></li>\n<li>2.第二，节点控制器通过(Kube-controller-manager)和云供应商(cloud-controller-manager)接口检查节点列表中每一个节点对象对应的虚拟机是否可用。<ul>\n<li>在<code>云环境</code>中只要节点状态异常，节点控制器检查其虚拟机在云供应商的状态，如果<code>虚拟机不可用自动将节点对象从 APIServer 中删除</code>。</li>\n<li>在<code>本地局域网环境</code>中如果节点状态异常它会不断地检查该节点是否有效,<code>并不会将点对象从 APIServer 中删除,除非您手动删除</code>;</li>\n</ul>\n</li>\n<li>3.节点控制器监控节点的健康状况，每隔 <code>--node-monitor-period</code> 秒检查一次节点的状态;当节点变得不可触达时（例<code>由于节点已停机，节点控制器不再收到来自节点的心跳信号</code>），默认<code>40秒未收到心跳</code>,此时节点控制器将节点API对象的<code>NodeStatus Condition</code>取值从 <code>NodeReady</code> 更新为 <code>Unknown</code>；然后在等待 <code>pod-eviction-timeout</code> 为 5分钟 时间后，将节点上的所有 Pod 从节点驱逐。<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># (1) NodeStatus(&lt; V1.13) 和 node lease(&gt;= V1.13)都被用来记录节点的心跳信号。</span></span><br><span class=\"line\"> - 1.1) NodeStatus 的更新频率远高于 node lease ,因为是每次节点向 master 发出心跳信号NodeStatus 都将被更新, 只有在 NodeStatus 发生改变，或者足够长的时间未接收到 NodeStatus 更新时，节点控制器才更新 node lease（默认为1分钟，比节点失联的超时时间40秒要更长）</span><br><span class=\"line\"> - 1.2) 由于 node lease 比 NodeStatus 更轻量级，该特性显著提高了节点心跳机制的效率，并使 Kubernetes 性能和可伸缩性得到了提升;</span><br><span class=\"line\"> - 1.3) 在v1.4 中优化了节点控制器的逻辑以便更好的处理大量节点不能触达 master 的情况;主要的优化点在于节点控制器在决定是否执行 Pod 驱逐的动作时，会检查集群中所有节点的状态。默认情况下节点控制器限制了驱逐 Pod 的速率为 `--node-eviction-rate （默认值是0.1）每秒`即每10s驱逐一个Pod;</span><br><span class=\"line\"> - 1.4) 当节点所在的高可用区出现故障时，节点控制器驱逐 Pod 的方式将不一样;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><br/></p>\n<p><strong>节点自注册（Self-Registration）</strong><br>描述:如果 kubelet 的启动参数 <code>--register-node</code> 为 true（默认为 true），kubelet 会尝试将自己注册到 API Server。<br>kubelet自行注册时，将使用如下选项：</p>\n<ul>\n<li>–kubeconfig：向 apiserver 进行认证时所用身份信息的路径</li>\n<li>–cloud-provider：向云供应商读取节点自身元数据</li>\n<li>–register-node：自动向 API Server 注册节点</li>\n<li>–register-with-taints：注册节点时，为节点添加污点(逗号分隔，格式为 <code>&lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</code>)</li>\n<li>–node-ip：节点的 IP 地址</li>\n<li>–node-labels：注册节点时，为节点添加标签</li>\n<li>–node-status-update-frequency：向 master 节点发送心跳信息的时间间隔</li>\n</ul>\n<p>如果 Node authorization mode 和 NodeRestriction admission plugin 被启用，kubelet 只拥有创建/修改其自身所对应的节点 API 对象的权限。</p>\n<p><br/></p>\n<p><strong>手动管理节点</strong><br>描述:集群管理员可以创建和修改节点API对象。<br>如果管理员想要手工创建节点API对象，可以将 kubelet 的启动参数 <code>--register-node 设置为 false</code>，管理员可以修改节点API对象不管是否设置了该参数。<br>可以修改的内容有：<code>增加/减少标签,标记节点为不可调度（unschedulable）</code><br>节点的标签与 Pod 上的节点选择器（node selector）配合可以控制调度方式，例如限定 Pod 只能在某一组节点上运行(后面会进行讲解);</p>\n<p>执行如下命令可将节点标记为不可调度（unschedulable），此时将阻止新的 Pod 被调度到该节点上，但是不影响任何已经在该节点上运行的 Pod。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 重启节点一直有效</span></span><br><span class=\"line\">$ kubectl cordon <span class=\"variable\">$NODENAME</span></span><br><span class=\"line\">$ kubectl cordon node-1</span><br><span class=\"line\">node/node-1 cordoned</span><br></pre></td></tr></table></figure></p>\n<p>Tips: <code>DaemonSet Controller</code> 创建的 Pod 将绕过 Kubernetes 调度器，并且忽略节点的 unschedulable 属性。因为我们假设 Daemons 守护进程属于节点，尽管该节点在准备重启前，已经排空了上面所有的应用程序。</p>\n<p><br/></p>\n<p><strong>节点容量（Node Capacity）</strong><br>描述:节点API对象中描述了节点的容量（Capacity），例如，CPU数量、内存大小等信息。通常，节点在向 APIServer 注册的同时，在节点API对象里汇报了其容量（Capacity）。</p>\n<ul>\n<li>如果您<code>手动管理节点</code>，您需要在<code>添加节点时自己设置节点</code>的容量。</li>\n<li>K8s调度器在调度 Pod 到节点上时，将确保节点上有足够的资源。</li>\n</ul>\n<p>具体来说<code>调度器检查节点上所有容器的资源请求之和不大于节点的容量</code>。此时只能检查由 kubelet 启动的容器，不包括直接由容器引擎启动的容器，更不包括不在容器里运行的进程。</p>\n<p><br></p>\n<h4 id=\"3-控制器\"><a href=\"#3-控制器\" class=\"headerlink\" title=\"3.控制器\"></a>3.控制器</h4><p><strong>Q: 什么是控制器?</strong><br>A:在机器人技术和自动化技术中，控制循环是一个控制系统状态的无限循环。比如房间里的恒温器就是控制循环的一个应用例子;</p>\n<ul>\n<li>在恒温器上设定好目标温度，就是在告诉该控制循环你想要的目标状态。</li>\n<li>房间里的实际温度，是当前状态。</li>\n<li>恒温器通过打开或关闭加热装置，不断地使当前状态接近于目标状态。</li>\n</ul>\n<p>在 Kubernetes 中控制器就是上面所说的 控制循环，它不断监控着集群的状态，并对集群做出对应的变更调整。每一个控制器都不断地尝试着将 当前状态 调整到 目标状态。作为一个底层设计原则Kubernetes使用了大量的控制器，每个控制器都用来管理集群状态的某一个方面。普遍来说任何一个特定的控制器都使用一种 API 对象作为其目标状态，并使用和管理多种类型的资源，以达到目标状态。使用许多个简单的控制器比使用一个全能的控制器要更加有优势。控制器可能会出故障，而这也是在设计 Kubernetes 时要考虑到的事情。</p>\n<ul>\n<li><p>1.可能存在多种控制器可以创建或更新相同类型的 API 对象，为了避免混淆，Kubernetes 控制器在创建新的 API 对象时，会将该对象与对应的控制 API 对象关联，并且只关注与控制对象关联的那些对象。</p>\n<ul>\n<li>例如，Deployment 和 Job，这两类控制器都创建 Pod。Job Controller 不会删除 Deployment Controller 创建的 Pod，因为控制器可以通过标签信息区分哪些 Pod 是它创建的。</li>\n</ul>\n</li>\n<li><p>2.目标状态 vs 当前状态，Kubernetes 使用了 云原生（cloud-native）的视角来看待系统，并且可以持续应对变化。您的集群在运行的过程中，任何时候都有可能发生突发事件，而控制器则自动地修正这些问题。这就意味着，本质上，您的集群永远不会达到一个稳定不变的状态。</p>\n<ul>\n<li>例如，通过控制器监控集群状态并利用负反馈原理不断接近目标状态的系统，相较于那种完成安装后就不再改变的系统，是一种更高级的系统形态，尤其是在您将运行一个大规模的复杂集群的情况下。  </li>\n</ul>\n</li>\n</ul>\n<p><br/></p>\n<p><strong>控制器模式</strong><br>描述:在K8S中每个控制器至少追踪一种类型的资源，在资源对象中有一个 spec 字段代表了目标状态，资源对象对应的控制器负责不断地将当前状态调整到目标状态。</p>\n<p>理论上控制器可以自己直接执行调整动作，实际上控制器发送消息到 API Server 而不是直接自己执行调整动作。</p>\n<ul>\n<li>(1) API-Server 控制<br>Kubernetes 自带的控制器都是通过与集群中 API Server 交互来达到调整状态的目的，以 Kubernetes 中自带的一个控制器 Job Controller 为例;</li>\n</ul>\n<p>Job 是一种 Kubernetes API 对象，一个 Job 将运行一个（或多个）Pod，执行一项任务，然后停止。当新的 Job 对象被创建时，Job Controller 将确保集群中有合适数量的节点上的 kubelet 启动了指定个数的 Pod，以完成 Job 的执行任务。Job Controller 自己并不执行任何 Pod 或容器，而是发消息给 API Server，由其他的控制组件配合 API Server，以执行创建或删除 Pod 的实际动作。</p>\n<p>当新的 Job 对象被创建时，目标状态是指定的任务被执行完成。Job Controller 调整集群的当前状态以达到目标状态：创建 Pod 以执行 Job 中指定的任务, 控制器同样也会更新其关注的 API 对象。</p>\n<p>例如：一旦 Job 的任务执行结束，Job Controller 将更新 Job 的 API 对象，将其标注为 Finished。（这有点儿像是恒温器将指示灯关闭，以表示房间里的温度已经到达指定温度。）</p>\n<ul>\n<li>(2) 直接控制<br>描述:某些特殊的控制器需要对集群外部的东西做调整，Kubernetes中真的提供了一个控制器可以水平伸缩集群中的节点。</li>\n</ul>\n<p>例如:您想用一个控制器确保集群中有足够的节点，此时控制器需要调用云供应商的接口以创建新的节点或移除旧的节点。这类控制器将从 API Server 中读取关于目标状态的信息，并直接调用外部接口以实现调整目标。</p>\n<p><br></p>\n<h4 id=\"4-集群内部通信\"><a href=\"#4-集群内部通信\" class=\"headerlink\" title=\"4.集群内部通信\"></a>4.集群内部通信</h4><p>描述:我们知道 Kubernetes集群和Master节点（实际上是API Server）之间的通信路径；</p>\n<p>Master-Node 之间的通信可以分为如下两类：</p>\n<ul>\n<li>(1) Cluster to Master:所有从集群访问 Master 节点的通信，都是针对 apiserver 的（没有任何其他 master 组件发布远程调用接口），得益于下面这些措施，从集群（节点以及节点上运行的 Pod）访问 master 的连接是安全的，因此，可以通过不受信的网络或公网连接 Kubernetes 集群<ul>\n<li>API Server监听的HTTPS端口是您在安装k8s的时候进行设置的，并配置了一种或多种客户端认证方式 authentication;注意至少需要配置一种形式的 授权方式 authorization ，尤其是 匿名访问 anonymous requests 或 Service Account Tokens 被启用的情况下；</li>\n<li>节点上必须配置集群（apiserver）的公钥根证书（public root certificate），此时，在提供有效的客户端身份认证的情况下，节点可以安全地访问 APIServer；</li>\n<li>对于需要调用 APIServer 接口的 Pod，应该为其关联 Service Account，此时，Kubernetes将在创建Pod时自动为其注入公钥根证书（public root certificate）以及一个有效的 bearer token（放在HTTP请求头Authorization字段）。所有名称空间中，都默认配置了名为 kubernetes Kubernetes Service，该 Service对应一个虚拟 IP（默认为 10.96.0.1），发送到该地址的请求将由 kube-proxy 转发到 apiserver 的 HTTPS 端口上；</li>\n</ul>\n</li>\n</ul>\n<p><br></p>\n<ul>\n<li>(2) Master to Cluster: 存在着两条主要的通信路径前者是apiserver 访问集群中每个节点上的 kubelet 进程，后者是使用 apiserver 的 proxy 功能，从 apiserver 访问集群中的任意节点、Pod、Service；<ul>\n<li>apiserver 会访问 kubelet 情况如下抓取 Pod 的日志时，通过 kubectl exec -it 指令（或 kuboard 的终端界面）获得容器的命令行终端时，提供 kubectl port-forward 功能时,连接访问端点是 kubelet 的 HTTPS 端口，但是默认情况下apiserver 不校验 kubelet 的 HTTPS 证书，此时链接可能会收到 man-in-the-middle 攻击，如果在不受信网络或者公网上运行时是不安全的；如果要校验 kubelet 的 HTTPS 证书，可以通过 <code>--kubelet-certificate-authority</code> 参数为 apiserver 提供校验 kubelet 证书的根证书。如果不能完成这个配置，又需要通过不受信网络或公网将节点加入集群，则需要使用 SSH隧道 连接 apiserver 和 kubelet。同时，Kubelet authentication/authorization需要激活，以保护 kubelet AP</li>\n<li>apiserver 访问 nodes, pods, services 的连接使用的是 HTTP 连接，没有进行身份认证也没有进行加密传输，此时可以通过增加 https 作为 节点/Pod/Service 请求 URL 的前缀，但是 HTTPS 证书并不会被校验，也无需客户端身份认证，因此该连接是无法保证一致性的</li>\n<li>Kubernetes 支持 SSH隧道（tunnel）来保护 Master –&gt; Cluster 访问路径（对于公网加入集群需要通信的情况下），<code>SSH隧道当前已被不推荐使用（deprecated），Kubernetes 正在设计新的替代通信方式</code>。</li>\n</ul>\n</li>\n</ul>\n<p><br></p>\n<h4 id=\"5-集群高可用\"><a href=\"#5-集群高可用\" class=\"headerlink\" title=\"5.集群高可用\"></a>5.集群高可用</h4><p>Tips: 高可用区出现故障时节点控制器驱逐Pod，将检查高可用区里故障节点的百分比（<code>NodeReady Condition 的值为 Unknown 或 False</code>);</p>\n<ul>\n<li>如果故障节点的比例不低于 <code>--unhealthy-zone-threshold（默认为 0.55）</code> 则降低驱逐 Pod 的速率;</li>\n<li>如果集群规模较小（少于等于 <code>--large-cluster-size-threshold</code> 个节点，默认值为 50），则停止驱逐 Pod;</li>\n<li>如果集群规模大于 <code>--large-cluster-size-threshold</code> 个节点，则驱逐 Pod 的速率降低到 <code>--secondary-node-eviction-rate</code> （默认值为 0.01）每秒;</li>\n</ul>\n<p>针对每个高可用区使用这个策略的原因是，某一个高可用区可能与 master 隔开了，而其他高可用区仍然保持连接。如果您的集群并未分布在云供应商的多个高可用区上，此时，您只有一个高可用区（即整个集群）。</p>\n<p>将集群的节点分布到多个高可用区最大的原因是，在某个高可用区出现整体故障时，可以将工作负载迁移到仍然健康的高可用区。因此，如果某个高可用区的所有节点都出现故障时，节点控制器仍然使用正常的驱逐 Pod 的速率（–node-eviction-rate）。</p>\n<p>最极端的情况是，所有的高可用区都完全不可用（例如，集群中一个健康的节点都没有），此时节点控制器 master 节点的网络连接出现故障，并停止所有的驱逐 Pod 的动作，直到某些连接得到恢复。</p>\n<p>简单的集群配置文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim kubeadm-config.yaml</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  certSANs:</span><br><span class=\"line\">    - k8s-master-01</span><br><span class=\"line\">    - k8s-master-02</span><br><span class=\"line\">    - k8s-master-03</span><br><span class=\"line\">    - master.k8s.io</span><br><span class=\"line\">    - 192.168.9.80</span><br><span class=\"line\">    - 192.168.9.81</span><br><span class=\"line\">    - 192.168.9.82</span><br><span class=\"line\">    - 192.168.9.83</span><br><span class=\"line\">    - 127.0.0.1</span><br><span class=\"line\">  extraArgs:</span><br><span class=\"line\">    authorization-mode: Node,RBAC</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controlPlaneEndpoint: <span class=\"string\">\"master.k8s.io:16443\"</span></span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns: </span><br><span class=\"line\">  <span class=\"built_in\">type</span>: CoreDNS</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  <span class=\"built_in\">local</span>:    </span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.16.3</span><br><span class=\"line\">networking: </span><br><span class=\"line\">  dnsDomain: cluster.local  </span><br><span class=\"line\">  podSubnet: 10.244.0.0/16</span><br><span class=\"line\">  serviceSubnet: 10.1.0.0/16</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h2 id=\"0x02-原理剖析\"><a href=\"#0x02-原理剖析\" class=\"headerlink\" title=\"0x02 原理剖析\"></a>0x02 原理剖析</h2><h3 id=\"Pod-操作时序图\"><a href=\"#Pod-操作时序图\" class=\"headerlink\" title=\"Pod 操作时序图\"></a>Pod 操作时序图</h3><p><strong>1) 创建</strong><br>流程步骤:</p>\n<ul>\n<li>1.用户通过kubectl创建Pod请求通知API SERVER，并写入到etcd数据库中;</li>\n<li>2.然后通过<code>API SERVER</code>与Scheduler联系，将该Pod绑定在指定的Node节点之上;</li>\n<li>3.API Server 进行记录相关节点与Pod绑定信息，并且将该绑定信息写入到etcd数据库之中;</li>\n<li>4.kubelet 通过 CRI 调用 Docker 进行管理容器，同时更新Pod状态;</li>\n<li>5.将 Pod 状态同步到 etcd数据库中;</li>\n</ul>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210227181312.png\" alt=\"WeiyiGeek.Pod创建时序图\" title=\"\" class=\"\">\n                <p>WeiyiGeek.Pod创建时序图</p>\n            </figure>\n<p><strong>2) 删除</strong></p>\n<ul>\n<li>1.用户通过kubectl发送删除Pod请求，并且将该请求写入到etcd之中</li>\n<li>2.等待30s后删除该Pod, 并回显到终端之中</li>\n<li>3.Endport Controller 将该Pod的端点进行回收</li>\n<li>4.Api Server 发送Term Signal信号，并触发运行Prestop Hook</li>\n<li>5.此时Docker接收到Hook后发送SigKill信号此时将会立即删除容器，并通知Api Server</li>\n<li>6.将写入到Etcd数据库之中该Pod信息进行删除</li>\n</ul>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210227181426.png\" alt=\"WeiyiGeek.Pod删除时序图\" title=\"\" class=\"\">\n                <p>WeiyiGeek.Pod删除时序图</p>\n            </figure>\n<p><br></p>\n<h3 id=\"K8s-集群架构\"><a href=\"#K8s-集群架构\" class=\"headerlink\" title=\"K8s 集群架构\"></a>K8s 集群架构</h3><h4 id=\"Api-Server\"><a href=\"#Api-Server\" class=\"headerlink\" title=\"Api-Server\"></a>Api-Server</h4><p>描述: K8S API Server 简称<code>Kubernetes Master</code>是k8s最重要的核心组件之一负责集群内各个模块的通信。其通过kube-apiserver的进程提供服务，它提供了k8s各类资源对象(Pod/RC/Server)等的增删改查以及Watch等<code>HTTP Rest</code>接口，它是整个系统的数据总线和数据中心；</p>\n<p>原理: 集群中各个功能模块通过API Server将信息存入etcd之中，当需要获取这些信息时则通过API Server提供的REST接口实现, 从而实现各个组件之间的交互; 即API Server本身是无状态服务，通过将资源数据存储到etcd中，后续业务则是由Sheduler与Controller-manager进行执行;</p>\n<p>高可用: <code>K8s Api Server</code> 服务高可用可以同时起多个K8S API Server服务，通过使用负载均衡器(Nginx / HAProxy)把客户端的流量转发到不同的后端ApiServer从而实现接入层的高可用;</p>\n<p><br/></p>\n<p><strong>API Server 功能:</strong><br>在kubernetes API Server的主要功能有<code>提供了集群管理的REST API 接口(包括认证授权、数据校验及集群状态变更)</code>和提供其它模块之间的数据交互和通信枢纽(只有API Server才能直接操作etcd数据库)、资源配额控制的入口、拥有完备的集群安全机制;</p>\n<p><br></p>\n<p><strong>API Server 应用场景:</strong></p>\n<ul>\n<li>1) 基于Kubernetes的管理平台</li>\n<li>2) 基于Pod中调用Api Server的请求</li>\n</ul>\n<p><br></p>\n<p><strong>API Server 工作原理图:</strong><br>描述: Kube-ApiServer 提供了K8s的REST API实现了<code>认证、授权、准入</code>等安全校验功能,同时负责集群状态的存储(ETCD)操作;</p>\n<figure class=\"image-box\">\n                <img src=\"https://cdn.jsdelivr.net/gh/WeiyiGeek/blogimage/2021/1/20210302201524.png\" alt=\"WeiyiGeek.API-Server工作原理图\" title=\"\" class=\"\">\n                <p>WeiyiGeek.API-Server工作原理图</p>\n            </figure>\n<p>Tips : 分成四个部分一是API、二是访问控制、三是Registry<code>(Pod Namespace Services)</code>、四是<code>Etcd Cluster</code>集群</p>\n<p><br></p>\n<p><strong>Api Server 与 集群三大组件通信介绍:</strong></p>\n<ul>\n<li>(1) API Server 与 Kubelet 介绍: 在 Node节点 上的k8s进程定期调用 <code>API Server</code> 的REST接口报告自身状态，API Server 收到信息后会将<code>节点状态存储在etcd</code>数据库之中，另外 kubelet 还会调用API Server 的Watch接口监听Pod信息，正对于Pod增删改查分别执行相应逻辑;</li>\n<li>(2) API Server 与 Controller-Manager介绍: 该组件对应的进程名为kube-controller-manager。其调用API Server的Watch接口，实时监控Node信息并做出相应的处理;</li>\n<li>(3) API Server 与 Scheduler 介绍: 该组件对应的进程名<code>kube-scheduler</code>其通过API Server的Watch接口，监听到新创建Pod请求后会根据设定的策略执行相应的调度逻辑，最后成功将Pod绑定在目标节点之上; </li>\n</ul>\n<p>Tips: 各个功能模块都会定期从API Server获取指定的资源对象然后通过<code>LIST 或者 Watch</code>采用缓存来缓存数据到本地之中，然后通过访问缓存的方式来减少对<code>Api Server</code>访问的压力；</p>\n<p><br></p>\n<p><strong>API-Server 启动参数:</strong><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kube-apiserver</span><br><span class=\"line\">  - --advertise-address=192.168.12.107</span><br><span class=\"line\">  - --allow-privileged=<span class=\"literal\">true</span></span><br><span class=\"line\">  - --authorization-mode=Node,RBAC  <span class=\"comment\"># 这就是前面所说的鉴权方式</span></span><br><span class=\"line\">  - --client-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">  - --<span class=\"built_in\">enable</span>-admission-plugins=NodeRestriction</span><br><span class=\"line\">  - --<span class=\"built_in\">enable</span>-bootstrap-token-auth=<span class=\"literal\">true</span></span><br><span class=\"line\">  - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class=\"line\">  - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt</span><br><span class=\"line\">  - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key</span><br><span class=\"line\">  - --etcd-servers=https://127.0.0.1:2379</span><br><span class=\"line\">  - --insecure-port=0</span><br><span class=\"line\">  - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt</span><br><span class=\"line\">  - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key</span><br><span class=\"line\">  - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class=\"line\">  - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt</span><br><span class=\"line\">  - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key</span><br><span class=\"line\">  - --requestheader-allowed-names=front-proxy-client</span><br><span class=\"line\">  - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class=\"line\">  - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class=\"line\">  - --requestheader-group-headers=X-Remote-Group</span><br><span class=\"line\">  - --requestheader-username-headers=X-Remote-User</span><br><span class=\"line\">  - --secure-port=6443</span><br><span class=\"line\">  - --service-account-key-file=/etc/kubernetes/pki/sa.pub</span><br><span class=\"line\">  - --service-cluster-ip-range=10.96.0.0/12</span><br><span class=\"line\">  - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span><br><span class=\"line\">  - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br></pre></td></tr></table></figure></p>\n<p><br></p>\n<h4 id=\"REST-API\"><a href=\"#REST-API\" class=\"headerlink\" title=\"REST API\"></a>REST API</h4><p>描述: Kube-apiserver 同时支持提供https(默认监听在6443端口)以及http（默认监听127.0.0.1的8080端口），其中后者是非安全接口，不做任何认证授权机制生产环境中不建议启用，注意两个接口REST API 格式一致;</p>\n<p><strong>Q: 如果查询API调用格式?</strong><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -v 8 get pod</span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:04.991697 3929980 loader.go:375] Config loaded from file:  /home/weiyigeek/.kube/config</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:04.996106 3929980 round_trippers.go:421] GET https://weiyigeek-lb-vip.k8s:16443/api/v1/namespaces/default/pods?limit=500</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:04.996128 3929980 round_trippers.go:428] Request Headers:</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:04.996147 3929980 round_trippers.go:432]     Accept: application/json;as=Table;v=v1;g=meta.k8s.io,application/json;as=Table;v=v1beta1;g=meta.k8s.io,application/json</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:04.996159 3929980 round_trippers.go:432]     User-Agent: kubectl/v1.19.6 (linux/amd64) kubernetes/fbf646b</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:05.008580 3929980 round_trippers.go:447] Response Status: 200 OK in 12 milliseconds</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:05.008598 3929980 round_trippers.go:450] Response Headers:</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:05.008604 3929980 round_trippers.go:453]     Cache-Control: no-cache, private</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:05.008609 3929980 round_trippers.go:453]     Content-Type: application/json</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:05.008619 3929980 round_trippers.go:453]     Date: Sun, 28 Feb 2021 06:39:05 GMT</span></span><br><span class=\"line\">  <span class=\"comment\"># I0228 06:39:05.008806 3929980 request.go:1097] Response Body: &#123;\"kind\":\"Table\",\"apiVersion\":\"meta.k8s.io/v1\",\"metadata\":&#123;\"selfLink\":\"/api/v1/namespaces/default/pods\",\"resourceVersion\":\"12507375\"&#125;,\"columnDefinitions\":[&#123;\"name\":\"Name\",\"type\":\"string\",\"format\":\"name\",\"description\":\"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names\",\"priority\":0&#125;,&#123;\"name\":\"Ready\",\"type\":\"string\",\"format\":\"\",\"description\":\"The aggregate readiness state of this pod for accepting traffic.\",\"priority\":0&#125;,&#123;\"name\":\"Status\",\"type\":\"string\",\"format\":\"\",\"description\":\"The aggregate status of the containers in this pod.\",\"priority\":0&#125;,&#123;\"name\":\"Restarts\",\"type\":\"integer\",\"format\":\"\",\"description\":\"The number of times the containers in this pod have been restarted.\",\"priority\":0&#125;,&#123;\"name\":\"Age\",\"type\":\"string\", [truncated 7667 chars]</span></span><br></pre></td></tr></table></figure></p>\n<p><br></p>\n<p><strong>Swagger &amp;&amp; Swagger-UI</strong><br>描述: 通过<code>/swagger.json</code>查看OpenAPI;</p>\n<p>操作流程:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 开启代理</span></span><br><span class=\"line\">$ kubectl proxy</span><br><span class=\"line\">  Starting to serve on 127.0.0.1:8001</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 通过`/swagger.json`查看OpenAPI</span></span><br><span class=\"line\">curl http://127.0.0.1:8001/swagger.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"paths\"</span>: [</span><br><span class=\"line\">    <span class=\"string\">\"/apis\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiextensions.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiextensions.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiextensions.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/etcd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/log\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/ping\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/crd-informer-synced\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/generic-apiserver-start-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/max-in-flight-filter\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-apiextensions-controllers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-apiextensions-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/etcd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/log\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/ping\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/crd-informer-synced\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/generic-apiserver-start-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/max-in-flight-filter\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-apiextensions-controllers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-apiextensions-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/metrics\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/openapi/v2\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/etcd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/informer-sync\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/log\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/ping\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/crd-informer-synced\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/generic-apiserver-start-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/max-in-flight-filter\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-apiextensions-controllers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-apiextensions-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/shutdown\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/version\"</span></span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;c</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看所有OpenAPI接口</span></span><br><span class=\"line\">~$ curl http://127.0.0.1:8001</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"paths\"</span>: [</span><br><span class=\"line\">    <span class=\"string\">\"/api\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/api/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/admissionregistration.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/admissionregistration.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/admissionregistration.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiextensions.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiextensions.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiextensions.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiregistration.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiregistration.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apiregistration.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apps\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/apps/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/authentication.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/authentication.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/authentication.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/authorization.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/authorization.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/authorization.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/autoscaling\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/autoscaling/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/autoscaling/v2beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/autoscaling/v2beta2\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/batch\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/batch/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/batch/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/certificates.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/certificates.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/certificates.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/coordination.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/coordination.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/coordination.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/discovery.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/discovery.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/events.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/events.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/events.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/extensions\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/extensions/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/networking.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/networking.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/networking.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/node.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/node.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/policy\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/policy/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/rbac.authorization.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/rbac.authorization.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/rbac.authorization.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/redis.kun\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/redis.kun/v1alpha1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/scheduling.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/scheduling.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/scheduling.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/storage.k8s.io\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/storage.k8s.io/v1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/apis/storage.k8s.io/v1beta1\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/autoregister-completion\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/etcd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/log\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/ping\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/aggregator-reload-proxy-client-cert\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/apiservice-openapi-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/apiservice-registration-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/apiservice-status-available-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/bootstrap-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/crd-informer-synced\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/generic-apiserver-start-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/kube-apiserver-autoregistration\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/max-in-flight-filter\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/rbac/bootstrap-roles\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/scheduling/bootstrap-system-priority-classes\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-apiextensions-controllers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-apiextensions-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-cluster-authentication-info-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-kube-aggregator-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/healthz/poststarthook/start-kube-apiserver-admission-initializer\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/autoregister-completion\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/etcd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/log\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/ping\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/aggregator-reload-proxy-client-cert\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/apiservice-openapi-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/apiservice-registration-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/apiservice-status-available-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/bootstrap-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/crd-informer-synced\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/generic-apiserver-start-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/kube-apiserver-autoregistration\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/max-in-flight-filter\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/rbac/bootstrap-roles\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/scheduling/bootstrap-system-priority-classes\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-apiextensions-controllers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-apiextensions-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-cluster-authentication-info-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-kube-aggregator-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/livez/poststarthook/start-kube-apiserver-admission-initializer\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/logs\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/metrics\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/openapi/v2\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/autoregister-completion\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/etcd\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/informer-sync\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/log\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/ping\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/aggregator-reload-proxy-client-cert\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/apiservice-openapi-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/apiservice-registration-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/apiservice-status-available-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/bootstrap-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/crd-informer-synced\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/generic-apiserver-start-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/kube-apiserver-autoregistration\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/max-in-flight-filter\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/rbac/bootstrap-roles\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/scheduling/bootstrap-system-priority-classes\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-apiextensions-controllers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-apiextensions-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-cluster-authentication-info-controller\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-kube-aggregator-informers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/poststarthook/start-kube-apiserver-admission-initializer\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/readyz/shutdown\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"/version\"</span></span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例如查看当前api-server版本</span></span><br><span class=\"line\">$ curl http://127.0.0.1:8001/version</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"major\"</span>: <span class=\"string\">\"1\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"minor\"</span>: <span class=\"string\">\"19\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"gitVersion\"</span>: <span class=\"string\">\"v1.19.6\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"gitCommit\"</span>: <span class=\"string\">\"fbf646b339dc52336b55d8ec85c181981b86331a\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"gitTreeState\"</span>: <span class=\"string\">\"clean\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"buildDate\"</span>: <span class=\"string\">\"2020-12-18T12:01:36Z\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"goVersion\"</span>: <span class=\"string\">\"go1.15.5\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"compiler\"</span>: <span class=\"string\">\"gc\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"platform\"</span>: <span class=\"string\">\"linux/amd64\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>如果想保留部分的 REST API 可以通过加入 <code>--reject-paths=&quot;^/api/v1/pods&quot;</code>，如果想限制非法的客户端访问则采用<code>--accept-host=&quot;^127\\\\.0\\\\.0\\\\.1$,^\\\\[::1\\\\]$&quot;</code> (注意支持正则表达式)<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># (1) 在拒绝前</span></span><br><span class=\"line\">~$ curl -si http://127.0.0.1:8001/api/v1/pods  | more</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Cache-Control: no-cache, private</span><br><span class=\"line\">Content-Type: application/json</span><br><span class=\"line\">Date: Sun, 28 Feb 2021 07:02:56 GMT</span><br><span class=\"line\">Vary: Accept-Encoding</span><br><span class=\"line\">Transfer-Encoding: chunked</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) 添加资源访问限制</span></span><br><span class=\"line\">~$ kubectl proxy --reject-paths=<span class=\"string\">\"^/api/v1/pods\"</span> --accept-hosts=<span class=\"string\">\"^127\\\\.0\\\\.0\\\\.1$,^\\\\[::1\\\\]$\"</span> --port 8888 -v 2</span><br><span class=\"line\">Starting to serve on 127.0.0.1:8888</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) 在拒绝后其拒绝访问pod相关信息</span></span><br><span class=\"line\">~$ curl -si http://127.0.0.1:8888/api/v1/pods  | more</span><br><span class=\"line\">HTTP/1.1 403 Forbidden</span><br><span class=\"line\">Content-Type: text/plain; charset=utf-8</span><br><span class=\"line\">X-Content-Type-Options: nosniff</span><br><span class=\"line\">Date: Sun, 28 Feb 2021 07:07:20 GMT</span><br><span class=\"line\">Content-Length: 10</span><br><span class=\"line\"></span><br><span class=\"line\">Forbidden</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (4) 访问非127.0.0.1地址由于没有本地192.168.12.107网卡监听则无任何回显</span></span><br><span class=\"line\">~$ curl -si http://192.168.12.107:8888/version | more</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (5) 查看 Api Server 目前所支持的资源对象种类</span></span><br><span class=\"line\">~$ curl -s http://127.0.0.1:8888/api/v1 | head -n 13</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"kind\"</span>: <span class=\"string\">\"APIResourceList\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"groupVersion\"</span>: <span class=\"string\">\"v1\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"resources\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"name\"</span>: <span class=\"string\">\"bindings\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"singularName\"</span>: <span class=\"string\">\"\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"namespaced\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"kind\"</span>: <span class=\"string\">\"Binding\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"verbs\"</span>: [</span><br><span class=\"line\">        <span class=\"string\">\"create\"</span></span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (5) 查看 Api Server 目前所支持的资源对象种类</span></span><br><span class=\"line\">~$ curl -s http://127.0.0.1:8888/api/v1/pods        <span class=\"comment\"># Pod 相关信息</span></span><br><span class=\"line\">~$ curl -s http://127.0.0.1:8888/api/v1/servics     <span class=\"comment\"># Service 相关信息</span></span><br><span class=\"line\">~$ curl -s http://127.0.0.1:8888/api/v1/deployments <span class=\"comment\"># deployments 部署相关信息</span></span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>下面我们可以通过访问<code>Swagger-UI接口</code>查看<code>REST API接口</code>,但是首先需要配置启用swagger-ui具有操作流程如下:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># (1) 通过开启-enable-swagger-ui=true还可以通过/swagger-ui访问Swagger UI</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) 修改 `/etc/kubernetes/manifests/kube-apiserver.yaml`中启动参数如下之后重新生成静态Pod</span></span><br><span class=\"line\"><span class=\"comment\"># - --insecure-port=0</span></span><br><span class=\"line\">- --<span class=\"built_in\">enable</span>-swagger-ui=<span class=\"literal\">true</span></span><br><span class=\"line\">- --insecure-bind-address=0.0.0.0</span><br><span class=\"line\">- --insecure-port=30999</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) 发现kube-apiserver已经重启了</span></span><br><span class=\"line\">/etc/kubernetes/manifests$ kubectl get pod -n kube-system -o wide | grep <span class=\"string\">\"kube-apiserver-weiyigeek-107\"</span></span><br><span class=\"line\">kube-apiserver-weiyigeek-107   1/1     Running   0       87s   192.168.12.107   weiyigeek-107 </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (4) 访问http://192.168.12.107:30999 与 /swagger-ui 查看你效果</span></span><br><span class=\"line\">$ curl -si http://127.0.0.1:30999  <span class=\"comment\"># 与上面的OPENAPI 返回一致</span></span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Cache-Control: no-cache, private</span><br><span class=\"line\">Content-Type: application/json</span><br><span class=\"line\">Date: Sun, 28 Feb 2021 08:24:07 GMT</span><br><span class=\"line\">Transfer-Encoding: chunked</span><br></pre></td></tr></table></figure>\n<p><br/></p>\n<h4 id=\"Controller-Manager\"><a href=\"#Controller-Manager\" class=\"headerlink\" title=\"Controller-Manager\"></a>Controller-Manager</h4><p>描述: Controller Manager 作为集群的管理控制中心(大脑)，负责整个集群内的Node、Pod Replica、Endpoint、Namespace、ServiceAccout以及ResourceQuota; 它通过API Server监控整个集群状态，并确保集群处于预期的工作状态;</p>\n<p>Controller-Manager 分类由一系列的控制器组成:</p>\n<ul>\n<li>Node         (实时获取Node相关信息，实现管理和监控集群中各个节点的相关控制功能)</li>\n<li>Namespace</li>\n<li>Replication  (副本控制器 - 弹性伸缩Scalling、滚动升级RollingUpdate)</li>\n<li>Deployment   (无状态推荐使用)</li>\n<li>StatefulSet  (有状态持久卷推荐使用)</li>\n<li>Daemon</li>\n<li>Cronjob</li>\n<li>Job</li>\n<li>Service Controller        (与外部云平台的接口控制器)</li>\n<li>ServiceAccount Controller</li>\n<li>Endport Controller        (集群中Service对应的全部Pod副本访问地址)</li>\n<li>Garbage Controller</li>\n<li>Volume Control</li>\n<li>ResourceQuota Controller (资源配额管理指定的资源对象对资源消费的限制，避免由于服务缺陷导致系统资源被过分消费)</li>\n</ul>\n<p>而云Controller-Manager用来配合云服务提供商的控制，也包括一系列的控制器如:</p>\n<ul>\n<li>Node Controller</li>\n<li>Route Controller</li>\n<li>Service Controller</li>\n</ul>\n<p><br></p>\n<h4 id=\"Scheduler\"><a href=\"#Scheduler\" class=\"headerlink\" title=\"Scheduler\"></a>Scheduler</h4><p>描述: 优良的调度是分布式系统的核心，承载着整个集群的调度功能，其根据特定的调度算法和策略，将Pod调度到最优工作节点之上，从而更合理与更充分的利用集群计算资源，使得资源更好的服务于业务服务的需求;</p>\n<p>Tips : Scheduler 是一个调度器, 普通用户可以将其理解为一个黑盒（<code>里面是待调度的Pod和全部计算节点的信息</code>），经过黑盒内部的调度算法和策略处理输出为最优的节点，而后将Pod调度在该节点之上;</p>\n<p>Q: 上述过程看似简单但在实际的生产环境的调度过程中，由很多问题需要进行考虑；</p>\n<ul>\n<li>如何保证全部计算机节点调度的公平性？</li>\n<li>如何保证每个节点都能被分配资源？</li>\n<li>计算资源如何能够被高效利用？</li>\n<li>集群所有计算资源如何才能最大化的使用?</li>\n<li>如何保证Pod调度的性能和效率</li>\n<li>如何能够快速对大批量的Pod完成调度到较优的计算机节点之上？</li>\n<li>是否可以根据实际需求进行定制自己的调度逻辑和策略？</li>\n</ul>\n<p>Tips: 用户可以自定义调度器并以插件的形式与Kubernetes集成或集成其他调度器，便于调度不同类型的任务。</p>\n<p>K8s调度器的源码位于<code>kubernetes/plugin</code>中而创建和运行的过程对应的代码在<code>plugin/pkg/scheduler/scheduler.go</code>。其大体的代码目录结构如下所示:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubernetes/plugin/pkg/  </span><br><span class=\"line\">`-- scheduler               //调度相关的具体实现              </span><br><span class=\"line\">    |-- algorithm</span><br><span class=\"line\">    |   |-- predicates       //节点筛选策略</span><br><span class=\"line\">    |   `-- priorities         //节点打分策略</span><br><span class=\"line\">    |       `-- util</span><br><span class=\"line\">    |-- algorithmprovider</span><br><span class=\"line\">    |   `-- defaults          //定义默认的调度器</span><br></pre></td></tr></table></figure></p>\n<p>上面初步介绍了Kubernetes调度器。具体的说，调度器是Kubernetes容器集群管理系统中加载并运行的调度程序，负责收集、统计分析容器集群管理系统中所有Node的资源使用情况，然后以此为依据将新建的Pod发送到优先级最高的可用Node上去建立。</p>\n<p>Kubernetes调度器使用Predicates和Priorites来决定一个Pod应该运行在哪一个节点上, 即调度分为以下几个部分：</p>\n<ul>\n<li>首先是预选过程，过滤掉不满足条件的节点，称为 Predicates (回答“能不能”的问题-强制性规则)</li>\n<li>然后是优选过程，对通过的节点按照优先级排序，称为 Priorities (回答“哪个更适合的问题”-非强制性规则)</li>\n<li>最后从中选择优先级最高的节点。</li>\n</ul>\n<p>注意: 如果中间任何一步骤有错误，就直接返回错误。</p>\n<p>Tips : 如果在预选（Predicates）过程中，如果所有的节点都不满足条件，Pod 会一直处<code>在Pending 状态</code>，直到有节点满足条件，这期间调度器会不断的重试。经过节点过滤后，如多个节点满足条件，会按照<code>节点优先级（priorities）</code>大小对节点排序，最后选择优先级最高的节点部署Pod。</p>\n<p><br/></p>\n<p><strong>具体的调度过程:</strong></p>\n<ul>\n<li><p>1) 首先客户端通过<code>API Server</code>的<code>REST API/kubectl/helm</code>创建<code>pod/service/deployment/job</code>等，支持类型主要为JSON/YAML/helm tgz。</p>\n</li>\n<li><p>2) 接下来API Server收到用户请求，存储到相关数据到etcd。</p>\n</li>\n<li><p>3) 调度器通过API Server查看未调度（bind）的Pod列表，循环遍历地为每个Pod分配节点，尝试为Pod分配节点。调度过程分为2个阶段：</p>\n<ul>\n<li><p>第一阶段：预选过程，过滤节点，调度器用一组规则过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉。</p>\n</li>\n<li><p>第二阶段：优选过程，节点优先级打分，对第一步筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把容一个Replication Controller的副本分布到不同的主机上，使用最低负载的主机等。</p>\n</li>\n</ul>\n</li>\n<li><p>4) 选择主机：选择打分最高的节点，进行binding操作，结果存储到etcd中。</p>\n</li>\n<li><p>5) 所选节点对于的kubelet根据调度结果执行Pod创建操作。</p>\n</li>\n</ul>\n<p>Predicates是用来形容主机匹配Pod所需要的资源，如果没有任何主机满足该Predicates，则该Pod会被挂起，直到有节点</p>\n<p><br/></p>\n<p><strong>预选（Predicates）与优选（Priorites）的策略罗列如下：</strong></p>\n<ul>\n<li><p>预选（Predicates）</p>\n<ul>\n<li>1.NoDiskConflict: pod所需的卷是否和节点已存在的卷冲突, 如果节点已经挂载了某个卷，其它同样使用这个卷的pod不能再调度到这个主机上，例如ISCSI禁止两个Pod分享相同的IQN/LUN与Target。</li>\n<li>2.NoVolumeZoneConflict: 检查给定的zone限制前提下，检查如果在此主机上部署Pod是否存在卷冲突。</li>\n<li>3.GeneralPredicates: 包含一些基本的筛选规则，主要考虑 Kubernetes 资源是否充足，比如 CPU 和 内存 是否足够，端口是否冲突、selector 是否匹配等：</li>\n<li>4.PodFitsResources: 检查节点是否有足够资源（例如 CPU、内存与GPU等）满足一个Pod的运行需求。</li>\n<li>5.PodFitsHostPorts: 检查Pod容器所需的HostPort是否已被节点上其它容器或服务占用。</li>\n<li>6.PodSelectorMatches：检查主机的标签是否满足Pod的selector, 包括NodeAffinity和nodeSelector中定义的标签。</li>\n<li>7.MatchNodeSelector: 检查节点标签（label）是否匹配Pod的nodeSelector属性要求。</li>\n<li><p>8.HostName: 检查节点是否满足PodSpec的NodeName字段中指定节点主机名，不满足节点的全部会被过滤掉。</p>\n</li>\n<li><p>9.MaxGCEPDVolumeCount: 确保已挂载的GCE存储卷不超过预设的最大值（GCE默认值最大存储卷值为16，</p>\n</li>\n<li>10.MaxAzureDiskVolumeCount: 确保已挂载的Azure存储卷不超过设置的最大值。</li>\n<li>11.CheckNodeMemoryPressure: 判断节点是否已经进入到内存压力状态，如果是则只允许调度内存为0标记的Pod</li>\n<li>12.CheckNodeDiskPressure : 判断节点是否已经进入到磁盘压力状态，如果是则不调度新的Pod。</li>\n<li>13.PodToleratesNodeTaints : 根据 taints 和 toleration 的关系判断Pod是否可以调度到节点上Pod是否满足节点容忍的一些条件。</li>\n</ul>\n</li>\n<li>优选（Priorites）: Kubernetes用一组优先级函数处理每一个通过预选的节点,每一个优先级函数会返回一个0-10的分数，分数越高表示节点越优， 同时每一个函数也会对应一个表示权重的值 <code>finalScoreNode = (weight1 * priorityFunc1) + (weight2 * priorityFunc2) + … + (weightn * priorityFuncn)</code><ul>\n<li>1.LeastRequestedPriority: 节点的优先级就由节点空闲资源与节点总容量的比值，即由（总容量-节点上Pod的容量总和-新Pod的容量）/总容量）来决定。即CPU和内存具有相同权重，资源空闲比越高的节点得分越高。<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cpu((capacity – sum(requested)) * 10 / capacity) + memory((capacity – sum(requested)) * 10 / capacity) / 2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 例如CPU的可用资源为100，运行容器申请的资源为15，则cpu分值为8.5分，内存可用资源为100，运行容器申请资源为20，则内存分支为8分。则此评价规则在此节点的分数为(8.5 +8) / 2 = 8.25分。</span></span><br></pre></td></tr></table></figure></li>\n<li>2.BalancedResourceAllocation : CPU和内存使用率越接近的节点权重越高，该策略不能单独使用，必须和<code>LeastRequestedPriority</code>组合使用，尽量选择在部署Pod后各项资源更均衡的机器。</li>\n<li>3.InterPodAffinityPriority : 通过迭代 weightedPodAffinityTerm 的元素计算和，并且如果对该节点满足相应的PodAffinityTerm，则将 “weight” 加到和中，具有最高和的节点是最优选的。 </li>\n<li>4.SelectorSpreadPriority：为了更好的容灾，对同属于一个service、replication controller或者replica的多个Pod副本，尽量调度到多个不同的节点上。</li>\n<li>5.NodeAffinityPriority：Kubernetes调度中的亲和性机制。</li>\n<li>6.NodePreferAvoidPodsPriority（权重1W）：如果 节点的 Anotation 没有设置 <code>key-value:scheduler. alpha.kubernetes.io/ preferAvoidPods = &quot;.&quot;</code>，则节点对该 policy 的得分就是10分，加上权重10000，那么该node对该policy的得分至少10W分</li>\n<li>7.TaintTolerationPriority : 使用 Pod 中 tolerationList 与 节点 Taint 进行匹配，配对成功的项越多，则得分越低。</li>\n<li>8.ImageLocalityPriority: 根据Node上是否存在一个pod的容器运行所需镜像大小对优先级打分，分值为0-10。</li>\n<li>9.EqualPriority : EqualPriority 是一个优先级函数，它给予所有节点相等权重。</li>\n<li>10.MostRequestedPriority : 在 ClusterAutoscalerProvider 中，替换 LeastRequestedPriority，给使用多资源的节点，更高的优先级<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(cpu(10 sum(requested) / capacity) + memory(10 sum(requested) / capacity)) / 2</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p>最后会把表格中按照节点把优先级函数的权重列表相加，得到最终节点的分值。上面代码就是这个过程，中间过程可以并发计算（下文图中的workQueue）以加快速度。</p>\n<table>\n<thead>\n<tr>\n<th>…</th>\n<th>node1</th>\n<th>node2</th>\n<th>…</th>\n<th>Noden</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PriorityFunc1</td>\n<td>S(1,1)</td>\n<td>S(1,2)</td>\n<td>…</td>\n<td>S(1,N)</td>\n</tr>\n<tr>\n<td>PriorityFunc2</td>\n<td>S(2,1)</td>\n<td>S(1,2)</td>\n<td>…</td>\n<td>S(2,N)</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n</tr>\n<tr>\n<td>PriorityFuncM</td>\n<td>S(2,1)</td>\n<td>S(1,2)</td>\n<td>…</td>\n<td>S(2,N)</td>\n</tr>\n<tr>\n<td>Result</td>\n<td>Score1</td>\n<td>Score2</td>\n<td>…</td>\n<td>ScoreN</td>\n</tr>\n</tbody>\n</table>\n<p><br/></p>\n<p><strong>自定义调度</strong><br>描述: 我们可以根据实际环境进行相应的调整，方便用户对调度的定制与二次开发。</p>\n<ul>\n<li><p>方式1.定制<code>预选</code>和<code>优选</code>策略<br>我们可以在kube-schduler启动时加入–policy-config-file参数可以指定调度策略文件，例如用户可以根据需要进行<code>组装Predicates和Priority函数</code>，即可以选择不同的过滤含税和优先级函数，控制优先级含税的权限，调整过滤函数的顺序都会影响调度过程。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">\"kind\"</span> : <span class=\"string\">\"Policy\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"apiVersion\"</span> : <span class=\"string\">\"v1\"</span>,</span><br><span class=\"line\"><span class=\"string\">\"predicates\"</span> : [</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"PodFitsHostPorts\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"PodFitsResources\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"NoDiskConflict\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"NoVolumeZoneConflict\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"MatchNodeSelector\"</span>&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"HostName\"</span>&#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\"><span class=\"string\">\"priorities\"</span> : [</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"LeastRequestedPriority\"</span>, <span class=\"string\">\"weight\"</span> : 1&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"BalancedResourceAllocation\"</span>, <span class=\"string\">\"weight\"</span> : 1&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"ServiceSpreadingPriority\"</span>, <span class=\"string\">\"weight\"</span> : 1&#125;,</span><br><span class=\"line\">    &#123;<span class=\"string\">\"name\"</span> : <span class=\"string\">\"EqualPriority\"</span>, <span class=\"string\">\"weight\"</span> : 1&#125;</span><br><span class=\"line\">    ],</span><br><span class=\"line\"><span class=\"string\">\"hardPodAffinitySymmetricWeight\"</span> : 10</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>方式2.自定义Priority和Predicate: 即Kubernetes还允许用户编写自己的Priority 和 Predicate函数，而并非上面的方式一是对已有的调度模块进行组合。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 过滤函数的接口：</span></span><br><span class=\"line\">// FitPredicate is a <span class=\"keyword\">function</span> that indicates <span class=\"keyword\">if</span> a pod fits into an existing node.</span><br><span class=\"line\">// The failure information is given by the error.</span><br><span class=\"line\"><span class=\"built_in\">type</span> FitPredicate func(pod *v1.Pod, meta PredicateMetadata, nodeInfo *schedulercache.NodeInfo) (bool, []PredicateFailureReason, error)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>在plugin/pkg/scheduler/algorithm/predicates/predicates.go文件中编写对象实现上面接口。</li>\n<li>编写完过滤函数之后进行注册，让 kube-scheduler 启动的时候知道它的存在，注册部分可以在 <code>plugin/pkg/scheduler/algorithmprovider/defaults/defaults.go</code>完成，可以参考其他过滤函数（例如PodFitsHostPorts）的注册代码：<code>kubernetes/plugin/pkg/scheduler/algorithmprovider/defaults/defaults.gofactory.RegisterFitPredicate(&quot;PodFitsPorts&quot;, predicates.PodFitsHostPorts)</code>。</li>\n<li>在 –policy-config-file把自定义过滤函数写进去，kube-scheduler运行时可以执行自定义调度逻辑了。</li>\n<li>自定义优先级函数，实现过程和过滤函数类似。</li>\n</ul>\n</li>\n<li><p>方式3.编写自己的调度器: Kubernetes也允许用户编写自己的调度器组件，并在创建资源的时候引用它。多个调度器可以同时运行和工作，只要名字不冲突。<br>描述: 使用某个调度器就是在Pod的spec.schedulername字段中填写上调度器的名字。Kubernetes提供的调度器名字是default，如果自定义的调度器名字是my-scheduler，那么只有当spec.schedulername字段是my-scheduler才会被调度。</p>\n<ul>\n<li>调度器最核心的逻辑并不复杂 : Scheduler首先监听apiserver ，获取没有被调度的Pod和全部节点列表，而后根据一定的算法和策略从节点中选择一个作为调度结果，最后向apiserver中写入binding 。</li>\n</ul>\n</li>\n</ul>\n<p>简单调度脚本:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\">SERVER=<span class=\"string\">'localhost:8001'</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> PODNAME <span class=\"keyword\">in</span> $(kubectl --server <span class=\"variable\">$SERVER</span> get pods -o json | jq <span class=\"string\">'.items[] | select(.spec.schedulerName == \"my-scheduler\") | select(.spec.nodeName == null) | .metadata.name'</span> | tr -d <span class=\"string\">'\"'</span>)</span><br><span class=\"line\">;</span><br><span class=\"line\">    <span class=\"keyword\">do</span></span><br><span class=\"line\">        NODES=($(kubectl --server <span class=\"variable\">$SERVER</span> get nodes -o json | jq <span class=\"string\">'.items[].metadata.name'</span> | tr -d <span class=\"string\">'\"'</span>))</span><br><span class=\"line\">        NUMNODES=<span class=\"variable\">$&#123;#NODES[@]&#125;</span></span><br><span class=\"line\">        CHOSEN=<span class=\"variable\">$&#123;NODES[$[ $RANDOM % $NUMNODES ]]&#125;</span></span><br><span class=\"line\">        curl --header <span class=\"string\">\"Content-Type:application/json\"</span> --request POST --data <span class=\"string\">'&#123;\"apiVersion\":\"v1\", \"kind\": \"Binding\", \"metadata\": &#123;\"name\": \"'</span><span class=\"variable\">$PODNAME</span><span class=\"string\">'\"&#125;, \"target\": &#123;\"apiVersion\": \"v1\", \"kind\"</span></span><br><span class=\"line\"><span class=\"string\">: \"Node\", \"name\": \"'</span><span class=\"variable\">$CHOSEN</span><span class=\"string\">'\"&#125;&#125;'</span> http://<span class=\"variable\">$SERVER</span>/api/v1/namespaces/default/pods/<span class=\"variable\">$PODNAME</span>/binding/</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"Assigned <span class=\"variable\">$PODNAME</span> to <span class=\"variable\">$CHOSEN</span>\"</span></span><br><span class=\"line\">    <span class=\"keyword\">done</span></span><br><span class=\"line\">    sleep 1</span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl  get nodes -o json | jq <span class=\"string\">'.items[].metadata.name'</span> | tr -d <span class=\"string\">'\"'</span></span><br><span class=\"line\">weiyigeek-107</span><br><span class=\"line\">weiyigeek-108</span><br><span class=\"line\">weiyigeek-109</span><br><span class=\"line\">weiyigeek-223</span><br><span class=\"line\">weiyigeek-224</span><br><span class=\"line\">weiyigeek-225</span><br><span class=\"line\">weiyigeek-226</span><br></pre></td></tr></table></figure><br>脚本解释: 它通过kubectl命令从apiserver获取未调度的Pod（<code>spec.schedulerName 是my-scheduler，并且spec.nodeName 为空</code>），同样地，用kubectl从apiserver获取nodes的信息，然后随机选择一个node作为调度结果，并写入到apiserver中。我们可通过<code>kubectl describe pod pod_name</code>查看一个Pod采用的调度器;</p>\n<BR/>\n\n<p>Tips: 当然要想编写一个生产级别的调度器，要完善的东西还很多比如：</p>\n<ul>\n<li><p>调度过程中需要保证Pod是最新的，这个例子中每次调度 pod 的时候，它在 apiserver 中的内容可能已经发生了变化</p>\n</li>\n<li><p>调度过程需要考虑资源等因素（节点的资源利用率，存储和网络的信息等）</p>\n</li>\n<li><p>尽量提高调度的性能（使用并发来提高调度的性能）</p>\n</li>\n</ul>\n<p><br></p>\n<p><strong>调度器总结:</strong></p>\n<p>描述: 没有什么事情是完美的，调度器也一样，用户可结合实际业务服务特性和需求，利用或定制Kubernetes调度策略，更好满足业务服务的需求。 </p>\n<p><br></p>\n<hr>\n<h2 id=\"0x03-服务质量-QoS\"><a href=\"#0x03-服务质量-QoS\" class=\"headerlink\" title=\"0x03 服务质量(QoS)\"></a>0x03 服务质量(QoS)</h2><p>描述: 什么是QoS?<br>即: Quality Of Service 服务质量;</p>\n<h3 id=\"resources-配额限制\"><a href=\"#resources-配额限制\" class=\"headerlink\" title=\"resources - 配额限制\"></a>resources - 配额限制</h3><p>描述: Kubernetes 对 资源的限制实际上是通过 cgroup 来控制的，cgroup是容器的一组用来控制内核如何运行进程的相关属性集合，针对内存、CPU 和network、存储以及各种设备都有对应的 cgroup。</p>\n<p>默认情况下，Pod运行没有CPU和内存的限额，意味着系统中的任何Pod将能够像执行该 Pod 所在的节点一样，消耗足够多的 CPU和内存。在生产环境中一般会针对某些特定应用的 pod 资源进行资源限制，常常资源限制是通过<code>resources的 requests 和 limits</code>来实现；</p>\n<p>Tips： Requests 申请的范围是0到Node节点的最大配置(<code>0&lt;= request&lt;=NodeAllocatable</code>) ,而Limit申请范围是Request到无限(<code>Request&lt;=limit&lt;=Infinity</code>)</p>\n<p>Kuberneters 资源限制可以针对以下对象:</p>\n<ul>\n<li>Container 层面 : 对容器使用的CPU与内存的限制;</li>\n<li>Pod 层面 : Pod 内所有容器进行限制; </li>\n<li>Namespace 层 : 限制一个名称空间全部资源对象使用总和，包括Pod数量、RC数量、Service数量、ResourceQuota数量,Secret数量以及PV数量等</li>\n</ul>\n<p>Tips :<code>ResourceQuota / LimitRange</code> - 在名称空间那节讲述过</p>\n<p><br/></p>\n<p><strong>QoS 分类</strong><br>描述: Kubelet 提供QoS服务质量管理，支持系统级别的OOM控制.在K8s中Pod的QoS级别Guaranteed(保证)、Burstable(瓶颈)、Best-Effort(尽力而为)</p>\n<ul>\n<li>1.Guaranteed: Pod清单中的所有容器都必须统一设置Limits, 并且如果设置了Reuqest所用容器都需设置一样;</li>\n<li>2.Burstable: Pod 清单中只要有一个容器的Reuquests与Limits的设置不同即为它</li>\n<li>3.Best-Effort: 缺省如果Pod清单中的container对象中resources未设置requests与Limit即为它</li>\n</ul>\n<p>Tips ：如果一个容器只指明Limit而未设定Request则其值为Limit的值</p>\n<p><br/></p>\n<p><strong>基础示例</strong></p>\n<ul>\n<li>示例1.对于Pod资源的<code>请求(requests)与限制(limits)</code>，可以简单理解为初始值和最大值<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  containers:</span></span><br><span class=\"line\"><span class=\"attr\">  - image:</span> <span class=\"attr\">nginx:latest</span></span><br><span class=\"line\"><span class=\"attr\">    imagePullPolicy:</span> <span class=\"string\">Always</span></span><br><span class=\"line\"><span class=\"attr\">    name:</span> <span class=\"string\">auth</span></span><br><span class=\"line\"><span class=\"attr\">    ports:</span></span><br><span class=\"line\"><span class=\"attr\">    - containerPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\"><span class=\"attr\">      protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\"><span class=\"attr\">    resources:</span>   <span class=\"comment\"># 关键点</span></span><br><span class=\"line\"><span class=\"attr\">      limits:</span>    <span class=\"comment\"># limits 为最高请求的资源值</span></span><br><span class=\"line\"><span class=\"attr\">        cpu:</span> <span class=\"string\">\"4\"</span></span><br><span class=\"line\"><span class=\"attr\">        memory:</span> <span class=\"number\">2</span><span class=\"string\">Gi</span></span><br><span class=\"line\"><span class=\"attr\">      requests:</span>  <span class=\"comment\"># requests 要分分配的资源</span></span><br><span class=\"line\"><span class=\"attr\">        cpu:</span> <span class=\"number\">250</span><span class=\"string\">m</span></span><br><span class=\"line\"><span class=\"attr\">        memory:</span> <span class=\"number\">250</span><span class=\"string\">Mi</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><br/></p>\n<ul>\n<li>示例2.对于名称空间的资源限制<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># (1) 计算资源配额</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span> </span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ResourceQuota</span> </span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">compute-resources</span> </span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">spark-cluster</span> </span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  hard:</span></span><br><span class=\"line\"><span class=\"attr\">    pods:</span> <span class=\"string\">\"20\"</span></span><br><span class=\"line\">    <span class=\"string\">requests.cpu:</span> <span class=\"string\">\"20\"</span></span><br><span class=\"line\">    <span class=\"string\">requests.memory:</span> <span class=\"number\">100</span><span class=\"string\">Gi</span> </span><br><span class=\"line\">    <span class=\"string\">limits.cpu:</span> <span class=\"string\">\"40\"</span></span><br><span class=\"line\">    <span class=\"string\">limits.memory:</span> <span class=\"number\">200</span><span class=\"string\">Gi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) 配置对象数量配额限制</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span> </span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ResourceQuota</span> </span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">object-counts</span> </span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">spark-cluster</span> </span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  hard:</span></span><br><span class=\"line\"><span class=\"attr\">    configmaps:</span> <span class=\"string\">\"10\"</span></span><br><span class=\"line\"><span class=\"attr\">    persistentvolumeclaims:</span> <span class=\"string\">\"4\"</span></span><br><span class=\"line\"><span class=\"attr\">    replicationcontrollers:</span> <span class=\"string\">\"20\"</span></span><br><span class=\"line\"><span class=\"attr\">    secrets:</span> <span class=\"string\">\"10\"</span></span><br><span class=\"line\"><span class=\"attr\">    services:</span> <span class=\"string\">\"10\"</span></span><br><span class=\"line\">    <span class=\"string\">services.loadbalancers:</span> <span class=\"string\">\"2\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) 配置 CPU和内存 LimitRange</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span> </span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">LimitRange</span> </span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">mem-limit-range</span> </span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  limits:</span> </span><br><span class=\"line\"><span class=\"attr\">  - default:</span>        <span class=\"comment\"># default 即 limit 的值 </span></span><br><span class=\"line\"><span class=\"attr\">      memory:</span> <span class=\"number\">50</span><span class=\"string\">Gi</span> </span><br><span class=\"line\"><span class=\"attr\">      cpu:</span> <span class=\"number\">5</span> </span><br><span class=\"line\"><span class=\"attr\">    defaultRequest:</span> <span class=\"comment\"># defaultRequest 即 request 的值</span></span><br><span class=\"line\"><span class=\"attr\">      memory:</span> <span class=\"number\">1</span><span class=\"string\">Gi</span> </span><br><span class=\"line\"><span class=\"attr\">      cpu:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">    type:</span> <span class=\"string\">Container</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><br></p>\n<h3 id=\"资源压缩\"><a href=\"#资源压缩\" class=\"headerlink\" title=\"资源压缩\"></a>资源压缩</h3><p>描述: k8s将资源压缩分为两类，一类是可压缩资源，另外一类是不可压缩资源。</p>\n<ul>\n<li>可压缩资源: 例如<code>CPU资源</code>当Pod容器超过设置的Limit值, Pod中进程使用CPU会被限制但不会被Kill;</li>\n<li>不可压缩资源: 例如<code>内存资源</code>与<code>磁盘资源</code>当资源不足时其会先Kill掉优先级较低的Pod。</li>\n</ul>\n<p>上面的方式在实际使用过程中是通过OOM分数值来实现的 OOM 分数值从 0-1000 区间范围之内, 其分值是根据OOM_ADJ参数计算得出;</p>\n<ul>\n<li>Guranteed 级别的Pod其OOM_ADJ参数设置为-998, 如果系统用完全部内存且没有Burstable与BestEffort类型的容器可以被Kill时将会被Kill</li>\n<li>Burstable 级别的Pod其OOM_ADJ参数设置为2-999, 如果系统用完全部内容且没有BestEffort可以被Kill时将被Kill;</li>\n<li>BestEffort 级别的Pod其OOM_ADJ参数设置为1000, 当系统全部内存被用完时将会被Kill;</li>\n</ul>\n<p>Tips :对于K8s的保留资源比如Kubelet、docker其OOM_ADJ参数设置为-999 (<code>表示永远不会被Kill</code>)</p>\n<p>Tips : 对于OOM_ADJ参数来说如果其越大则计算出的OOM分数越高，则表明该Pod优先级就越低当出现资源竞争时就会被越早Kill；</p>\n<p>QoS优先级: 从低到高的有 <code>BestEffort &lt;  Burstable &lt; Guranteed</code> Pod</p>\n<p>Tips : 如果Pod进程因使用超过预先设定的Limit而非Node资源紧张，系统一般倾向于其原所在的机器上重启该Container或者本机以及其它节点上创建一个Pod。</p>\n<p><br></p>\n<p><strong>QoS 使用建议</strong><br>描述: 如果资源充足或者想更好的提高资源利用率可以将QoS Pods类型设置为Guarantee用计算资源换业务性能和稳定性、减少排查问题时间和成本。而其它服务根据重要程度可分别设置为Burstable或BestEffort，例如 Filebeat 业务;</p>\n","comments":true,"excerpt":"[TOC]","categories":[{"name":"Containers","path":"api/categories/Containers.json"},{"name":"OperationTools","path":"api/categories/OperationTools.json"}],"tags":[{"name":"k8s","path":"api/tags/k8s.json"}]}