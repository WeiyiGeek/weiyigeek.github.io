{"title":"23-Kubernetes之企业运维实践操作笔记","slug":"虚拟云容/云容器/Kubernetes/23-Kubernetes扩展学习实践笔记","date":"2022-12-18T02:37:47.000Z","updated":"2023-02-06T14:03:37.756Z","url":"2022/12-18-691.html","path":"api/articles/2022/12-18-691.html.json","covers":null,"content":"<p>[TOC]</p>\n<a id=\"more\"></a>\n<h2 id=\"0x00-实操1-记一次-Kubernetes-V1-23-x-集群证书过期或者延期处理操作实践案例\"><a href=\"#0x00-实操1-记一次-Kubernetes-V1-23-x-集群证书过期或者延期处理操作实践案例\" class=\"headerlink\" title=\"0x00 实操1.记一次 Kubernetes V1.23.x 集群证书过期或者延期处理操作实践案例\"></a>0x00 实操1.记一次 Kubernetes V1.23.x 集群证书过期或者延期处理操作实践案例</h2><p>描述: 下述操作主要用于处理K8S证书<code>已过期</code>或者<code>即将过期的kubernetes集群</code>实践案例，当然网上百度、CSDN（捡垃圾）大多数方法均是一知半解，不同的K8S版本操作有些许不同，若全部按照其操作，有可能你需要重建K8S了，别问我怎么知道的，因为我踩过坑( Ĭ ^ Ĭ )，所以建议在遇到问题时先查询K8S官方文档。</p>\n<h3 id=\"1-前言简述\"><a href=\"#1-前言简述\" class=\"headerlink\" title=\"1.前言简述\"></a>1.前言简述</h3><p>在年后上班的第一天，我像往常一样，登录到K8S集群之中依次检查应用，在检查开发测试环境的k8s集群时，发现执行kubectl命令报证书过期错误，顿时心情都不好了，却也无可奈何，只能进行证书续签了，由于是高可用集群遇到了许多坑，为了方便自己以及广大的运维工作者，解决相关问题，遂整理了此篇文章。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 连接 Api-server 失败，报证书已过期不可用。</span></span><br><span class=\"line\">$ kubectl get node,pod</span><br><span class=\"line\">Unable to connect to the server: x509: certificate has expired or is not yet valid: current time 2023-01-31T16:55:27+08:00 is after 2023-01-16T04:47:34Z</span><br></pre></td></tr></table></figure>\n<p><br/></p>\n<h3 id=\"2-实践环境\"><a href=\"#2-实践环境\" class=\"headerlink\" title=\"2.实践环境\"></a>2.实践环境</h3><p><strong>集群版本及其节点描述:</strong><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 集群版本</span></span><br><span class=\"line\">$ kubeadm version</span><br><span class=\"line\">kubeadm version: &amp;version.Info&#123;Major:<span class=\"string\">\"1\"</span>, Minor:<span class=\"string\">\"23\"</span>, GitVersion:<span class=\"string\">\"v1.23.1\"</span>, GitCommit:<span class=\"string\">\"86ec240af8cbd1b60bcc4c03c20da9b98005b92e\"</span>, GitTreeState:<span class=\"string\">\"clean\"</span>, BuildDate:<span class=\"string\">\"2021-12-16T11:39:51Z\"</span>, GoVersion:<span class=\"string\">\"go1.17.5\"</span>, Compiler:<span class=\"string\">\"gc\"</span>, Platform:<span class=\"string\">\"linux/amd64\"</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 集群节点</span></span><br><span class=\"line\">$ data -s <span class=\"string\">\"2023-01-01\"</span></span><br><span class=\"line\">$ kubectl get node</span><br><span class=\"line\">NAME       STATUS   ROLES                  AGE    VERSION</span><br><span class=\"line\">weiyigeek-107   Ready    control-plane,master   381d   v1.23.1</span><br><span class=\"line\">weiyigeek-108   Ready    control-plane,master   380d   v1.23.1</span><br><span class=\"line\">weiyigeek-109   Ready    control-plane,master   380d   v1.23.1</span><br><span class=\"line\">weiyigeek-223   Ready    work                   380d   v1.23.1</span><br><span class=\"line\">weiyigeek-224   Ready    work                   380d   v1.23.1</span><br><span class=\"line\">weiyigeek-225   Ready    work                   381d   v1.23.1</span><br><span class=\"line\">weiyigeek-226   Ready    work                   220d   v1.23.1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 论保存过程配置文件的重要性，在搭建k8s集群时建议备份资源清单。</span></span><br><span class=\"line\">kubectl -n kube-system get cm kubeadm-config -o yaml &gt; kubeadm-config-v1.23.1.yaml</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<h3 id=\"3-证书续签\"><a href=\"#3-证书续签\" class=\"headerlink\" title=\"3.证书续签\"></a>3.证书续签</h3><p><strong>高可用K8S集群，证书续签操作流程步骤如下:</strong><br>0.在进行操作前一定要进行备份，便于回退处理，此处我在三台master节点之一的<code>weiyigeek-107</code>机器上操作，后续默认也在此机器上操作，若需在其他机器上操作我会进行说明<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 备份旧的配置文件。</span></span><br><span class=\"line\">cp -a /etc/kubernetes&#123;,.bak&#125;</span><br><span class=\"line\">cp -a /var/lib/kubelet&#123;,.bak&#125;</span><br><span class=\"line\">cp -a /var/lib/etcd /var/lib/etcd.bak</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 备份集群配置 (当证书到期时是无法执行的此步骤可跳过)但可以利用date命令将系统时间设置到过期前。</span></span><br><span class=\"line\">data -s <span class=\"string\">\"2023-01-01\"</span> || timedatectl <span class=\"built_in\">set</span>-time <span class=\"string\">\"2023-01-01\"</span></span><br><span class=\"line\">kubectl -n kube-system get cm kubeadm-config -o yaml &gt; kubeadm-init-config.yaml     <span class=\"comment\"># 后续会用到此原始配置文件。</span></span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>1.使用openssl命令查询单个证书可用时间及其相关信息<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># k8s 集群的 ca.crt 证书有效期为 十年</span></span><br><span class=\"line\"><span class=\"comment\"># k8s 集群的 apiserver.crt 、kubelet.crt、etcd.crt 证书默认有效期为 一年，当然你也可以自行修改为十年（后续有文章进行讲解）</span></span><br><span class=\"line\">$ <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> $(ls /etc/kubernetes/pki/*.crt /etc/kubernetes/pki/etcd/*.crt); <span class=\"keyword\">do</span> <span class=\"built_in\">echo</span> <span class=\"string\">\"===== <span class=\"variable\">$i</span> =====\"</span>; openssl x509 -<span class=\"keyword\">in</span> <span class=\"variable\">$i</span> -text -noout | grep -A 3 <span class=\"string\">'Validity'</span> ; <span class=\"keyword\">done</span></span><br><span class=\"line\"><span class=\"comment\"># for item in `find /etc/kubernetes/pki -maxdepth 2 -name \"*.crt\"`;do echo ======================$item===============;openssl x509 -in $item -text -noout| grep -A 3 Not;done</span></span><br><span class=\"line\">===== /etc/kubernetes/pki/apiserver.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:56 2022 GMT  <span class=\"comment\"># 颁发时间</span></span><br><span class=\"line\">            Not After : Jan 15 10:42:57 2023 GMT  <span class=\"comment\"># 到期时间</span></span><br><span class=\"line\">        Subject: CN = kube-apiserver              <span class=\"comment\"># 通用名称</span></span><br><span class=\"line\">===== /etc/kubernetes/pki/apiserver-etcd-client.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 15 10:42:59 2023 GMT</span><br><span class=\"line\">        Subject: O = system:masters, CN = kube-apiserver-etcd-client</span><br><span class=\"line\">===== /etc/kubernetes/pki/apiserver-kubelet-client.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:56 2022 GMT</span><br><span class=\"line\">            Not After : Jan 15 10:42:57 2023 GMT</span><br><span class=\"line\">        Subject: O = system:masters, CN = kube-apiserver-kubelet-client</span><br><span class=\"line\">===== /etc/kubernetes/pki/ca.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:56 2022 GMT</span><br><span class=\"line\">            Not After : Jan 13 10:42:56 2032 GMT</span><br><span class=\"line\">        Subject: CN = kubernetes</span><br><span class=\"line\">===== /etc/kubernetes/pki/etcd/ca.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 13 10:42:58 2032 GMT</span><br><span class=\"line\">        Subject: CN = etcd-ca</span><br><span class=\"line\">===== /etc/kubernetes/pki/etcd/healthcheck-client.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 15 10:42:59 2023 GMT</span><br><span class=\"line\">        Subject: O = system:masters, CN = kube-etcd-healthcheck-client</span><br><span class=\"line\">===== /etc/kubernetes/pki/etcd/peer.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 15 10:42:59 2023 GMT</span><br><span class=\"line\">        Subject: CN = weiyigeek-107</span><br><span class=\"line\">===== /etc/kubernetes/pki/etcd/server.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 15 10:42:59 2023 GMT</span><br><span class=\"line\">        Subject: CN = weiyigeek-107</span><br><span class=\"line\">===== /etc/kubernetes/pki/front-proxy-ca.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 13 10:42:58 2032 GMT</span><br><span class=\"line\">        Subject: CN = front-proxy-ca</span><br><span class=\"line\">===== /etc/kubernetes/pki/front-proxy-client.crt =====</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan 15 10:42:58 2022 GMT</span><br><span class=\"line\">            Not After : Jan 15 10:42:58 2023 GMT</span><br><span class=\"line\">        Subject: CN = front-proxy-client</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>2.查看当前集群证书相关信息，包含所有证书名称以及证书颁发机构、到期时间等, 此处可以看到均已经到期。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo kubeadm certs check-expiration</span><br><span class=\"line\">  <span class=\"comment\"># [check-expiration] Reading configuration from the cluster...</span></span><br><span class=\"line\">  <span class=\"comment\"># [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'</span></span><br><span class=\"line\">  <span class=\"comment\"># [check-expiration] Error reading configuration from the Cluster. Falling back to default configuration</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># CERTIFICATE                EXPIRES(过期时间)         RESIDUAL TIME(剩余时间)   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED(是否是外部管理)</span></span><br><span class=\"line\">  <span class=\"comment\"># admin.conf                 Jan 15, 2023 10:43 UTC   &lt;invalid&gt;       ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># apiserver                  Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># apiserver-etcd-client      Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># apiserver-kubelet-client   Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># controller-manager.conf    Jan 15, 2023 10:43 UTC   &lt;invalid&gt;       ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-healthcheck-client    Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-peer                  Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-server                Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># front-proxy-client         Jan 15, 2023 10:42 UTC   &lt;invalid&gt;       front-proxy-ca          no</span></span><br><span class=\"line\">  <span class=\"comment\"># scheduler.conf             Jan 15, 2023 10:43 UTC   &lt;invalid&gt;       ca                      no</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span></span><br><span class=\"line\">  <span class=\"comment\"># ca                      Jan 13, 2032 10:42 UTC   8y              no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-ca                 Jan 13, 2032 10:42 UTC   8y              no</span></span><br><span class=\"line\">  <span class=\"comment\"># front-proxy-ca          Jan 13, 2032 10:42 UTC   8y              no</span></span><br></pre></td></tr></table></figure></p>\n<p>温馨提示: 如果 Etcd 是由Kubeadm创建和托管的此时也可以通过下面的方式进行证书的续期, 如果是外部高可用环境管理需要则手动进行更新证书配置;</p>\n<p><br/></p>\n<p>3.使用 certs 的 renew 子命令刷新集群所有证书的到期时间进行再续期一年, 此处 –config 参数指定的是我当初创建集群的初始化配置清单，若没有可以安装步骤0进行生成。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/.k8s$ sudo kubeadm certs renew all --config=./kubeadm-init-config.yaml</span><br><span class=\"line\">  <span class=\"comment\"># W1212 17:17:16.721037 1306627 configset.go:348] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed  # 嵌入在kubeconfig文件中的证书，供管理员使用，并对kubeadm本身进行更新 (admin.conf )</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate for serving the Kubernetes API renewed               # 更新Kubernetes API服务证书</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate the apiserver uses to access etcd renewed            # 服务器访问etcd所使用的证书已更新</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate for the API server to connect to kubelet renewed     # API服务器连接到kubelet的证书已更新</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate embedded in the kubeconfig file for the controller manager to use renewed  # 证书嵌入在kubeconfig文件中，供控制器管理器使用更新 (controller-manager.conf)</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate for liveness probes to healthcheck etcd renewed        # 健康检查etcd激活探针证书续期</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate for etcd nodes to communicate with each other renewed  # 用于etcd节点之间通信的证书更新</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate for serving etcd renewed                               # 续期etcd“服务证书”</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate for the front proxy client renewed                     # 前代理客户端的证书更新</span></span><br><span class=\"line\">  <span class=\"comment\"># certificate embedded in the kubeconfig file for the scheduler manager to use renewed # 证书嵌入在kubeconfig文件中，供调度器管理器使用更新 (scheduler.conf  )</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 若看到已完成续订证书，您必须重新启动kube apiserver、kube控制器管理器、kube调度器等，以便它们可以使用新证书，表示证书续期成功</span></span><br><span class=\"line\">Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检查证书续签以及到期时间</span></span><br><span class=\"line\">~/.k8s$ kubeadm certs check-expiration</span><br><span class=\"line\">  <span class=\"comment\"># [check-expiration] Reading configuration from the cluster...</span></span><br><span class=\"line\">  <span class=\"comment\"># [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span></span><br><span class=\"line\">  <span class=\"comment\"># admin.conf                 Jan 31, 2024 09:26 UTC   364d            ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># apiserver                  Jan 31, 2024 09:26 UTC   364d            ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># apiserver-etcd-client      Jan 31, 2024 09:26 UTC   364d            etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># apiserver-kubelet-client   Jan 31, 2024 09:26 UTC   364d            ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># controller-manager.conf    Jan 31, 2024 09:26 UTC   364d            ca                      no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-healthcheck-client    Jan 31, 2024 09:26 UTC   364d            etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-peer                  Jan 31, 2024 09:26 UTC   364d            etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-server                Jan 31, 2024 09:26 UTC   364d            etcd-ca                 no</span></span><br><span class=\"line\">  <span class=\"comment\"># front-proxy-client         Jan 31, 2024 09:26 UTC   364d            front-proxy-ca          no</span></span><br><span class=\"line\">  <span class=\"comment\"># scheduler.conf             Jan 31, 2024 09:26 UTC   364d            ca                      no</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span></span><br><span class=\"line\">  <span class=\"comment\"># ca                      Jan 13, 2032 10:42 UTC   8y              no</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-ca                 Jan 13, 2032 10:42 UTC   8y              no</span></span><br><span class=\"line\">  <span class=\"comment\"># front-proxy-ca          Jan 13, 2032 10:42 UTC   8y              no</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用stat命令查看 apiserver.key 与 apiserver.crt 证书修改时间</span></span><br><span class=\"line\">/etc/kubernetes/pki$ <span class=\"built_in\">stat</span> apiserver.key  apiserver.crt</span><br><span class=\"line\">  <span class=\"comment\">#   File: apiserver.key</span></span><br><span class=\"line\">  <span class=\"comment\">#   Size: 1675            Blocks: 8          IO Block: 4096   regular file</span></span><br><span class=\"line\">  <span class=\"comment\"># Device: fd00h/64768d    Inode: 3670556     Links: 1</span></span><br><span class=\"line\">  <span class=\"comment\"># Access: (0600/-rw-------)  Uid: (    0/    root)   Gid: (    0/    root)</span></span><br><span class=\"line\">  <span class=\"comment\"># Access: 2022-04-28 12:55:13.456040564 +0800 最近访问：</span></span><br><span class=\"line\">  <span class=\"comment\"># Modify: 2023-01-31 17:26:51.108767670 +0800 最近更改：</span></span><br><span class=\"line\">  <span class=\"comment\"># Change: 2023-01-31 17:26:51.108767670 +0800 最近改动：</span></span><br><span class=\"line\">  <span class=\"comment\">#   Birth: -</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\">#   File: apiserver.crt</span></span><br><span class=\"line\">  <span class=\"comment\">#   Size: 1338            Blocks: 8          IO Block: 4096   regular file</span></span><br><span class=\"line\">  <span class=\"comment\"># Device: fd00h/64768d    Inode: 3670557     Links: 1</span></span><br><span class=\"line\">  <span class=\"comment\"># Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span></span><br><span class=\"line\">  <span class=\"comment\"># Access: 2023-01-31 17:28:58.104917185 +0800</span></span><br><span class=\"line\">  <span class=\"comment\"># Modify: 2023-01-31 17:26:51.108767670 +0800</span></span><br><span class=\"line\">  <span class=\"comment\"># Change: 2023-01-31 17:26:51.108767670 +0800</span></span><br><span class=\"line\">  <span class=\"comment\">#   Birth: -</span></span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>4.完成证书更新后，此时我们需要重新生成新的K8S集群master节点所需的相关配置文件，例如 <code>/etc/kubernetes</code> 目录下的 <code>admin.conf / controller-manager.conf / kubelet.conf / scheduler.conf</code> 相关文件。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 初始化所需配置文件 </span></span><br><span class=\"line\">$ rm -rf /etc/kubernetes/*.conf</span><br><span class=\"line\">$ kubeadm init phase kubeconfig all --config=kubeadm-init-config.yaml</span><br><span class=\"line\">  <span class=\"comment\"># [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"</span></span><br><span class=\"line\">  <span class=\"comment\"># [kubeconfig] Writing \"admin.conf\" kubeconfig file</span></span><br><span class=\"line\">  <span class=\"comment\"># [kubeconfig] Writing \"kubelet.conf\" kubeconfig file</span></span><br><span class=\"line\">  <span class=\"comment\"># [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file</span></span><br><span class=\"line\">  <span class=\"comment\"># [kubeconfig] Writing \"scheduler.conf\" kubeconfig file</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可以看到文件时间已经发生变化</span></span><br><span class=\"line\">$ ls -alh /etc/kubernetes/*.conf</span><br><span class=\"line\">-rw------- 1 root root 5.6K Jan 31 21:53 /etc/kubernetes/admin.conf</span><br><span class=\"line\">-rw------- 1 root root 5.6K Jan 31 21:53 /etc/kubernetes/controller-manager.conf</span><br><span class=\"line\">-rw------- 1 root root 5.6K Jan 31 21:53 /etc/kubernetes/kubelet.conf</span><br><span class=\"line\">-rw------- 1 root root 5.5K Jan 31 21:53 /etc/kubernetes/scheduler.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 为防止 kubelet 客户端证书轮换失败，我们需要将（此处坑有点大）kubelet-client-* 进行删除，在kubelet服务重启时又会自动生成</span></span><br><span class=\"line\"><span class=\"comment\"># 如果此轮换过程失败，你可能会在 kube-apiserver 日志中看到诸如 x509: certificate has expired or is not yet valid 之类的错误</span></span><br><span class=\"line\"><span class=\"comment\"># https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert</span></span><br><span class=\"line\">rm -rf /var/lib/kubelet/pki/kubelet-client-*</span><br></pre></td></tr></table></figure></p>\n<p>补充: 若要生成其他master节点的K8S配置文件请参考如下，例如，此处是 weiyigeek-108 控制平面节点的conf配置文件。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># $ mkdir -vp /tmp/kubernetes/</span></span><br><span class=\"line\"><span class=\"comment\"># $ kubeadm init phase kubeconfig all --node-name weiyigeek-108 --kubeconfig-dir /tmp/kubernetes/</span></span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>5.按照提示将当前操作集群 master（weiyigeek-107） 节点上重启 kube-apiserver, kube-controller-manager, kube-scheduler 以及 etcd 等相关服务。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将新生成的集群连接配置文件覆盖到 ~/.kube/config </span></span><br><span class=\"line\">mkdir -p <span class=\"variable\">$HOME</span>/.kube</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'yes'</span> |  sudo cp -i /etc/kubernetes/admin.conf <span class=\"variable\">$HOME</span>/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) <span class=\"variable\">$HOME</span>/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重启 kube-apiserver, kube-controller-manager, kube-scheduler 及 etcd 等相关服务（建议一个一个pod删除，启动后再进行下一步操作）</span></span><br><span class=\"line\">kubectl -n kube-system delete pod -l <span class=\"string\">'component=kube-apiserver'</span></span><br><span class=\"line\">kubectl -n kube-system delete pod -l <span class=\"string\">'component=kube-controller-manager'</span></span><br><span class=\"line\">kubectl -n kube-system delete pod -l <span class=\"string\">'component=kube-scheduler'</span></span><br><span class=\"line\">kubectl -n kube-system delete pod -l <span class=\"string\">'component=etcd'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重启节点上 kubelet 服务</span></span><br><span class=\"line\">systemctl restart kubelet.service</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 kubelet 服务状态</span></span><br><span class=\"line\">systemctl status -l kubelet.service </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 查看 kubelet 服务运行日志有无异常（有异常请依次解决）</span></span><br><span class=\"line\">journalctl -xefu kubelet</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重启 kubelet 后 kubelet 客户端证书轮换自动生成新的 pem 证书</span></span><br><span class=\"line\">ls -alh /var/lib/kubelet/pki/kubelet-client-current.pem</span><br><span class=\"line\">  <span class=\"comment\"># lrwxrwxrwx 1 root root 59 Jan 31 22:29 /var/lib/kubelet/pki/kubelet-client-current.pem -&gt; /var/lib/kubelet/pki/kubelet-client-2023-01-31-22-29-20.pem</span></span><br></pre></td></tr></table></figure>\n<p><br/></p>\n<p>6.此时在（weiyigeek-107） 节点上运行kubectl相关命令，则不会报证书到期了，我们可正常使用相关命令.<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get nodes</span><br><span class=\"line\">  <span class=\"comment\"># NAME       STATUS   ROLES                  AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-107   Ready    control-plane,master   381d    v1.23.1   192.168.12.107   &lt;none&gt;        Ubuntu 20.04.1 LTS   5.4.0-137-generic   containerd://1.4.12</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-108   Ready    control-plane,master   57m     v1.23.1   192.168.12.108   &lt;none&gt;        Ubuntu 20.04.3 LTS   5.4.0-137-generic   containerd://1.4.12</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-109   Ready    control-plane,master   2m19s   v1.23.1   192.168.12.109   &lt;none&gt;        Ubuntu 20.04.3 LTS   5.4.0-137-generic   containerd://1.4.12</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-223   Ready    work                   380d    v1.23.1   192.168.12.223   &lt;none&gt;        Ubuntu 20.04.3 LTS   5.4.0-94-generic    containerd://1.4.12</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-224   Ready    work                   380d    v1.23.1   192.168.12.224   &lt;none&gt;        Ubuntu 20.04.3 LTS   5.4.0-42-generic    containerd://1.4.12</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-225   Ready    work                   381d    v1.23.1   192.168.12.225   &lt;none&gt;        Ubuntu 20.04.3 LTS   5.4.0-94-generic    containerd://1.4.12</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-226   Ready    work                   220d    v1.23.1   192.168.12.226   &lt;none&gt;        Ubuntu 20.04.3 LTS   5.4.0-80-generic    containerd://1.4.12</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n kube-system  | egrep <span class=\"string\">\"kube-apiserver|kube-controller-manager|kube-scheduler|etcd\"</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-weiyigeek-107                             1/1     Running   1              380d</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-weiyigeek-108                             1/1     Running   0              96d</span></span><br><span class=\"line\">  <span class=\"comment\"># etcd-weiyigeek-109                             1/1     Running   0              380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-apiserver-weiyigeek-107                   1/1     Running   0              380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-apiserver-weiyigeek-108                   1/1     Running   0              380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-apiserver-weiyigeek-109                   1/1     Running   0              380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-controller-manager-weiyigeek-107          1/1     Running   2 (380d ago)   380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-controller-manager-weiyigeek-108          1/1     Running   1 (15d ago)    380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-controller-manager-weiyigeek-109          1/1     Running   1 (380d ago)   380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-scheduler-weiyigeek-107                   1/1     Running   3 (15d ago)    380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-scheduler-weiyigeek-108                   1/1     Running   2 (15d ago)    380d</span></span><br><span class=\"line\">  <span class=\"comment\"># kube-scheduler-weiyigeek-109                   1/1     Running   1 (380d ago)   380d</span></span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>7.查看集群的健康状态，即调度器、控制器以及etcd数据库是否正常。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get cs</span><br><span class=\"line\">Warning: v1 ComponentStatus is deprecated <span class=\"keyword\">in</span> v1.19+</span><br><span class=\"line\">NAME                 STATUS    MESSAGE                         ERROR</span><br><span class=\"line\">scheduler            Healthy   ok</span><br><span class=\"line\">controller-manager   Healthy   ok</span><br><span class=\"line\">etcd-0               Healthy   &#123;<span class=\"string\">\"health\"</span>:<span class=\"string\">\"true\"</span>,<span class=\"string\">\"reason\"</span>:<span class=\"string\">\"\"</span>&#125;</span><br></pre></td></tr></table></figure></p>\n<p>你是否认为，实践到这里就结束了，当然不是由于此处是高可用K8S集群，更新证书后坑，远不止于此。</p>\n<p>有兴趣的，请继续看下节。</p>\n<hr>\n<h3 id=\"4-集群证书更新后-calico-amp-amp-kube-proxy-相关操作\"><a href=\"#4-集群证书更新后-calico-amp-amp-kube-proxy-相关操作\" class=\"headerlink\" title=\"4.集群证书更新后 calico &amp;&amp; kube-proxy 相关操作\"></a>4.集群证书更新后 calico &amp;&amp; kube-proxy 相关操作</h3><p>描述：在进行该K8S高可用集群安装时，参照了我博客中的《在Ubuntu安装部署K8S高可用集群使用初体验》文章，我将文章链接地址( <a href=\"https://blog.weiyigeek.top/2020/4-27-470.html#0x04-高可用集群使用初体验\">https://blog.weiyigeek.top/2020/4-27-470.html#0x04-高可用集群使用初体验</a> ), 其中在使用calico网络插件时选择将 Calico 数据存储在 etcd datastore 之中，所以在进行calico安装或者使用时需要将数据存储到etcd中，则肯定需要链接到etcd数据中，此处 calico-etcd.yaml 配置清单中的etcd-ca、etcd-cert、etcd-key 字段的值仍然为原证书，由于我们前面已经更新了所有组件证书，所以再进行数据的CURD肯定是无法链接到etcd，则此时我们需要重新该 <code>calico-etcd.yaml</code> 资源配置文件。</p>\n<p>在更新集群证书后发现的calico以及业务应用的异常情况，其中最明显的就是calic无法正常启动。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -n kube-system</span><br><span class=\"line\">  NAME                                      READY   STATUS              RESTARTS        AGE</span><br><span class=\"line\">  calico-kube-controllers-6cf9b574f-zlrjn   0/1     Running             0               3s</span><br><span class=\"line\">  calico-node-5q8lq                         0/1     CrashLoopBackOff    11 (6s ago)     25m</span><br><span class=\"line\">  calico-node-62zd9                         0/1     CrashLoopBackOff    9 (5m6s ago)    25m</span><br><span class=\"line\">  calico-node-85b7k                         0/1     Running             11 (66s ago)    25m</span><br><span class=\"line\">  calico-node-8mt8q                         0/1     Running             3 (66s ago)     4m43s</span><br><span class=\"line\">  calico-node-cdkf8                         0/1     CrashLoopBackOff    9 (5m6s ago)    25m</span><br><span class=\"line\">  calico-node-jgm6q                         0/1     CrashLoopBackOff    9 (4m56s ago)   25m</span><br><span class=\"line\">  calico-node-x2b9q                         0/1     CrashLoopBackOff    9 (5m6s ago)    25m</span><br><span class=\"line\">  coredns-65c54cc984-7vt8m                  0/1     ContainerCreating   0               7m5s</span><br><span class=\"line\">  coredns-65c54cc984-hf774                  0/1     ContainerCreating   0               25m</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p><strong>操作步骤:</strong><br>步骤 01.此处参考上面的文章进行更改etcd数据库证书链接字段。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># (1) Install Calico with etcd datastore (使用etcd数据存储安装Calico) </span></span><br><span class=\"line\">curl https://docs.projectcalico.org/manifests/calico-etcd.yaml -O</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># calico-etcd 网络与etc集群连接修改(此处指定pod子网地址)</span></span><br><span class=\"line\">ETCD_CA=`cat /etc/kubernetes/pki/etcd/ca.crt | base64 | tr -d <span class=\"string\">'\\n'</span>`</span><br><span class=\"line\">ETCD_CERT=`cat /etc/kubernetes/pki/etcd/server.crt | base64 | tr -d <span class=\"string\">'\\n'</span>`</span><br><span class=\"line\">ETCD_KEY=`sudo cat /etc/kubernetes/pki/etcd/server.key | base64 | tr -d <span class=\"string\">'\\n'</span>`</span><br><span class=\"line\">POD_SUBNET=`sudo cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= <span class=\"string\">'&#123;print $NF&#125;'</span>`</span><br><span class=\"line\">sed -i <span class=\"string\">\"s@# etcd-key: null@etcd-key: <span class=\"variable\">$&#123;ETCD_KEY&#125;</span>@g; s@# etcd-cert: null@etcd-cert: <span class=\"variable\">$&#123;ETCD_CERT&#125;</span>@g; s@# etcd-ca: null@etcd-ca: <span class=\"variable\">$&#123;ETCD_CA&#125;</span>@g\"</span> calico-etcd.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">sed -i <span class=\"string\">'s#etcd_ca: \"\"#etcd_ca: \"/calico-secrets/etcd-ca\"#g; s#etcd_cert: \"\"#etcd_cert: \"/calico-secrets/etcd-cert\"#g; s#etcd_key: \"\" #etcd_key: \"/calico-secrets/etcd-key\" #g'</span> calico-etcd.yaml</span><br><span class=\"line\">sed -i <span class=\"string\">'s#etcd_endpoints: \"http://&lt;ETCD_IP&gt;:&lt;ETCD_PORT&gt;\"#etcd_endpoints: \"https://192.168.12.107:2379,https://192.168.12.108:2379,https://192.168.12.109:2379\"#g'</span> calico-etcd.yaml</span><br><span class=\"line\">sed -i <span class=\"string\">'s@# - name: CALICO_IPV4POOL_CIDR@- name: CALICO_IPV4POOL_CIDR@g; s@#   value: \"192.168.0.0/16\"@  value: '</span><span class=\"string\">\"<span class=\"variable\">$&#123;POD_SUBNET&#125;</span>\"</span><span class=\"string\">'@g'</span> calico-etcd.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2) 覆盖部署calico到K8S集群中</span></span><br><span class=\"line\">kubectl apply -f calico-etcd.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (3) 此处对比两个配置清单文件即可发现证书的不同。</span></span><br><span class=\"line\">diff calico-etcd.yaml calico-etcd.yaml.bak</span><br><span class=\"line\">17,18c17,18</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>步骤 02.在master节点(weiyigeek-107)节点上执行如下命令，重启 calico 以及各节点中的 kube-proxy Pod 容器。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># calico-node</span></span><br><span class=\"line\">kubectl delete pod -n kube-system -l k8s-app=calico-node</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># kube-proxy</span></span><br><span class=\"line\">kubectl delete pod -n kube-system -l k8s-app=calico-node</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>步骤 03.等待一段时间后，验证 calico-node 、kube-proxy服务启动情况<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -n kube-system  | egrep <span class=\"string\">\"calico|kube-proxy\"</span></span><br><span class=\"line\">calico-kube-controllers-6cf9b574f-42jnz   1/1     Running   0               98m</span><br><span class=\"line\">calico-node-dvvxk                         1/1     Running   0               98m</span><br><span class=\"line\">calico-node-g9svc                         1/1     Running   0               98m</span><br><span class=\"line\">calico-node-ggxqp                         1/1     Running   0               98m</span><br><span class=\"line\">calico-node-jps97                         1/1     Running   0               98m</span><br><span class=\"line\">calico-node-qf7cj                         1/1     Running   0               92m</span><br><span class=\"line\">calico-node-vvw9f                         1/1     Running   0               98m</span><br><span class=\"line\">calico-node-zvz8r                         1/1     Running   0               98m</span><br><span class=\"line\">kube-proxy-25p5s                          1/1     Running   0               220d</span><br><span class=\"line\">kube-proxy-8bl7f                          1/1     Running   0               94m</span><br><span class=\"line\">kube-proxy-8jxvr                          1/1     Running   0               93m</span><br><span class=\"line\">kube-proxy-d79mp                          1/1     Running   0               381d</span><br><span class=\"line\">kube-proxy-dtdtm                          1/1     Running   0               108m</span><br><span class=\"line\">kube-proxy-l7jxp                          1/1     Running   0               93m</span><br><span class=\"line\">kube-proxy-nlgln                          1/1     Running   0               381d</span><br></pre></td></tr></table></figure></p>\n<p>步骤 04.访问通过nodePort暴露的业务系统验证是否可以从任意节点代理转发访问。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get svc,pod -n devops -l app=jenkins</span><br><span class=\"line\">  <span class=\"comment\"># NAME              TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                          AGE</span></span><br><span class=\"line\">  <span class=\"comment\"># service/jenkins   NodePort   10.109.163.223   &lt;none&gt;        8080:30001/TCP,50000:30634/TCP   380d</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># NAME                           READY   STATUS    RESTARTS   AGE</span></span><br><span class=\"line\">  <span class=\"comment\"># pod/jenkins-7fc6f4fcf6-glqxj   1/1     Running   0          118m</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ curl -sI 10.109.163.223:8080 | head -n 1</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\"></span><br><span class=\"line\">$ curl -s 10.109.163.223:8080  | grep -oP <span class=\"string\">\"&lt;title&gt;\\S.+&lt;/title&gt;\"</span></span><br><span class=\"line\">$ curl -s 192.168.12.107:30001  | grep -oP <span class=\"string\">\"&lt;title&gt;\\S.+&lt;/title&gt;\"</span></span><br><span class=\"line\">&lt;title&gt;Dashboard [Jenkins]&lt;/title&gt;</span><br></pre></td></tr></table></figure></p>\n<p>好的，此问题也已经解决了。</p>\n<p>下面继续来看，如何在更新证书后<code>删除或者新增</code>控制面板节点以及工作节点。</p>\n<hr>\n<h3 id=\"5-控制平面-Master-节点的移除-amp-amp-添加\"><a href=\"#5-控制平面-Master-节点的移除-amp-amp-添加\" class=\"headerlink\" title=\"5.控制平面(Master)节点的移除&amp;&amp;添加\"></a>5.控制平面(Master)节点的移除&amp;&amp;添加</h3><p>描述: 有时在更新集群证书后，某一个控制平面的节点可能一致不正常，我们也找不到解决办法时，最终解决方案就是重置该master节点并重新加入到K8S集群中。</p>\n<p> <br/></p>\n<p><strong>操作流程</strong></p>\n<p>步骤 01.将需要master节点，例如此处(weiyigeek-108)节点设置不可调度，温馨提示操作前请注意备份该节点上的相关数据。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 在 weiyigeek-107 节点上执行如下命令，设置节点设置不可调度，此时节点状态变成：Ready,SchedulingDisabled</span></span><br><span class=\"line\">kubectl drain weiyigeek-108 --delete-local-data  --delete-emptydir-data --force --ignore-daemonsets</span><br><span class=\"line\">  <span class=\"comment\"># node/weiyigeek-108 cordoned</span></span><br><span class=\"line\">  <span class=\"comment\"># WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-qf7cj, kube-system/kube-proxy-8jxvr</span></span><br><span class=\"line\">  <span class=\"comment\"># node/weiyigeek-108 drained</span></span><br><span class=\"line\"></span><br><span class=\"line\">kubectl get node  weiyigeek-108</span><br><span class=\"line\">  NAME       STATUS                     ROLES                  AGE     VERSION</span><br><span class=\"line\">  weiyigeek-108   Ready,SchedulingDisabled   control-plane,master   3h50m   v1.23.1</span><br><span class=\"line\">  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 从集群中移除 weiyigeek-108 节点</span></span><br><span class=\"line\">kubectl delete node weiyigeek-109</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>步骤 02.生成master节点以及工作节点加入到K8S集群的认证Token及其命令示例（值得学习借鉴）。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># (1) 查看token是否失效默认是24H，如果失效过期可以重新进行生成token并打印加入命令</span></span><br><span class=\"line\">kubeadm token list</span><br><span class=\"line\">kubeadm token create --<span class=\"built_in\">print</span>-join-command</span><br><span class=\"line\">  <span class=\"comment\"># kubeadm join slb-vip.k8s:16443 --token vkhqa1.t3gtrbowlalt8um5 --discovery-token-ca-cert-hash sha256:bfc86e13da79a1ec5f53cef99661e4e3f51adda59c525cb9377cfe59956b1e59 # 注意，配置清单中会使用到</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (2)从节点的 kubeadm 加入到k8s集群之中 (推荐)，使用此命令调用init工作流的单个阶段</span></span><br><span class=\"line\">kubeadm init phase upload-certs --upload-certs</span><br><span class=\"line\">  <span class=\"comment\"># [upload-certs] Using certificate key:</span></span><br><span class=\"line\">  <span class=\"comment\"># c6a084cb06aaae2f4581145dbbe6057ce111c88fdac4ff4405a0a2db58882d76     # 注意，配置清单中会使用到</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3) 获取CA（证书）公钥哈希值</span></span><br><span class=\"line\">openssl x509 -pubkey -<span class=\"keyword\">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed <span class=\"string\">'s/^ .* //'</span></span><br><span class=\"line\"><span class=\"comment\"># (stdin)= bfc86e13da79a1ec5f53cef99661e4e3f51adda59c525cb9377cfe59956b1e59  </span></span><br><span class=\"line\"><span class=\"comment\"># 此处是公钥哈希值(一台机器上ca证书不变就一直是该sha256的值)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># (4) 进行收到组合加入集群的 master 节点的 join 命令如下:</span></span><br><span class=\"line\">kubeadm join slb-vip.k8s:16443 --token ejwx62.vqwog6il5p83uk7y \\</span><br><span class=\"line\">--discovery-token-ca-cert-hash sha256:bfc86e13da79a1ec5f53cef99661e4e3f51adda59c525cb9377cfe59956b1e59 \\</span><br><span class=\"line\">--control-plane --certificate-key c6a084cb06aaae2f4581145dbbe6057ce111c88fdac4ff4405a0a2db58882d76</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>步骤 03.通过ssh远程登录<code>weiyigeek-108</code>节点重置该节点。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop kubelet</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> y | kubeadm reset</span><br><span class=\"line\">sudo rm -rf <span class=\"variable\">$HOME</span>/.kube </span><br><span class=\"line\">sudo rm -rf /var/lib/cni/ /etc/cni/ /var/lib/kubelet/* </span><br><span class=\"line\">ipvsadm --clear</span><br><span class=\"line\">iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start kubelet; systemctl status kubelet</span><br></pre></td></tr></table></figure>\n<p>温馨提示: 如果主Master节点在初始化时候出错需要重新配置时候,请执行以上述命令进行重置;</p>\n<p><br/></p>\n<p>步骤 04.准备控制平面节点加入到集群的JoinConfiguration资源配置清单<br><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">$</span> <span class=\"string\">vim</span> <span class=\"string\">join-k8s.yaml</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">kubeadm.k8s.io/v1beta3</span></span><br><span class=\"line\"><span class=\"attr\">caCertPath:</span> <span class=\"string\">/etc/kubernetes/pki/ca.crt</span></span><br><span class=\"line\"><span class=\"attr\">discovery:</span></span><br><span class=\"line\"><span class=\"attr\">  bootstrapToken:</span></span><br><span class=\"line\"><span class=\"attr\">    apiServerEndpoint:</span> <span class=\"string\">slb-vip.k8s:16443</span>   <span class=\"comment\"># 高可用的APIServer地址</span></span><br><span class=\"line\"><span class=\"attr\">    token:</span> <span class=\"string\">vkhqa1.t3gtrbowlalt8um5</span>         <span class=\"comment\"># 上述步骤生成Token</span></span><br><span class=\"line\"><span class=\"attr\">    caCertHashes:</span></span><br><span class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">\"sha256:bfc86e13da79a1ec5f53cef99661e4e3f51adda59c525cb9377cfe59956b1e59\"</span>   <span class=\"comment\"># 上述步骤获取到的CA（证书）公钥哈希值</span></span><br><span class=\"line\"><span class=\"attr\">  timeout:</span> <span class=\"number\">5</span><span class=\"string\">m0s</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">JoinConfiguration</span></span><br><span class=\"line\"><span class=\"attr\">controlPlane:</span></span><br><span class=\"line\"><span class=\"attr\">  certificateKey:</span> <span class=\"string\">\"c6a084cb06aaae2f4581145dbbe6057ce111c88fdac4ff4405a0a2db58882d76\"</span>  <span class=\"comment\"># 上述步骤获取到 certificate key</span></span><br><span class=\"line\"><span class=\"attr\">  localAPIEndpoint:</span></span><br><span class=\"line\"><span class=\"attr\">    advertiseAddress:</span> <span class=\"number\">192.168</span><span class=\"number\">.12</span><span class=\"number\">.108</span>      <span class=\"comment\"># 本地APIServer节点地址(即weiyigeek-108节点机器地址)</span></span><br><span class=\"line\"><span class=\"attr\">    bindPort:</span> <span class=\"number\">6443</span>                        <span class=\"comment\"># 本地APIServer节点端口</span></span><br><span class=\"line\"><span class=\"attr\">nodeRegistration:</span></span><br><span class=\"line\"><span class=\"attr\">  criSocket:</span> <span class=\"string\">/run/containerd/containerd.sock</span>  <span class=\"comment\"># 重点，在1.24.x之前默认是使用docker-shim，此处我们指定使用containerd</span></span><br><span class=\"line\"><span class=\"attr\">  imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">weiyigeek-108</span>                              <span class=\"comment\"># 重点，节点名称</span></span><br><span class=\"line\"><span class=\"attr\">  taints:</span></span><br><span class=\"line\"><span class=\"attr\">  - effect:</span> <span class=\"string\">NoSchedule</span></span><br><span class=\"line\"><span class=\"attr\">    key:</span> <span class=\"string\">node-role.kubernetes.io/master</span></span><br></pre></td></tr></table></figure></p>\n<p>温馨提示: 在 bootstrapToken 字段中也可跳过 caCertHashes 认证，请键值为<code>unsafeSkipCAVerification: true</code>。</p>\n<p><br/></p>\n<p>步骤 05.证书更新后原有的master节点移除加入前，需要针对久的etcd数据库进行处理操作。</p>\n<p>此处有个小插曲，由于各master节点组成了一个高可用集群，每个master节点上都运行了etcd服务，以实现etcd数据库的高可用，有</p>\n<p>Kubernetes 与 Etcd 版本与证书关联说明:</p>\n<ul>\n<li>ETCD 版本小于等于v1.9版本，etcd默认是不使用TLS连接，没有etcd相关证书，只需要更新master证书即可。</li>\n<li>ETCD 版本大于等于v1.10版本，etcd默认开启TLS，需要更新etcd证书和master证书。</li>\n</ul>\n<p>此处我们的etcd版本是v3.5.x是开启TLS的，前面我们重启在master节点的etcd的相关pod后将会自动使用最新的证书，而在将master节点移除重新加入需进行如下操作，否则将会报错（查看尾部的错误实例）:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl <span class=\"built_in\">exec</span> -n kube-system -it etcd-weiyigeek-107 /bin/sh</span><br><span class=\"line\"><span class=\"comment\"># etcd 集群成员列表</span></span><br><span class=\"line\">$ etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key member list</span><br><span class=\"line\">  <span class=\"comment\"># 2db31a5d67ec1034, started, weiyigeek-108, https://192.168.12.108:2380, https://192.168.12.108:2379, false</span></span><br><span class=\"line\">  <span class=\"comment\"># 42efe7cca897d765, started, weiyigeek-109, https://192.168.12.109:2380, https://192.168.12.109:2379, false</span></span><br><span class=\"line\">  <span class=\"comment\"># 471323846709334f, started, weiyigeek-107, https://192.168.12.107:2380, https://192.168.12.107:2379, false</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># etcd 集群节点数据状态</span></span><br><span class=\"line\">$ etcdctl --endpoints https://192.168.12.107:2379,https://192.168.12.108:2379,https://192.168.12.109:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key endpoint status</span><br><span class=\"line\">  <span class=\"comment\"># https://192.168.12.107:2379, 471323846709334f, 3.5.1, 324 MB, true, false, 8, 109396908, 109396908,</span></span><br><span class=\"line\">  <span class=\"comment\"># https://192.168.12.108:2379, 2db31a5d67ec1034, 3.5.1, 324 MB, false, false, 8, 109396916, 109396916,</span></span><br><span class=\"line\">  <span class=\"comment\"># https://192.168.12.109:2379, 42efe7cca897d765, 3.5.1, 324 MB, false, false, 8, 109396922, 109396922,</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#  移除 2db31a5d67ec1034 成员（weiyigeek-108 旧节点）</span></span><br><span class=\"line\">$ etcdctl --endpoints 127.0.0.1:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key /etc/kubernetes/pki/etcd/server.key member remove 7e66da9dd902d557</span><br><span class=\"line\">Member 2db31a5d67ec1034 removed from cluster 3a7f4f11f646b97b</span><br></pre></td></tr></table></figure>\n<p><br/></p>\n<p>步骤 06.在 weiyigeek-108 节点上执行加入集群命令, 若加入成果可以通过<code>kubectl get nods</code>命令查看<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 停止该节点上所有 Pod 防止端口占用</span></span><br><span class=\"line\">crictl stop $(crictl ps -a -q)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按照 JoinConfiguration 资源配置清单加入到集群中，--v=5显示更完整的操作过程日志，排错必备。</span></span><br><span class=\"line\">kubeadm join --config=join-k8s.yaml --v=5</span><br><span class=\"line\">  <span class=\"comment\"># 若显示如下提示则加入成功，否则请排查异常情况。</span></span><br><span class=\"line\">  <span class=\"comment\"># This node has joined the cluster and a new control plane instance was created</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># To start administering your cluster from this node, you need to run the following as a regular user:</span></span><br><span class=\"line\">mkdir -p <span class=\"variable\">$HOME</span>/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf <span class=\"variable\">$HOME</span>/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) <span class=\"variable\">$HOME</span>/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get node weiyigeek-108</span><br><span class=\"line\">  <span class=\"comment\"># NAME       STATUS     ROLES                  AGE     VERSION</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-108   Ready      control-plane,master   3m9s    v1.23.1</span></span><br></pre></td></tr></table></figure></p>\n<p>温馨提示: 如果加入主master节点时一直停留在 pre-flight 状态，请在第额外的几个节点上执行命令检查：<code>curl -ik https://设置APISERVER地址:6443/version</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -ik https://slb-vip.k8s:16443/version</span><br><span class=\"line\"><span class=\"comment\"># 正常状态下的输出</span></span><br><span class=\"line\">HTTP/2 200</span><br><span class=\"line\">audit-id: 77c614cb-0c27-42f5-a852-b5ef8415361f</span><br><span class=\"line\">cache-control: no-cache, private</span><br><span class=\"line\">content-type: application/json</span><br><span class=\"line\">x-kubernetes-pf-flowschema-uid: 41a01a35-c480-4cfd-8854-494261622406</span><br><span class=\"line\">x-kubernetes-pf-prioritylevel-uid: 4cfd380c-d39c-490f-96b0-dd4ed07be4e0</span><br><span class=\"line\">content-length: 263</span><br><span class=\"line\">date: Wed, 01 Feb 2023 07:34:01 GMT</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"major\"</span>: <span class=\"string\">\"1\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"minor\"</span>: <span class=\"string\">\"23\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"gitVersion\"</span>: <span class=\"string\">\"v1.23.0\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"gitCommit\"</span>: <span class=\"string\">\"ab69524f795c42094a6630298ff53f3c3ebab7f4\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"gitTreeState\"</span>: <span class=\"string\">\"clean\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"buildDate\"</span>: <span class=\"string\">\"2021-12-07T18:09:57Z\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"goVersion\"</span>: <span class=\"string\">\"go1.17.3\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"compiler\"</span>: <span class=\"string\">\"gc\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"platform\"</span>: <span class=\"string\">\"linux/amd64\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>至此，实践完毕!</p>\n<hr>\n<h3 id=\"6-工作平面-Work-节点的移除-amp-amp-添加\"><a href=\"#6-工作平面-Work-节点的移除-amp-amp-添加\" class=\"headerlink\" title=\"6.工作平面(Work)节点的移除&amp;&amp;添加\"></a>6.工作平面(Work)节点的移除&amp;&amp;添加</h3><p>描述: k8s集群中工作节点的添加与移除，和master节点移除添加方法基本一致，不同之处在于加入集群的配置清单，你可以对照一下master节点与node节点加入集群时的配置清单。</p>\n<p>此处，也不在累述直接快速上脚本。</p>\n<p>步骤 01.在master节点上执行，将设weiyigeek-226节点置不可调度,即不分配新的资源到该节点上，并且驱逐pod到其他工作节点上。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 温馨提示: drain命令会自动把node设置为不可调度，所以可以省略上面执行的cordon命令</span></span><br><span class=\"line\">kubectl cordon weiyigeek-226</span><br><span class=\"line\">kubectl drain weiyigeek-226 --delete-emptydir-data --force --ignore-daemonsets</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>步骤 02.在weiyigeek-226工作节点上执行重置节点命令<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop kubelet</span><br><span class=\"line\"><span class=\"built_in\">echo</span> y | kubeadm reset</span><br><span class=\"line\">sudo rm -rf <span class=\"variable\">$HOME</span>/.kube; sudo rm -rf /var/lib/cni/ /etc/cni/ /var/lib/kubelet/* </span><br><span class=\"line\">ipvsadm --clear; iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span><br><span class=\"line\">systemctl start kubelet; systemctl status kubelet</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<p>步骤 03.两种方式将工作节点加入K8S集群中。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1.命令行模式</span></span><br><span class=\"line\">kubeadm join 192.168.80.137:6443 --token 新生成的Token填写此处 --discovery-token-ca-cert-hash sha256:获取的公钥哈希值填写此处</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2.配置清单模式</span></span><br><span class=\"line\">tee &gt; join-k8s.yaml &lt;&lt;EOF</span><br><span class=\"line\">cat join-k8s.yaml</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">caCertPath: /etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">discovery:</span><br><span class=\"line\">  bootstrapToken:</span><br><span class=\"line\">    apiServerEndpoint: slb-vip.k8s:16443</span><br><span class=\"line\">    token: vkhqa1.t3gtrbowlalt8um5</span><br><span class=\"line\">    unsafeSkipCAVerification: <span class=\"literal\">true</span></span><br><span class=\"line\">  timeout: 5m0s</span><br><span class=\"line\">  tlsBootstrapToken: vkhqa1.t3gtrbowlalt8um5</span><br><span class=\"line\">kind: JoinConfiguration</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: /run/containerd/containerd.sock</span><br><span class=\"line\">  imagePullPolicy: IfNotPresent</span><br><span class=\"line\">  name: weiyigeek-226</span><br><span class=\"line\">  taints: null</span><br><span class=\"line\">EOF</span><br><span class=\"line\">kubeadm join --config=join-k8s.yaml --v=5</span><br></pre></td></tr></table></figure>\n<p><br/></p>\n<p>步骤 04.在master节点查看加入的工作的节点，此处设置其work标签。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl label nodes weiyigeek-226 node-role.kubernetes.io/work=<span class=\"built_in\">test</span></span><br><span class=\"line\">kubectl get nodes weiyigeek-226</span><br><span class=\"line\">  <span class=\"comment\"># NAME       STATUS   ROLES   AGE    VERSION</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-226   Ready    work    10m   v1.23.1</span></span><br></pre></td></tr></table></figure></p>\n<p>至此，完毕!</p>\n<p><br/></p>\n<h3 id=\"n-实践所遇问题\"><a href=\"#n-实践所遇问题\" class=\"headerlink\" title=\"n.实践所遇问题\"></a>n.实践所遇问题</h3><h4 id=\"问题1-在master节点上或者非master节点上执行kubectl命令报-The-connection-to-the-server-localhost-8080-was-refused-错误\"><a href=\"#问题1-在master节点上或者非master节点上执行kubectl命令报-The-connection-to-the-server-localhost-8080-was-refused-错误\" class=\"headerlink\" title=\"问题1.在master节点上或者非master节点上执行kubectl命令报 The connection to the server localhost:8080 was refused -错误\"></a>问题1.在master节点上或者非master节点上执行kubectl命令报 <code>The connection to the server localhost:8080 was refused -</code>错误</h4><p>错误信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get cs</span><br><span class=\"line\">The connection to the server localhost:8080 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure></p>\n<p>错误原因: 通常情况下是当前用户下没有<code>~/.kube/config</code>或者不存在环境变量<br>解决办法:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 方式1.复制 /etc/kubernetes 目录下 admin.conf 文件到 当前用户家目录下 /.kube/config</span></span><br><span class=\"line\">mkdir -p <span class=\"variable\">$HOME</span>/.kube</span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'yes'</span> |  sudo cp -i /etc/kubernetes/admin.conf <span class=\"variable\">$HOME</span>/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) <span class=\"variable\">$HOME</span>/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 方式2.使用 KUBECONFIG 环境变量包含一个 kubeconfig 文件列表。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span>  KUBECONFIG=/etc/kubernetes/admin.conf:~/.kube/devops.kubeconfig</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 方式3.在命令执行时使用--kubeconfig参数指定配置文件</span></span><br><span class=\"line\">kubectl config --kubeconfig=/etc/kubernetes/admin.conf</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<h4 id=\"问题2-在某master节点上calico-node准备状态一直为0-1并提示-connect-connection-refusedcalico-node-is-not-ready-错误\"><a href=\"#问题2-在某master节点上calico-node准备状态一直为0-1并提示-connect-connection-refusedcalico-node-is-not-ready-错误\" class=\"headerlink\" title=\"问题2.在某master节点上calico-node准备状态一直为0/1并提示 connect: connection refusedcalico/node is not ready: 错误\"></a>问题2.在某master节点上calico-node准备状态一直为0/1并提示 <code>connect: connection refusedcalico/node is not ready:</code> 错误</h4><p>错误信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -n kube-system calico-node-v52sv</span><br><span class=\"line\">  <span class=\"comment\"># NAME                READY   STATUS    RESTARTS   AGE</span></span><br><span class=\"line\">  <span class=\"comment\"># calico-node-v52sv   0/1     Running   0          31m</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl describe pod -n kube-system calico-node-v52sv | grep <span class=\"string\">\"not ready\"</span></span><br><span class=\"line\">  <span class=\"comment\"># Warning  Unhealthy    33m (x2 over 33m)  kubelet  Readiness probe failed: calico/node is not ready: BIRD is not ready: Error querying BIRD: unable to connect to BIRDv4 socket: dial unix /var/run/calico/bird.ctl: connect: connection refused</span></span><br><span class=\"line\">  <span class=\"comment\"># calico/node is not ready: BIRD is not ready: BGP not established with 192.168.12.107,192.168.12.109,192.168.12.223,192.168.12.224,192.168.12.225,192.168.12.226</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl logs -f --tail 50  -n kube-system calico-node-v52sv | grep <span class=\"string\">\"interface\"</span></span><br><span class=\"line\">  <span class=\"comment\"># 2023-02-01 08:40:57.583 [INFO][69] monitor-addresses/startup.go 714: Using autodetected IPv4 address on interface br-b92e9270f33c: 172.22.0.1/16</span></span><br><span class=\"line\">  <span class=\"comment\"># calico 对应的 Pod 启动失败，报错：</span></span><br><span class=\"line\">  <span class=\"comment\"># Number of node(s) with BGP peering established = 0</span></span><br></pre></td></tr></table></figure></p>\n<p>错误原因: 由于该节点上安装了docker并创建了容器，Calico 选择了有问题的br网卡，导致 calico-node 的 Pod 不能启动。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Calico 提供了 IP 自动检测的方法，默认是使用第一个有效网卡上的第一个有效的 IP 地址：</span></span><br><span class=\"line\">IP_AUTODETECTION_METHOD=first-found</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 节点上应该是出现了有问题的网卡，可以使用以下命令查看：</span></span><br><span class=\"line\">ip link | grep br</span><br></pre></td></tr></table></figure><br>知识扩展: calico-node daemonset 默认的策略是获取第一个取到的网卡的 ip 作为 calico node 的ip, 由于集群中网卡名称不统一所以可能导致calico获取的网卡IP不对, 所以出现此种情况下就只能 IP_AUTODETECTION_METHOD 字段指定通配符网卡名称或者IP地址。</p>\n<p>解决办法:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 方法1.修改 yaml 配置清单中 IP 自动检测方法，在 spec.containers.env 下添加以下两行。（推荐）</span></span><br><span class=\"line\">  - name: IP_AUTODETECTION_METHOD</span><br><span class=\"line\">    value: <span class=\"string\">\"interface=ens.*\"</span>  <span class=\"comment\"># ens 根据实际网卡开头配置</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 方法2.删除有问题的网卡（推荐），即指定网卡名称（br 开头的问题网卡）删除。</span></span><br><span class=\"line\">ifconfig br-b92e9270f33c down</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 方法3.假如环境不依赖docker情况下，可以卸载docker, 然后重启系统即可。</span></span><br><span class=\"line\">sudo apt-get autoremove docker docker-ce docker-engine docker.io</span><br></pre></td></tr></table></figure></p>\n<p>最后重新启动异常Pod即可:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl delete pod -n kube-system calico-node-v52sv</span><br><span class=\"line\">kubectl get nodes weiyigeek-108</span><br><span class=\"line\">  <span class=\"comment\"># NAME       STATUS   ROLES                  AGE   VERSION</span></span><br><span class=\"line\">  <span class=\"comment\"># weiyigeek-108   Ready    control-plane,master   66m   v1.23.1</span></span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<h4 id=\"问题3-在节点加入集群时报-bridge-nf-call-iptables-does-not-exist错误问题解决\"><a href=\"#问题3-在节点加入集群时报-bridge-nf-call-iptables-does-not-exist错误问题解决\" class=\"headerlink\" title=\"问题3.在节点加入集群时报 bridge-nf-call-iptables does not exist错误问题解决\"></a>问题3.在节点加入集群时报 <code>bridge-nf-call-iptables does not exist</code>错误问题解决</h4><p>错误信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[preflight] Some fatal errors occurred:</span><br><span class=\"line\">  [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist</span><br><span class=\"line\">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br><span class=\"line\">error execution phase preflight</span><br></pre></td></tr></table></figure><br>解决办法:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置</span></span><br><span class=\"line\">$ cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class=\"line\">br_netfilter</span><br><span class=\"line\">EOF</span><br><span class=\"line\">$ cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">EOF</span><br><span class=\"line\">$ modprobe br_netfilter &amp;&amp; sudo sysctl --system</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<h4 id=\"问题4-在启动某个节点的kubelet报Unable-to-read-config-path-quot-err-quot-path-does-not-exist-ignoring错误解决办法\"><a href=\"#问题4-在启动某个节点的kubelet报Unable-to-read-config-path-quot-err-quot-path-does-not-exist-ignoring错误解决办法\" class=\"headerlink\" title=\"问题4.在启动某个节点的kubelet报Unable to read config path&quot; err=&quot;path does not exist, ignoring错误解决办法\"></a>问题4.在启动某个节点的kubelet报<code>Unable to read config path&quot; err=&quot;path does not exist, ignoring</code>错误解决办法</h4><p>错误信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Jan 16 14:27:25 weiyigeek-226 kubelet[882231]: E0116 14:27:25.496423  882231 kubelet.go:2347] <span class=\"string\">\"Container runtime network not ready\"</span> networkReady=<span class=\"string\">\"NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns e&gt;</span></span><br><span class=\"line\"><span class=\"string\">Jan 16 14:27:26 weiyigeek-226 kubelet[882231]: E0116 14:27:26.482369  882231 file_linux.go:61] \"</span>Unable to <span class=\"built_in\">read</span> config path<span class=\"string\">\" err=\"</span>path does not exist, ignoring<span class=\"string\">\" path=\"</span>/etc/kubernetes/manifests<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">J</span></span><br></pre></td></tr></table></figure><br>解决办法: 检查 /etc/kubernetes/manifests 目录是否存储及其权限<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -vp /etc/kubernetes/manifests</span><br></pre></td></tr></table></figure></p>\n<p><br/></p>\n<h4 id=\"问题5-在节点加入到集群中时报the-namespace-quot-kube-system-quot-error-downloading-the-secret-错误解决办法\"><a href=\"#问题5-在节点加入到集群中时报the-namespace-quot-kube-system-quot-error-downloading-the-secret-错误解决办法\" class=\"headerlink\" title=\"问题5.在节点加入到集群中时报the namespace &quot;kube-system&quot; error downloading the secret 错误解决办法\"></a>问题5.在节点加入到集群中时报<code>the namespace &quot;kube-system&quot; error downloading the secret</code> 错误解决办法</h4><p>错误信息:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">I0116 04:39:41.428788  184219 checks.go:246] validating the existence and emptiness of directory /var/lib/etcd</span><br><span class=\"line\">[preflight] Would pull the required images (like <span class=\"string\">'kubeadm config images pull'</span>)</span><br><span class=\"line\">[download-certs] Downloading the certificates <span class=\"keyword\">in</span> Secret <span class=\"string\">\"kubeadm-certs\"</span> <span class=\"keyword\">in</span> the <span class=\"string\">\"kube-system\"</span> Namespace</span><br><span class=\"line\">secrets <span class=\"string\">\"kubeadm-certs\"</span> is forbidden: User <span class=\"string\">\"system:bootstrap:20w21w\"</span> cannot get resource <span class=\"string\">\"secrets\"</span> <span class=\"keyword\">in</span> API group <span class=\"string\">\"\"</span> <span class=\"keyword\">in</span> the namespace <span class=\"string\">\"kube-system\"</span></span><br><span class=\"line\">error downloading the secret</span><br></pre></td></tr></table></figure><br>解决办法: 将证书上载到kubeadm证书。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm init phase upload-certs --upload-certs</span><br><span class=\"line\">  <span class=\"comment\"># [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace</span></span><br><span class=\"line\">  <span class=\"comment\"># [upload-certs] Using certificate key:</span></span><br><span class=\"line\">  <span class=\"comment\"># 3a3d7610038c9d14edf377d92b9c6b44e049566ddd25b0e69bf571af58227ae7</span></span><br></pre></td></tr></table></figure></p>\n","comments":true,"excerpt":"[TOC]","categories":[{"name":"Containers","path":"api/categories/Containers.json"},{"name":"OperationTools","path":"api/categories/OperationTools.json"}],"tags":[{"name":"k8s","path":"api/tags/k8s.json"}]}